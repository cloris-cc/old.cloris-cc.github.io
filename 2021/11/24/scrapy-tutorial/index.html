<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>scrapy_tutorial - 茶茶日记 - winklog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶茶日记 - winklog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶茶日记 - winklog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="scrapy 爬虫框架"><meta property="og:type" content="blog"><meta property="og:title" content="scrapy_tutorial"><meta property="og:url" content="https://teamwang.cn/2021/11/24/scrapy-tutorial/"><meta property="og:site_name" content="茶茶日记 - winklog"><meta property="og:description" content="scrapy 爬虫框架"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://teamwang.cn/img/og_image.png"><meta property="article:published_time" content="2021-11-23T18:10:07.000Z"><meta property="article:modified_time" content="2021-11-23T18:21:58.869Z"><meta property="article:author" content="Jacky"><meta property="article:tag" content="茶茶,日记,茶茶日记,winklog,WinkLog,博客,teamwang,TeamWang,王嘉尔,Jakcy,jacky"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://teamwang.cn/2021/11/24/scrapy-tutorial/"},"headline":"scrapy_tutorial","image":["https://teamwang.cn/img/og_image.png"],"datePublished":"2021-11-23T18:10:07.000Z","dateModified":"2021-11-23T18:21:58.869Z","author":{"@type":"Person","name":"Jacky"},"description":"scrapy 爬虫框架"}</script><link rel="canonical" href="https://teamwang.cn/2021/11/24/scrapy-tutorial/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?05af3f3bd18ffe652b63cc7ee6abb48c";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶茶日记 - winklog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时光轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-11-23T18:10:07.000Z" title="11/24/2021, 2:10:07 AM">2021-11-24</time>发表</span><span class="level-item"><time dateTime="2021-11-23T18:21:58.869Z" title="11/24/2021, 2:21:58 AM">2021-11-24</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></span><span class="level-item">13 分钟读完 (大约1951个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">scrapy_tutorial</h1><div class="content"><p>scrapy 爬虫框架</p>
<span id="more"></span>

<h1 id="Scrapy-Tutorial"><a href="#Scrapy-Tutorial" class="headerlink" title="Scrapy Tutorial"></a>Scrapy Tutorial</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>python官方文档 <a target="_blank" rel="noopener" href="https://docs.python.org/zh-cn/3.9/tutorial/">https://docs.python.org/zh-cn/3.9/tutorial/</a></p>
<p>CSS selectors and XPath expressions：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35290785/article/details/90634344">python中 r’’, b’’, u’’, f’’ 的含义</a></p>
<p>xpath教程</p>
<h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><p>安装scrapy:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scrapy</span><br></pre></td></tr></table></figure>

<p>创建项目：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject [project name]</span><br></pre></td></tr></table></figure>

<p>运行爬虫：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider [filename]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line">scrapy crawl [spider name]</span><br></pre></td></tr></table></figure>

<p>提取数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; scrapy shell <span class="string">&quot;http://quotes.toscrape.com/page/1/&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">&quot;div.quote&quot;</span>):</span></span><br><span class="line">    		text = quote.css(&quot;span.text::text&quot;).get()</span><br><span class="line">	    	author = quote.css(&quot;small.author::text&quot;).get()</span><br><span class="line">	  	  tags = quote.css(&quot;div.tags a.tag::text&quot;).getall()</span><br><span class="line">  		 	print(dict(text=text, author=author, tags=tags))</span><br></pre></td></tr></table></figure>

<p>保存爬取的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider1</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&quot;quotes1&quot;</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">&#x27;http://quotes.toscrape.com/page/1/&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://quotes.toscrape.com/page/2/&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">&#x27;div.quote&#x27;</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">&#x27;text&#x27;</span>: quote.css(<span class="string">&#x27;span.text::text&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;author&#x27;</span>: quote.css(<span class="string">&#x27;span.author::text&#x27;</span>).get(),</span><br><span class="line">                <span class="string">&#x27;tags&#x27;</span>: quote.css(<span class="string">&#x27;span.tags a.tag::text&#x27;</span>).getall(),</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> -O, Overwrite; -o, 在已有的json文件最佳内容，但是会破坏 json 的格式</span></span><br><span class="line">scrapy crawl quotes1 -O quotes.json</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 建议用这种文件格式 Json Line</span></span><br><span class="line">scrapy crawl quotes1 -o quotes.jl</span><br></pre></td></tr></table></figure>



<p>下一页的处理方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">next_page = response.css(<span class="string">&quot;li.next a::attr(href)&quot;</span>).get() <span class="comment"># /href/2</span></span><br><span class="line"><span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	next_page = response.urljoin(next_page) <span class="comment"># 拼接 url</span></span><br><span class="line">  print(next_page)</span><br><span class="line">  <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_page = response.css(<span class="string">&quot;li.next a::attr(href)&quot;</span>).get()</span><br><span class="line"><span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">  <span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">&#x27;ul.pager a::attr(href)&#x27;</span>):</span><br><span class="line">  <span class="keyword">yield</span> response.follow(href, callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>自动解析 href 链接 + url DFS</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="string">&#x27;ul.pager a&#x27;</span>):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(a, callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">anchors = response.css(<span class="string">&#x27;ul.pager a&#x27;</span>)</span><br><span class="line"><span class="keyword">yield</span> <span class="keyword">from</span> response.follow_all(anchors, callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">yield</span> <span class="keyword">from</span> response.follow_all(css=<span class="string">&#x27;ul.pager a&#x27;</span>, callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>传参 -a：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -O quotes-humor.json -a tag=humor</span><br></pre></td></tr></table></figure>

<p>xpath的@相当于css的attr方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToScrapeCSS</span>(<span class="params">scrapy.Spider</span>):</span>    <span class="string">&quot;&quot;&quot; css &quot;&quot;&quot;</span>    name = <span class="string">&#x27;to_scrape_css&#x27;</span>    start_urls = [<span class="string">&#x27;http://quotes.toscrape.com/&#x27;</span>]    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span>        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">&#x27;div.quote&#x27;</span>):            <span class="keyword">yield</span> &#123;                <span class="string">&#x27;text&#x27;</span>: quote.css(<span class="string">&#x27;span.text::text&#x27;</span>).extract_first(),                <span class="string">&#x27;author&#x27;</span>: quote.css(<span class="string">&#x27;small.author::text&#x27;</span>).extract_first(),                <span class="string">&#x27;tags&#x27;</span>: quote.css(<span class="string">&#x27;div.tags &gt; a.tag::text&#x27;</span>).extract()            &#125;        next_page_url = response.css(<span class="string">&#x27;li.next &gt; a::attr(href)&#x27;</span>).extract_first()        <span class="keyword">if</span> next_page_url <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:            <span class="keyword">yield</span> scrapy.Request(response.urljoin(next_page_url))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToScrapeXPath</span>(<span class="params">scrapy.Spider</span>):</span>  	<span class="string">&quot;&quot;&quot; xpath &quot;&quot;&quot;</span>    name = <span class="string">&#x27;toscrape-xpath&#x27;</span>    start_urls = [        <span class="string">&#x27;http://quotes.toscrape.com/&#x27;</span>,    ]    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response, **kwargs</span>):</span>        <span class="keyword">for</span> quote <span class="keyword">in</span> response.xpath(<span class="string">&#x27;//div[@class=&quot;quote&quot;]&#x27;</span>):            <span class="keyword">yield</span> &#123;                <span class="string">&#x27;text&#x27;</span>: quote.xpath(<span class="string">&#x27;./span[@class=&quot;text&quot;]/text()&#x27;</span>).extract_first(),                <span class="string">&#x27;author&#x27;</span>: quote.xpath(<span class="string">&#x27;.//small[@class=&quot;author&quot;]/text()&#x27;</span>).extract_first(),                <span class="string">&#x27;tags&#x27;</span>: quote.xpath(<span class="string">&#x27;.//div[@class=&quot;tags&quot;]/a[@class=&quot;tag&quot;]/text()&#x27;</span>).extract()            &#125;        next_page_url = response.xpath(<span class="string">&#x27;//li[@class=&quot;next&quot;]/a/@href&#x27;</span>).extract_first()        <span class="keyword">if</span> next_page_url <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:            <span class="keyword">yield</span> scrapy.Request(response.urljoin(next_page_url))</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; response.css(<span class="string">&#x27;img::attr(src)&#x27;</span>).get()<span class="string">&#x27;image1_thumb.jpg&#x27;</span>&gt;&gt;&gt; response.css(<span class="string">&#x27;img&#x27;</span>).xpath(<span class="string">&#x27;@src&#x27;</span>).get()<span class="string">&#x27;image1_thumb.jpg&#x27;</span>&gt;&gt;&gt; response.css(<span class="string">&#x27;img&#x27;</span>).xpath(<span class="string">&#x27;@src&#x27;</span>).getall()[<span class="string">&#x27;image1_thumb.jpg&#x27;</span>, <span class="string">&#x27;image2_thumb.jpg&#x27;</span>, <span class="string">&#x27;image3_thumb.jpg&#x27;</span>, <span class="string">&#x27;image4_thumb.jpg&#x27;</span>, <span class="string">&#x27;image5_thumb.jpg&#x27;</span>]&gt;&gt;&gt; response.xpath(<span class="string">&#x27;//div[@id=&quot;images&quot;]/a/text()&#x27;</span>).get()<span class="string">&#x27;Name: My image 1 &#x27;</span><span class="comment"># attrib[] 属性&gt;&gt;&gt; [img.attrib[&#x27;src&#x27;] for img in response.css(&#x27;img&#x27;)][&#x27;image1_thumb.jpg&#x27;, &#x27;image2_thumb.jpg&#x27;, &#x27;image3_thumb.jpg&#x27;, &#x27;image4_thumb.jpg&#x27;, &#x27;image5_thumb.jpg&#x27;]&gt;&gt;&gt; response.css(&#x27;img&#x27;).attrib[&#x27;src&#x27;]&#x27;image1_thumb.jpg&#x27;</span></span></span><br></pre></td></tr></table></figure>





<p>中文“乱码”：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl dy_spider -o dy_spider.jl -s FEED_EXPORT_ENCODING=utf-8</span><br></pre></td></tr></table></figure>

<p>常用命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查询项目下的所有爬虫scrapy list<span class="comment"># 查看配置scrapy settings --get [USER_AGENT]</span></span></span><br></pre></td></tr></table></figure>

<p>登录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># start_req..方法只会执行 1 次def start_requests(self):	return [scrapy.FormRequest(&quot;http://www.example.com/login&quot;,                                   formdata=&#123;&#x27;user&#x27;: &#x27;john&#x27;, &#x27;pass&#x27;: &#x27;secret&#x27;&#125;,                                   callback=self.logged_in)]</span></span><br></pre></td></tr></table></figure>

<p>css: class用. id用# 其它属性用::attr(xxx)</p>
<p>获取某个属性值：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; response.css(<span class="string">&#x27;a::attr(href)&#x27;</span>).getall()[<span class="string">&#x27;image1.html&#x27;</span>, <span class="string">&#x27;image2.html&#x27;</span>, <span class="string">&#x27;image3.html&#x27;</span>, <span class="string">&#x27;image4.html&#x27;</span>, <span class="string">&#x27;image5.html&#x27;</span>]&gt;&gt;&gt; response.xpath(<span class="string">&#x27;//a/@href&#x27;</span>).getall()[<span class="string">&#x27;image1.html&#x27;</span>, <span class="string">&#x27;image2.html&#x27;</span>, <span class="string">&#x27;image3.html&#x27;</span>, <span class="string">&#x27;image4.html&#x27;</span>, <span class="string">&#x27;image5.html&#x27;</span>]<span class="comment"># 注意，response.xpath(&#x27;//a[@href]&#x27;).getall() 会输出所有a标签</span></span></span><br></pre></td></tr></table></figure>

<p>获取所有属性：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; response.css(<span class="string">&#x27;base&#x27;</span>).attrib&#123;<span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://example.com/&#x27;</span>&#125;&gt;&gt;&gt; response.css(<span class="string">&#x27;base&#x27;</span>).attrib[<span class="string">&#x27;href&#x27;</span>]<span class="string">&#x27;http://example.com/&#x27;</span></span></span><br></pre></td></tr></table></figure>

<p>正则表达式：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; response.xpath(<span class="string">&#x27;//a[contains(@href, &quot;image&quot;)]/text()&#x27;</span>).re(r<span class="string">&#x27;Name:\s*(.*)&#x27;</span>)[<span class="string">&#x27;My image 1&#x27;</span>, <span class="string">&#x27;My image 2&#x27;</span>, <span class="string">&#x27;My image 3&#x27;</span>, <span class="string">&#x27;My image 4&#x27;</span>, <span class="string">&#x27;My image 5&#x27;</span>] &gt;&gt;&gt; response.xpath(<span class="string">&#x27;//a[contains(@href, &quot;image&quot;)]/text()&#x27;</span>).re_first(r<span class="string">&#x27;Name:\s*(.*)&#x27;</span>)<span class="string">&#x27;My image 1&#x27;</span></span></span><br></pre></td></tr></table></figure>

<p>xpath的遍历：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; divs = response.xpath(<span class="string">&#x27;//div&#x27;</span>)&gt;&gt;&gt; <span class="keyword">for</span> p <span class="keyword">in</span> divs.xpath(<span class="string">&#x27;//p&#x27;</span>):  <span class="comment"># this is wrong - gets all &lt;p&gt; from the whole document    print(p.get())    &gt;&gt;&gt; for p in divs.xpath(&#x27;.//p&#x27;):  # extracts all &lt;p&gt; inside    print(p.get())</span></span>    </span><br></pre></td></tr></table></figure>

<p>xpath中使用变量 $：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; response.xpath(<span class="string">&#x27;//div[@id=$val]/a/text()&#x27;</span>, val=<span class="string">&#x27;images&#x27;</span>).get()<span class="string">&#x27;Name: My image 1 &#x27;</span></span></span><br></pre></td></tr></table></figure>



<h2 id="即将遇到的问题"><a href="#即将遇到的问题" class="headerlink" title="即将遇到的问题"></a>即将遇到的问题</h2><p>json数据；xhr请求；jd的翻页；</p>
<p>item type: Dataclass object</p>
<p>monodb</p>
<h2 id="Settings¶"><a href="#Settings¶" class="headerlink" title="Settings¶"></a>Settings<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#settings">¶</a></h2><p>These are the settings used for configuring the feed exports:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEEDS"><code>FEEDS</code></a> (mandatory)</li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_ENCODING"><code>FEED_EXPORT_ENCODING</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_STORE_EMPTY"><code>FEED_STORE_EMPTY</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_FIELDS"><code>FEED_EXPORT_FIELDS</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_INDENT"><code>FEED_EXPORT_INDENT</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_STORAGES"><code>FEED_STORAGES</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_STORAGE_FTP_ACTIVE"><code>FEED_STORAGE_FTP_ACTIVE</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_STORAGE_S3_ACL"><code>FEED_STORAGE_S3_ACL</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORTERS"><code>FEED_EXPORTERS</code></a></li>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_BATCH_ITEM_COUNT"><code>FEED_EXPORT_BATCH_ITEM_COUNT</code></a></li>
</ul>
<p>Json 请求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;    <span class="string">&#x27;name1&#x27;</span>: <span class="string">&#x27;value1&#x27;</span>,    <span class="string">&#x27;name2&#x27;</span>: <span class="string">&#x27;value2&#x27;</span>,&#125;<span class="keyword">yield</span> JsonRequest(url=<span class="string">&#x27;http://www.example.com/post/action&#x27;</span>, data=data)</span><br></pre></td></tr></table></figure>

<h2 id="避免被禁止¶"><a href="#避免被禁止¶" class="headerlink" title="避免被禁止¶"></a>避免被禁止<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/practices.html#avoiding-getting-banned">¶</a></h2><p>一些网站实施了某些措施来防止机器人抓取它们，但其复杂程度各不相同。绕过这些措施可能既困难又棘手，有时可能需要特殊的基础设施。如果有疑问，请考虑联系<a target="_blank" rel="noopener" href="https://scrapy.org/support/">商业支持</a>。</p>
<p>在处理这些类型的网站时，请牢记以下提示：</p>
<ul>
<li>从浏览器中的一组知名用户代理中轮换您的用户代理（谷歌以获取它们的列表）</li>
<li>禁用 cookie（请参阅<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED"><code>COOKIES_ENABLED</code></a>），因为某些站点可能会使用 cookie 来发现机器人行为</li>
<li>使用下载延迟（2 或更高）。见<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/settings.html#std-setting-DOWNLOAD_DELAY"><code>DOWNLOAD_DELAY</code></a>设置。</li>
<li>如果可能，请使用<a target="_blank" rel="noopener" href="http://www.googleguide.com/cached_pages.html">Google 缓存</a>来获取页面，而不是直接访问网站</li>
<li>使用轮换 IP 池。例如，免费的<a target="_blank" rel="noopener" href="https://www.torproject.org/">Tor 项目</a>或<a target="_blank" rel="noopener" href="https://proxymesh.com/">ProxyMesh 之</a>类的付费服务。一个开源替代方案是<a target="_blank" rel="noopener" href="https://scrapoxy.io/">scrapoxy</a>，一个超级代理，您可以将自己的代理附加到。</li>
<li>使用高度分布式的下载器来绕过内部禁令，因此您可以专注于解析干净的页面。此类下载程序的一个示例是 <a target="_blank" rel="noopener" href="https://www.zyte.com/smart-proxy-manager/">Zyte 智能代理管理器</a></li>
</ul>
<p>如果您仍然无法防止您的机器人被禁止，请考虑联系 <a target="_blank" rel="noopener" href="https://scrapy.org/support/">商业支持</a>。</p>
<p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/contracts.html"> 以前的</a><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/broad-crawls.html">下一个 </a></p>
<p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/deploy.html">https://docs.scrapy.org/en/latest/topics/deploy.html</a></p>
<h2 id="安装-mongoDB"><a href="#安装-mongoDB" class="headerlink" title="安装 mongoDB"></a>安装 mongoDB</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name spider_mongo -d -p 27017:27017 -e MONGO_INITDB_ROOT_USERNAME=root -e MONGO_INITDB_ROOT_PASSWORD=123456 mongo</span><br></pre></td></tr></table></figure>

<p><strong>如何访问settings</strong>: <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/settings.html">https://docs.scrapy.org/en/latest/topics/settings.html</a></p>
<p>在 Spider 中，通过 self.settings 即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span>(<span class="params">scrapy.Spider</span>):</span>    name = <span class="string">&#x27;myspider&#x27;</span>    start_urls = [<span class="string">&#x27;http://example.com&#x27;</span>]    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span>        print(<span class="string">f&quot;Existing settings: <span class="subst">&#123;self.settings.attributes.keys()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>在 middlewares 或 item pipelines 中，使用<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/api.html#scrapy.crawler.Crawler.settings"><code>scrapy.crawler.Crawler.settings</code></a>的 <code>from_crawler</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyExtension</span>:</span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, log_is_enabled=<span class="literal">False</span></span>):</span>        <span class="keyword">if</span> log_is_enabled:            print(<span class="string">&quot;log is enabled!&quot;</span>)    @<span class="built_in">classmethod</span>    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span>        settings = crawler.settings        <span class="keyword">return</span> cls(settings.getbool(<span class="string">&#x27;LOG_ENABLED&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>连接池+浏览器user-agent</p>
<p><code>response.follow/follow_all</code>方法不是简单的字符串拼接，而是通过下一页标签的href属性值自动拼接下一页的url。因此，<strong>没有href属性则无法使用follow方法</strong>。</p>
<p>自定义随机 user-agent：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleware</span>:</span>    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span>        ua = UserAgent() <span class="comment"># fake-useragent 库        request.headers[&#x27;user-agent&#x27;] = ua.random</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;    <span class="string">&#x27;myproject.middlewares.CustomDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,    <span class="string">&#x27;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#x27;</span>: <span class="literal">None</span>,&#125;</span><br></pre></td></tr></table></figure>

<p>代理(以阿布云为例)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AbuyunProxyMiddleware</span>:</span>  	<span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span>      	request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http-cla.abuyun.com:9030&#x27;</span>        proxy_name_pass = <span class="string">b&#x27;name:pass&#x27;</span>        encode_pass_name = base64.b64encode(proxy_name_pass)        request.headers[<span class="string">&#x27;Proxy-Authorization&#x27;</span>] = <span class="string">&#x27;Basic&#x27;</span> + encode_pass_name.decode()</span><br></pre></td></tr></table></figure>











</div><div class="article-licensing box"><div class="licensing-title"><p>scrapy_tutorial</p><p><a href="https://teamwang.cn/2021/11/24/scrapy-tutorial/">https://teamwang.cn/2021/11/24/scrapy-tutorial/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Jacky</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-11-24</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-11-24</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/11/24/MongoDB%E5%92%8CRedis%E7%9A%84%E5%8C%BA%E5%88%AB/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">MongoDB和Redis的区别</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/11/24/python-grammar/"><span class="level-item">python_grammar</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "D7nrmJ3xSHla6mxR3p0BrXqD-gzGzoHsz",
            appKey: "rGXO6glIn8ETvzytN7maFaoP",
            placeholder: "Leave your comments~",
            
            
            meta: ["nick"],
            pageSize: 10,
            lang: "en",
            visitor: true,
            highlight: true,
            
            
            
            
            enableQQ: true,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Scrapy-Tutorial"><span class="level-left"><span class="level-item">Scrapy Tutorial</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#概述"><span class="level-left"><span class="level-item">概述</span></span></a></li><li><a class="level is-mobile" href="#快速开始"><span class="level-left"><span class="level-item">快速开始</span></span></a></li><li><a class="level is-mobile" href="#即将遇到的问题"><span class="level-left"><span class="level-item">即将遇到的问题</span></span></a></li><li><a class="level is-mobile" href="#Settings¶"><span class="level-left"><span class="level-item">Settings</span></span></a></li><li><a class="level is-mobile" href="#避免被禁止¶"><span class="level-left"><span class="level-item">避免被禁止</span></span></a></li><li><a class="level is-mobile" href="#安装-mongoDB"><span class="level-left"><span class="level-item">安装 mongoDB</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Jacky"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jacky</p><p class="is-size-6 is-block">(ง ˙o˙)ว</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">36</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">1</p></a></div></div></nav><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/cloris-cc"><i class="fab fa-github"></i></a></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><span>&copy; 2021 Jacky</span>  <a href="https://beian.miit.gov.cn/" target="_blank">粤ICP备19098392号</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/"><i class="fab fa-weibo"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/cloris-cc"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>