{"pages":[{"title":"关于我 &#x2F; About me","text":"简介 / IntroHi 我是该网站的维护人 Jacky。 一个喜欢听 Rap、玩游戏、敲代码的老透明 也是王嘉尔(Jackson Wang) 的粉丝；ow 养老玩家；茶茶的小海豚； Hi I’m jacky, the maintainer of this website. An obscure person who likes to listen to Rap, play games, and program. Meanwhile, I’m also a fan of Jackson Wang, OverWatch player, and little dolphin of TeaTea ^ ^ 联系 / ContactEmail: jacky.teamwang@qq.com / clorisforcoding@gmail.com Twitter: Anonymous sry 也可以在下方留言喔～ Welcome to leave your message~ 链接 / LinksMy Github: 这里有我写的许多 hello world 级别的项目。 My LeetCode: 平时有空刷算法的地方。偶尔参加比赛但始终保持千名开外 😅","link":"/about.html"}],"posts":[{"title":"Java并发编程","text":"并发编程基础相关的内容… Immutable of Guava 的实现原理，就是在实现的方法中抛出异常。 线程封闭的方法：使用 ThreadLocal 线程不安全的写法：if(condition(a)) { handle(a); },可以使用 volatile boolean 来做标记 + while 语句 final Object mutex; // Object on which to synchronize 同步容器不一定能做到线程安全。应使用并发容器。 1. 线程安全性1.1 原子性 互斥访问，即同一时刻只能有一个线程对它操作。 若多个线程同时对int变量increase操作，可能会因为主内存变量不是最新值(这是可见性问题)同时执行(违背原子性)而不能达到预计结果。 AtomicInteger 原理：AtomicInteger 的原理是依靠底层的 CAS 来保障原子性的更新数据，在要添加或者减少的时候，会使用死循环不断地 CAS 到特定的值，从而达到更新数据的目的。CAS 的 ABA 问题通过 Version Stamp 解决。 12// setup to use Unsafe.compareAndSwapInt&lt;CAS&gt; for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe(); 123456789101112131415161718192021222324252627public class AtomicMain { // static 类变量 static int sum = 0;// static AtomicInteger sum = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException { CountDownLatch latch = new CountDownLatch(2); ExecutorService service = Executors.newFixedThreadPool(2); service.execute(() -&gt; { for (int i = 0; i &lt; 5000; i++) { sum++; } latch.countDown(); }); service.execute(() -&gt; { for (int i = 0; i &lt; 5000; i++) { sum++; } latch.countDown(); }); latch.await(); System.out.println(&quot;======&gt;结果：&quot; + sum); // 随机且小于等于10000 }} LongAdder 和 AtomicLong 的区别 LongAdder(jdk1.8) 在 AtomicLong(jdk1.5) 的基础上将单点的更新压力分散到各个节点，性能更好。 下面为 LongAdder 的部分源码： 123456789101112131415/** * Adds the given value. * * @param x the value to add */public void add(long x) { Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) { boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); }} 对比 AtomicInteger 的实现： 12345678public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;} AtomicReference AtomicStampedReference 相比该类多了一个 stamp. 对比synchronized synchronized 不属于方法声明的一部分。 synchronized 不可中断，直到执行完代码。Lock 通过 unlock 方法中断。 synchronized 适合竞争不激烈的场景。 Atomic 比 Lock 性能好，但是只能同步一个值。 1.2 可见性 一个线程对主内存的修改可以及时地被其它线程观察到。 导致共享变量在线程间不可见的原因：1. 线程交叉执行。 2. 指令重排。 3. 值更新后没有在工作内存和主内存中及时更新。 synchronized JMM 关于 synchronized 的两条规定： 线程解锁前，必须把共享变量的最新值刷新到主内存。 线程加锁时，将清空工作内存中共享变量的值，让共享变量的值使用主内存中的数据。（加锁和解锁是同一把锁） volatile 可见性的实现原理：通过加入内存屏障和禁止重排序来实现可见性。 对 volatile 变量写操作时，会在最后加入一条 store 屏障指令，将本地工作内存中的共享变量刷新到主内存。 对 volatile 变量读操作时，会在前面加入一条 load 屏障指令，使其从主内存中读取共享变量。 Tips: 下面为一个 atomic 实现的计数器，若换成 volatile，则无法保证线程安全。因为在执行count++;操作时，虽然会先从主内存取出最新值，但是有可能**多个线程(即无原子性)**执行了+1的操作。因此，即便是保证了可见性(即变量是最新值)，也会由于原子性的问题而无法保证线程安全。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * @author Jacky * Date: 2019/1/4 * Time: 0:26 */@Slf4j@ThreadSafepublic class CountExample1 { private static final int REQUESTS_TOTAL = 5000; private static final int THREADS = 200; // public static final int INIT_THREADS = 50; private static AtomicInteger counts = new AtomicInteger(0); private static void add() { counts.incrementAndGet(); } public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(THREADS); final CountDownLatch countDownLatch = new CountDownLatch(REQUESTS_TOTAL); for (int i = 0; i &lt; REQUESTS_TOTAL; i++) { executorService.execute(() -&gt; { try { semaphore.acquire(); add(); semaphore.release(); } catch (Exception e) { log.error(&quot;exception&quot;, e); } countDownLatch.countDown(); }); } try { countDownLatch.await(); } catch (InterruptedException e) { log.error(&quot;exception&quot;, e); } executorService.shutdown(); log.info(&quot;counts:{}&quot;, counts.get()); }} 1.3 有序性 一个线程观察到其它线程中的指令执行顺序。由于指令重排的存在，该观察结果一般杂乱无序。 2. 同步 &amp; 并发容器 (JUC)参照《Java基础知识》容器章节。 3. 线程池3.1 基础线程池ThreadPoolExecutor的核心参数及结构： core =&gt; queue =&gt; max =&gt; handler 核心线程数不足，无法处理的任务会被放到等待队列中；当等待队列也排满了后，就会启动更多的线程(最大线程数)来处理任务；当最大线程数也不够处理时，就会执行拒绝策略；超出coreSize的线程，称为空闲线程。 ThreadPoolExecutor 线程池的5种状态： 另外，Executors创建的线程池均是使用ThreadPoolExecutor创建的 基本方法介绍： execte(): 提交任务 submit(): 提交任务，有返回值。相当于 execute + future shutdown(): 关闭线程池，但是会等待任务都执行完再关闭 shutdownNow(): 关闭线程池，不等待任务执行完，直接停止执行任务的线程 3.2 Executors 类 示例 先创建任务，即实现 runnable/callable 接口。 123456public class OrderTask implements Callable&lt;String&gt; { @Override public String call() { return &quot;hello world&quot;; }} 接着也可以用FutureTask接收，实现更多功能如取消任务，判断任务结束等等。FutureTask是Future唯一的实现类。 提交(submit)任务到线程池 12345678910111213141516/** * 每次执行3个任务 */public class ThreadPoolExample { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService threadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) { // foreach concrete business Future&lt;String&gt; submit = threadPool.submit(new OrderTask()); System.out.println(submit.get()); } System.out.println(&quot;10 tasks have been dispatched successfully.&quot;); threadPool.shutdown(); }} 3.2 线程池拒绝策略 All implement the RejectedExecutionHandler. CallerRunsPolicy: A handler for rejected tasks that runs the rejected task directly in the calling thread of the execute method, unless the executor has been shut down, in which case the task is discarded.(调用线程处理) AbortPolicy(default): A handler for rejected tasks that throws a RejectedExecutionException.(丢弃并抛出异常) DiscardPolicy: A handler for rejected tasks that silently discards the rejected task.(直接丢弃) DiscardOldestPolicy: A handler for rejected tasks that discards the oldest unhandled request and then retries execute, unless the executor is shut down, in which case the task is discarded.(丢弃旧任务再尝试重新执行) 4. HashMap4.1 数据结构ConcurrentHashMap数组 + 链表，链表在发生hash冲突时形成。如下图： 注意，当链表长度大于等于 8 时，会转化成红黑树结构。寻址的时间复杂度从 O(n) 降为 O(logn) 4.2 初始容量和负载因子123static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final float DEFAULT_LOAD_FACTOR = 0.75f; // 在保证了空间利用率的同时，减少Hash冲突 4.3 HashMap 的扩容扩容 2 倍，保证容量是 2^n。减少了hash冲突。 下图为单线程的扩容： 5. 多线程并发与线程安全总结","link":"/2021/03/01/Concurrency%E5%B9%B6%E5%8F%91/"},{"title":"Hexo博客网站搭建","text":"1. 自言自语花了好几天的时候，从技术框架筛选再到样式调整、配置修改、项目部署等等。上线后也花了许多时间精力增加功能。 由于之前有尝试过从零开始搭建个人博客 (前后端一起写，后端用Springboot，前端是 bootstrap + jquery)，单前端来讲，写个分页的js加上调试就够我花大半天时间了T T 毕竟自己的前端都是临时抱佛脚学的！！加上现在已经 2021 年了，也不会有人重复写这些市面上已经有而且很成熟的组件了吧 (虽然真的有但是是少部分) = = 写着写着感觉变成日记了… 2. 技术框架网上相关的教程其实已经很多了，就大概说一下主要用到的技术叭。 首先是静态博客框架 Hexo，主题采用 Icarus。 另外关于 wordpress, vuepress, halo, jpress 等博客框架的对比在网上已经有许多文章了。由于最初的想法是自己写后端，再用动态博客框架，所以尝试了基于 Java 的 Halo 框架。但后来想到写博客的初衷或者说是重点应该是基于创作内容的质量上，而不是网站有多少功能或者多酷(当然啦也希望自己的网站酷一点)。故采用了相对方便且简洁的 Hexo。 回到正题！！！经历千辛万苦配置好网站后，再部署在 github pages 上 (不要问为什么要挂在国外的服务器上，因为不舍得买服务器了！！)，然后用自己购买的域名CNAME 到 github pages 默认的域名 yourname.github.io 用到的插件：valine(评论功能)、valine-admin(评论通知及数据管理)、sharethis(文章分享功能)、不蒜子(访客统计)、百度统计(用于数据分析)、google Adsense(网站的广告位)、hexo-renderer-marked(文章图片渲染)、hexo-deployer-git(一键部署) 素材：阿里巴巴矢量图标库 3. 说在最后由于之前除了写技术笔记外，基本没写过任何东西。所以就当作小学生写作文一样看看别在意！！ “行动比说话更有信服力。”（其实就是对自己说的 T T ） 4. 相关文档 https://hexo.io Icarus快速上手 - Icarus","link":"/2021/02/25/Hexo%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"},{"title":"MacApp推荐","text":"MacApp推荐 鼠标： sensible-side-buttons: 解决鼠标在mac上前进、后退侧键不可用。 steelseries-exactmouse-tool: 移除mac上的鼠标加速度 系统： avast: 杀毒软件 一键发布： openwrite","link":"/2021/03/07/MacApp%E6%8E%A8%E8%8D%90/"},{"title":"RabbitMQ Adv","text":"Github Project: Private Repo","link":"/2021/04/09/RabbitMQ-Adv/"},{"title":"","text":"偶然看到一个音乐纪录片，是和马思唯的新专辑《黑马》中的一首歌《东大街》有关。虽然之前就听过这首歌了但是没有什么特别的情感（也和自己对新专辑的期待比较高有关吧）现在看完还是有许多说不上来的感慨 TT","link":"/2021/02/26/210226/"},{"title":"Redis6.0之多线程","text":"下午太困了就在网上随便看看文章。 文章链接：Redis6.0之多线程 个人总结： 单线程Redis指的是在处理请求的过程中使用单线程，而其它模块仍会使用多线程。 而redis6.0引入的多线程是在处理请求的网络IO部分，处理请求的其它流程如Redis命令执行，依然使用单线程操作。","link":"/2021/04/02/Redis6-0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"RocketMQ和RabbitMQ的区别","text":"虽然都使用过这两种消息队列，不过还是写个简单的summary吧。 概览：两者均开源，由于rabbitmq更早开源以及纳入SpringCloud体系，故用户量更多(docker-hub更为明显，但是rocketmq在github上更受欢迎)。rocketmq优势主要体现在性能。 这里是一个从网上看到的性能对比，所以仅供参考：Kafka吞吐量17.3w/s，rocketmq吞吐量11.6w/s，rabbitmq吞吐量5.95w/s。 业务功能： 功能 RocketMQ RabbitMQ 顺序消息 支持 不支持 全链路消息轨迹 支持 不支持 消息堆积能力 不影响性能 影响性能 消息回溯 支持 不支持 其它一些功能细节差异： 失败重试：rabbitmq默认失败一直重试，可设置重试次数和重试间隔，而rocketmq默认重试2次，间隔根据messageDelayLevel递增。 两者达到重试次数上限，均会自动ack消息，再把消息投递到死信队列DLQ(deadline queue)(rabbitmq不会自动到DLQ)。rocketmq保存DLQ的消息3天，因为所有消息3天不消费均会被删除。 通常建议当重试次数达到上限后，(Consumer端)回滚事务并保存错误日志(尽量不要使用手动ack消息)。若是因为消息发送失败而触发重试，则要根据SendResult的SendState状态来做处理。其中，rocketmq可通过MessageExt获取重试次数，而rabbitmq需要自行实现（如使用redis，消息的主键如orderId/messageId做key，消费次数做val）。 另外，要注意如果在消息消费使用了try/catch或全局异常处理异常，会导致rocketmq获取不到异常导致触发不了重试机制。 最后，相较Kafka这两款消息组件虽然性能不及它，但由于是面向具体业务而生的(Kafka面向数据/日志)，所以不管是消息可靠性上还是功能上更具优势。 一些概念上的对应关系：","link":"/2021/04/02/RocketMQ%E5%92%8CRabbitMQ%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"ShardingSphere","text":"ShardingSphere ShardingSphere 1. 概念 &amp; 功能1.1 数据分片 数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。 垂直分片 按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用。 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。 下图展示了根据业务需要，将用户表和订单表垂直分片到不同的数据库的方案。(即分库) 垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。 水平分片 水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入0库（或表），奇数主键的记录放入1库（或表），如下图所示。(即分表分库) 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。 Challenge：数据查询&amp;聚合&amp;分组、分页、排序、分布式事务(基于XA的分布式事务(MYCAT)由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务) 分片相关概念 逻辑表(logic table)：t_order 真实表(actual table)：t_order_0到t_order_9 数据节点(data node)：数据分片的最小单元。由数据源名称和数据表组成，例：ds_0.t_order_0。 绑定表(binding table) 广播表是什么…. 分片键：用于数据库分片的(1个或多个)字段。 SQL中如果无分片字段，将执行全路由，性能较差。 分片算法 分片策略（分片键 + 分片算法） SQL Hint对于分片字段非SQL决定，而由其他外置条件决定的场景，可使用SQL Hint灵活的注入分片字段。例：内部系统，按照员工登录主键分库，而数据库中并无此字段。SQL Hint支持通过Java API和SQL注释(待实现)两种方式使用。 分片策略配置 自增主键生成策略通过在客户端生成自增主键替换以数据库原生自增主键的方式，做到分布式主键无重复。 1.2 内部执行流程 ShardingSphere的3个产品的数据分片主要流程是完全一致的。 核心由SQL解析 =&gt; 执行器优化 =&gt; SQL路由 =&gt; SQL改写 =&gt; SQL执行 =&gt; 结果归并的流程组成。 解析引擎(Parse Engine)解析过程分为词法解析和语法解析。 词法解析：将SQL拆解为不可再分的原子符号，称为Token（绿色）。语法解析：将SQL转换为抽象语法树。 1SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age &gt; 18 路由引擎(Route Engine)改写引擎(Rewrite Engine)执行引擎(Execute Engine)归并引擎(Merger Engine)1.3 注意事项 不支持跨库关联查询 不支持CASE WHEN、HAVING、UNION (ALL)，有限支持子查询（由于归并的限制，子查询中包含聚合函数目前无法支持。） 运算表达式和函数中的分片键（sharding column）会导致全路由。 2. sharding-jdbc 介绍2.1 运行流程 2.2 功能特性数据分片 分库 &amp; 分表 读写分离 分片策略定制化 无中心化分布式主键 分布式事务 标准化事务接口 XA强一致事务 柔性事务 数据库治理 配置动态化 编排 &amp; 治理 数据脱敏 可视化链路追踪 弹性伸缩(规划中) 不支持的功能（即缺点） https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/unsupported-items/ 面临问题 越获取偏移量位置靠后数据，使用LIMIT分页方式的效率就越低。 有很多方法可以避免使用LIMIT进行分页。比如构建行记录数量与行偏移量的二级索引，或使用上次分页数据结尾ID作为下次查询条件的分页方式等。 若id为uuid等无序字符，则考虑使用时间范围查询。不然就没办法啦。 ShardingSphere进行了2个方面的优化。 首先，采用流式处理 + 归并排序的方式来避免内存的过量占用。由于SQL改写不可避免的占用了额外的带宽，但并不会导致内存暴涨。 与直觉不同，大多数人认为ShardingSphere会将1,000,010 * 2记录全部加载至内存，进而占用大量内存而导致内存溢出。 但由于每个结果集的记录是有序的，因此ShardingSphere每次比较仅获取各个分片的当前结果集记录，驻留在内存中的记录仅为当前路由到的分片的结果集的当前游标指向而已。 对于本身即有序的待排序对象，归并排序的时间复杂度仅为O(n)，性能损耗很小。 其次，ShardingSphere对仅落至单分片的查询进行进一步优化。 落至单分片查询的请求并不需要改写SQL也可以保证记录的正确性，因此在此种情况下，ShardingSphere并未进行SQL改写，从而达到节省带宽的目的。 PageHelper 是怎么解决的？ 没有解决，也是通过 limit 拼接 SQL 来实现分页功能的。 可以通过查询主键再联表解决。 123456select * from user where age = 10 limit 100000,10;&lt;!-- 改写成 --&gt;SELECT a.* FROM USER aINNER JOIN (SELECT id FROM USER WHERE age = 10 LIMIT 100000,10) b ON a.id = b.id; 3. 快速开始3.1 配置介绍数据分片 (Data Sharding)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667spring: shardingsphere: datasource: &lt;data-source-name&gt;: driver-class-name: '#数据库驱动类名' password: '#数据库密码' type: '#数据库连接池类名称' url: '#数据库url连接' username: '#数据库用户名' xxx: '#数据库连接池的其它属性' names: '#数据源名称，多数据源以逗号分隔' props: executor: size: '#工作线程数量，默认值: CPU核数' sql: show: '#是否开启SQL显示，默认值: false' sharding: binding-tables: - '#绑定表规则列表' - '#绑定表规则列表' binding-tables[x]: '#绑定表规则列表' broadcast-tables: - '#广播表规则列表' - '#广播表规则列表' broadcast-tables[x]: '#广播表规则列表' default-data-source-name: '#未配置分片规则的表将通过默认数据源定位' default-database-strategy: xxx: '#默认数据库分片策略，同分库策略' default-key-generator: props: &lt;property-name&gt;: '#自增列值生成器属性配置, 比如SNOWFLAKE算法的worker.id与max.tolerate.time.difference.milliseconds' type: '#默认自增列值生成器类型，缺省将使用org.apache.shardingsphere.core.keygen.generator.impl.SnowflakeKeyGenerator。可使用用户自定义的列值生成器或选择内置类型：SNOWFLAKE/UUID' default-table-strategy: xxx: '#默认表分片策略，同分表策略' master-slave-rules: &lt;master-slave-data-source-name&gt;: load-balance-algorithm-class-name: '#详见读写分离部分' load-balance-algorithm-type: '#详见读写分离部分' master-data-source-name: '#详见读写分离部分' slave-data-source-names: - '#详见读写分离部分' - '#详见读写分离部分' slave-data-source-names[x]: '#详见读写分离部分' tables: &lt;logic-table-name&gt;: actual-data-nodes: '#由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持inline表达式。缺省表示使用已知数据源与逻辑表名称生成数据节点，用于广播表（即每个库中都需要一个同样的表用于关联查询，多为字典表）或只分库不分表且所有库的表结构完全一致的情况' database-strategy: complex: algorithm-class-name: '#复合分片算法类名称。该类需实现ComplexKeysShardingAlgorithm接口并提供无参数的构造器' sharding-columns: '#分片列名称，多个列以逗号分隔' hint: algorithm-class-name: '#Hint分片算法类名称。该类需实现HintShardingAlgorithm接口并提供无参数的构造器' inline: algorithm-expression: '#分片算法行表达式，需符合groovy语法' sharding-column: '#分片列名称' standard: precise-algorithm-class-name: '#精确分片算法类名称，用于=和IN。该类需实现PreciseShardingAlgorithm接口并提供无参数的构造器' range-algorithm-class-name: '#范围分片算法类名称，用于BETWEEN，可选。该类需实现RangeShardingAlgorithm接口并提供无参数的构造器' sharding-column: '#分片列名称' key-generator: column: '#自增列名称，缺省表示不使用自增主键生成器' props: &lt;property-name&gt;: '#属性配置, 注意：使用SNOWFLAKE算法，需要配置worker.id与max.tolerate.time.difference.milliseconds属性。若使用此算法生成值作分片值，建议配置max.vibration.offset属性' type: '#自增列值生成器类型，缺省表示使用默认自增列值生成器。可使用用户自定义的列值生成器或选择内置类型：SNOWFLAKE/UUID' table-strategy: xxx: '#省略' 读写分离 (Read-Write Split)支持： 提供一主多从的读写分离配置，可独立使用，也可配合分库分表使用。 独立使用读写分离支持SQL透传。 同一线程且同一数据库连接内，如有写入操作，以后的读操作均从主库读取，用于保证数据一致性。 基于Hint的强制主库路由。 不支持： 主库和从库的数据同步。 主库和从库的数据同步延迟导致的数据不一致。 主库双写或多写。 跨主库和从库之间的事务的数据不一致。主从模型中，事务中读写均用主库。 12345678910111213141516171819202122spring: shardingsphere: props: check: table: metadata: enabled: '#是否在启动时检查分表元数据一致性，默认值: false' executor: size: '#工作线程数量，默认值: CPU核数' sql: show: '#是否开启SQL显示，默认值: false' sharding: master-slave-rules: &lt;master-slave-data-source-name&gt;: load-balance-algorithm-class-name: '#从库负载均衡算法类名称。该类需实现MasterSlaveLoadBalanceAlgorithm接口且提供无参数构造器' load-balance-algorithm-type: '#从库负载均衡算法类型，可选值：ROUND_ROBIN，RANDOM。若`load-balance-algorithm-class-name`存在则忽略该配置' master-data-source-name: '#主库数据源名称' slave-data-source-names: - '#从库数据源名称列表' - '#从库数据源名称列表' slave-data-source-names[x]: '#从库数据源名称列表' 数据脱敏 (Data Masking)1234567891011121314151617spring: shardingsphere: encrypt: encryptors: &lt;encryptor-name&gt;: props: &lt;property-name&gt;: '#属性配置, 注意：使用AES加密器，需要配置AES加密器的KEY属性：aes.key.value' type: '#加解密器类型，可自定义或选择内置类型：MD5/AES ' tables: &lt;table-name&gt;: columns: &lt;logic-column-name&gt;: assistedQueryColumn: '#辅助查询字段，针对ShardingQueryAssistedEncryptor类型的加解密器进行辅助查询' cipherColumn: '#存储密文的字段' encryptor: '#加密器名字' plainColumn: '#存储明文的字段' 治理 (Orchestration)12345678910111213141516spring: shardingsphere: orchestration: name: '#治理实例名称' overwrite: '#本地配置是否覆盖注册中心配置。如果可覆盖，每次启动都以本地配置为准' registry: digest: '#连接注册中心的权限令牌。缺省为不需要权限验证' max-retries: '#连接失败后的最大重试次数，默认3次' namespace: '#注册中心的命名空间' operation-timeout-milliseconds: '#操作超时的毫秒数，默认500毫秒' props: '#配置中心其它属性' retry-interval-milliseconds: '#重试间隔毫秒数，默认500毫秒' server-lists: '#连接注册中心服务器的列表。包括IP地址和端口号。多个地址用逗号分隔。如: host1:2181,host2:2181' time-to-live-seconds: '#临时节点存活秒数，默认60秒' type: '#配置中心类型。如：zookeeper' 3.2 代码示例 创建 DataSource：通过ShardingDataSourceFactory工厂和规则配置对象获取ShardingDataSource，ShardingDataSource实现自JDBC的标准接口DataSource。然后即可通过DataSource选择使用原生JDBC开发，或者使用JPA, MyBatis等ORM工具。 使用 MyBatis使用 JPA","link":"/2021/03/14/ShardingSphere/"},{"title":"Spring Cloud 快速集成 Seata","text":"Spring Cloud 快速集成 Seata 1. 添加依赖添加Spring Cloud Alibaba 依赖管理工具和 Seata 依赖 Gradle 12345dependencyManagement { imports { mavenBom &quot;com.alibaba.cloud:spring-cloud-alibaba-dependencies:2.1.0.RELEASE&quot; }} 123dependencies { compile('com.alibaba.cloud:spring-cloud-starter-alibaba-seata')} Maven 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt; 需要注意的是Spring Cloud Alibaba 的毕业版本的 GroupId 是 com.alibaba.cloud spring-cloud-starter-alibaba-seata这个依赖中只依赖了spring-cloud-alibaba-seata，所以在项目中添加spring-cloud-starter-alibaba-seata和spring-cloud-alibaba-seata是一样的 2. 添加Seata 配置文件registry.conf该配置用于指定 TC 的注册中心和配置文件，默认都是 file; 如果使用其他的注册中心，要求 Seata-Server 也注册到该配置中心上 registry.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;file&quot; nacos { serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; } eureka { serviceUrl = &quot;http://localhost:8761/eureka&quot; application = &quot;default&quot; weight = &quot;1&quot; } redis { serverAddr = &quot;localhost:6379&quot; db = &quot;0&quot; } zk { cluster = &quot;default&quot; serverAddr = &quot;127.0.0.1:2181&quot; session.timeout = 6000 connect.timeout = 2000 } consul { cluster = &quot;default&quot; serverAddr = &quot;127.0.0.1:8500&quot; } etcd3 { cluster = &quot;default&quot; serverAddr = &quot;http://localhost:2379&quot; } sofa { serverAddr = &quot;127.0.0.1:9603&quot; application = &quot;default&quot; region = &quot;DEFAULT_ZONE&quot; datacenter = &quot;DefaultDataCenter&quot; cluster = &quot;default&quot; group = &quot;SEATA_GROUP&quot; addressWaitTime = &quot;3000&quot; } file { name = &quot;file.conf&quot; }}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;file&quot; nacos { serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; } consul { serverAddr = &quot;127.0.0.1:8500&quot; } apollo { app.id = &quot;seata-server&quot; apollo.meta = &quot;http://192.168.1.204:8801&quot; } zk { serverAddr = &quot;127.0.0.1:2181&quot; session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = &quot;http://localhost:2379&quot; } file { name = &quot;file.conf&quot; }} file.conf该配置用于指定TC的相关属性；如果使用注册中心也可以将配置添加到配置中心 file.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121transport { # tcp udt unix-domain-socket type = &quot;TCP&quot; #NIO NATIVE server = &quot;NIO&quot; #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = &quot;NettyBoss&quot; worker-thread-prefix = &quot;NettyServerNIOWorker&quot; server-executor-thread-prefix = &quot;NettyServerBizHandler&quot; share-boss-worker = false client-selector-thread-prefix = &quot;NettyClientSelector&quot; client-selector-thread-size = 1 client-worker-thread-prefix = &quot;NettyClientWorkerThread&quot; # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = &quot;seata&quot; compressor = &quot;none&quot;}service { #vgroup-&gt;rgroup vgroup_mapping.my_test_tx_group = &quot;default&quot; #only support single node default.grouplist = &quot;127.0.0.1:8091&quot; #degrade current not support enableDegrade = false #disable disable = false #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent max.commit.retry.timeout = &quot;-1&quot; max.rollback.retry.timeout = &quot;-1&quot;}client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5}## transaction log storestore { ## store mode: file、db mode = &quot;file&quot; ## file store file { dir = &quot;sessionStore&quot; # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = &quot;dbcp&quot; ## mysql/oracle/h2/oceanbase etc. db-type = &quot;mysql&quot; url = &quot;jdbc:mysql://127.0.0.1:3306/seata&quot; user = &quot;mysql&quot; password = &quot;mysql&quot; min-conn = 1 max-conn = 3 global.table = &quot;global_table&quot; branch.table = &quot;branch_table&quot; lock-table = &quot;lock_table&quot; query-limit = 100 }}lock { ## the lock store mode: local、remote mode = &quot;remote&quot; local { ## store locks in user's database } remote { ## store locks in the seata's server }}recovery { committing-retry-delay = 30 asyn-committing-retry-delay = 30 rollbacking-retry-delay = 30 timeout-retry-delay = 30}transaction { undo.data.validation = true undo.log.serialization = &quot;jackson&quot;}## metrics settingsmetrics { enabled = false registry-type = &quot;compact&quot; # multi exporters use comma divided exporter-list = &quot;prometheus&quot; exporter-prometheus-port = 9898} 需要注意的是 service.vgroup_mapping这个配置，在 Spring Cloud 中默认是${spring.application.name}-fescar-service-group，可以通过指定application.properties的 spring.cloud.alibaba.seata.tx-service-group这个属性覆盖，但是必须要和 file.conf 中的一致，否则会提示 no available server to connect 3. 注入数据源Seata 通过代理数据源的方式实现分支事务；MyBatis 和 JPA 都需要注入 io.seata.rm.datasource.DataSourceProxy, 不同的是，MyBatis 还需要额外注入 org.apache.ibatis.session.SqlSessionFactory MyBatis 123456789101112131415161718192021@Configurationpublic class DataSourceProxyConfig { @Bean @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) public DataSource dataSource() { return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); return sqlSessionFactoryBean.getObject(); }} JPA 12345678910111213141516@Configurationpublic class DataSourceProxyConfig { @Bean @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) public DruidDataSource druidDataSource() { return new DruidDataSource(); } @Primary @Bean public DataSourceProxy dataSource(DruidDataSource druidDataSource) { return new DataSourceProxy(druidDataSource); }} 如果使用的是 Hikari 数据源，需要修改数据源的配置，以及注入的 Bean 的配置前缀 1234spring.datasource.hikari.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.hikari.jdbc-url=jdbc:mysql://localhost:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=falsespring.datasource.hikari.username=rootspring.datasource.hikari.password=123456 12345@Bean@ConfigurationProperties(prefix = &quot;spring.datasource.hikari&quot;)public DataSource dataSource() { return new HikariDataSource();} 4. 添加 undo_log 表在业务相关的数据库中添加 undo_log 表，用于保存需要回滚的数据 12345678910111213141516CREATE TABLE `undo_log`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGINT(20) NOT NULL, `xid` VARCHAR(100) NOT NULL, `context` VARCHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` INT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARCHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`)) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 5. 启动 Seata-Server在 https://github.com/seata/seata/releases 下载相应版本的 Seata-Server，修改 registry.conf为相应的配置(如果使用 file 则不需要修改)，解压并通过以下命令启动: 1sh ./bin/seata-server.sh 6. 使用@GlobalTransactional开启事务在业务的发起方的方法上使用@GlobalTransactional开启全局事务，Seata 会将事务的 xid 通过拦截器添加到调用其他服务的请求中，实现分布式事务 7. 总结","link":"/2021/03/14/Spring-Cloud-%E5%BF%AB%E9%80%9F%E9%9B%86%E6%88%90-Seata/"},{"title":"Java基础知识","text":"涵盖了 Java 许多重要的基础知识～ 1. 数据类型1.1 数据类型 基本数据类型（或叫做原生类、内置类型）8种： 整数：byte，short，int，long（默认是int类型） 浮点类型： float，double（默认是double类型） 字符类型：char 布尔类型：boolean 引用数据类型3种：数组，类，接口 1.2 == 和 equals 的区别用法上的区别：== 比较(引用的)内存地址，equals 比较内容是否一样。 代码实现：默认的Object.equals()方法也是使用 == 做判断，而String.equals()方法比较了每个Character字符，并重写了hashCode方法。如果要重写equals方法，同时也应重写hashCode方法。 如果不重写对象的hashCode，当两者equals为true但hashCode不同，存放在双列容器Map中也会是两个不同的对象。因为Map比较key时，会先比较hashCode，再使用equals方法。 e.g. 使用JDK1.7BKDR哈希算法重写euqals和hashCode方法 (通过使用 Objects.equals(..) + Objects.hash(..) 方法)： 12345678910111213141516171819public class Laptop { private String name; private Integer price; // omit getter and setter @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Laptop laptop = (Laptop) o; return Objects.equals(name, laptop.name) &amp;&amp; Objects.equals(price, laptop.price); } @Override public int hashCode() { return Objects.hash(name, price); }} 下面是String的hashCode方法，就是 BKDR Hash： 123456789101112public int hashCode() { int h = hash; // hash默认值是0 if (h == 0 &amp;&amp; value.length &gt; 0) { char val[] = value; for (int i = 0; i &lt; value.length; i++) { h = 31 * h + val[i]; // key point } hash = h; } return h;} e.g. == 判断 box，equals 判断 value new Integer(3) == new Integer(3) 不是同个box, false new Integer(3) == 3 (int) 同个box, true 2. Thread2.1 线程安全/数据同步 synchronized：包括monitor enter和monitor exit两个JVM指令。保证执行enter/exit都能读写到主内存的数据（即最新数据）。 monitor计数器：每一个对象与一个monitor关联，enter时monitor计数器+1,exit时monitor计数器-1。 HashMap不是线程安全的，多线程同时写操作容易出现死循环引起死锁。 2.2 锁锁的策略：悲观锁 &amp; 乐观锁a. 悲观锁 每次获取数据时都会先加上锁，例如synchronized 关键字，就是悲观锁策略的一种实现 传统关系型数据库的行锁、表锁和读写锁等也是悲观锁，都是在操作之前先上锁 悲观锁存在的问题/缺点： 在多线程竞争下，加锁、释放锁会导致比较多的线程上下文切换和调度延时，引起性能问题 一个线程持有锁会导致其它所有需要此锁的线程挂起 (线程阻塞) 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险 b. 乐观锁 很乐观，每次拿数据的是都认为别人不会来修改，所以不上锁 在更新的时候会判断一下在此别人有没有也来更新这个数据，可以使用版本号等机制。由于使用了版本号机制，所以 CAS 原理不会产生 ABA 问题 乐观锁适合read的场景，可以提高tps，类似于数据库write_condition机制 CAS(Compare And Swap, 比较和交换) 是其中一种实现方式 JUC包的实现就是建立在CAS算法基础上的(the entities have ‘Lock’, ‘ReadWriteLock’)。 Java 从 5.0开始引入了对CAS的支持，与之对应的是 java.util.concurrent.atomic 包下的AtomicInteger、AtomicReference等类，它们提供了基于CAS的读写操作和并发环境下的内存可见性。 下面是CAS的部分模拟代码： 123456789101112public class SimulatedCAS { private int value; public synchronized int get() { return value; } public synchronized int compareAndSwap(int expectedValue, int newValue) { int oldValue = value; if (oldValue == expectedValue) value = newValue; return oldValue; }} 上边的类模拟了CAS操作，如果成员变量 value 的值与参数 expecredValue 的值不同，那就说明其他的线程已对其进行了修改，本次操作失败。 锁的机制：(自适应)自旋锁自旋锁： 在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。自旋次数的默认值是10次，若仍然没有成功获得锁，则使用传统的方式挂起线程。 自适应自旋锁： 在JDK 1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前 一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长时间，比如100个循环。 如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源. 锁的状态：偏向锁、轻量/重量级锁偏向锁： 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。 轻量级锁(自旋)： 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 重量级锁(阻塞)： 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。 分段锁：ConcurrentHashMapConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即**内部拥有一个Entry数组。数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment 继承了 ReentrantLock)**。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 synchronized &amp; lock synchronized 关键字是 jvm 原生语义上的实现 Synchronized：一个非公平，悲观，独享，互斥，可重入的重量级锁 什么是可重入锁？就是可重复可递归调用的锁。在外层使用锁之后内层仍然可以使用，并且不发生死锁（即可以嵌套使用） lock 是 API 层面上的实现，位于 J.U.C.locks 包下 ReentrantLock：一个默认非公平但可实现公平的，悲观，独享，互斥，可重入，重量级锁 ReentrantReadWriteLocK：一个默认非公平但可实现公平的，悲观，**写独享&amp;读共享(适用读多的场景)**，读写，可重入，重量级锁 下面是Lock接口的源码： 12345678910111213141516public interface Lock { void lock(); // 等待可中断 void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(Long time, TimeUnit unit) throws InterruptedException; void unlock(); // 绑定条件 Condition newCondition();} 对于实现了Lock接口的ReentrantLock，有以下3个主要特性(也是synchronized无法做到的)： 等待可中断 等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。 1void lockInterruptibly() throws InterruptedException; 可实现公平锁() 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 123public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 锁可以绑定多个条件 锁绑定多个条件是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在synchronized中，锁对象的 wait（）和 notify（）或 notifyAll（）方法可以实现一个隐含的条件。如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition() 方法即可。 1Condition newCondition(); 用法上的不同： synchronized 是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized 的锁定，而且在代码执行时出现异常，JVM会自动释放锁定，但是使用 Lock 则不行，lock 是通过代码实现的，要保证锁定一定会被释放，就必须将 unLock() 放到 finally{} 中(lock方法可不放try{}中)。 在资源竞争不是很激烈的情况下，Synchronized 的性能要优于 ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized 的性能会下降几十倍，但是 ReetrantLock 的性能能维持常态； 另外，在 jdk1.8 中两者的性能已经相差无几了。若synchronized在功能层面上无法满足，就用 lock()方法 + try{} finally{} 2.3 线程 6 种状态 新建 可运行 阻塞 等待 限时等待 结束 1234567891011public class Thread implements Runnable { // ... public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED; }} 2.4 线程间的通信同步阻塞 和 异步非阻塞 同步阻塞消息处理的过程：每次提交一个event，服务端接受event创建线程处理，返回结果。 异步非阻塞消息处理的过程：提交even，放入event队列(立即返回工单)，让多个线程(线程数量在可控范围之内)处理。 降低CPU上下文切换线程的开销； 线程可以重复利用，减少创建线程的资源浪费； wait 和 notify 方法 wait()方法必须必须拥有该对象的monitor，不然肿么让锁。即wait方法必须在同步方法块中使用；notify方法也一样 哪个对象wait，哪个对象就notify。否则抛出IllegalMonitorStateException异常 sleep 和 wait 方法的比较 相同点： 阻塞线程 等待可中断 不同点： sleep是Thread特有的方法 wait方法(让锁)必须在同步代码块中执行，sleep不需要 sleep方法短暂休眠之后会主动退出阻塞，而wait(没有指定 wait 时间)则需要被其他线程中断后才能退出阻塞 多线程间的通信If 条件语句在多线程情况下不可靠，需要使用 while + volatile 2.5 类加载的过程 主要分为3个阶段：加载、连接(验证 准备 解析)、初始化 主动使用和被动使用被动使用不会导致类的加载和初始化。此外，类的初始化操作只会执行static静态代码(在方法区/Metaspace)；而实例化操作包括初始化外，还会运行构造方法、分配空间(Head)等操作。 主动使用的场景(5种)：new、使用类的静态变量/方法、反射操作(class.forName方法)、初始化其子类、作为启动类(即main方法所在的类，maybe反射) 被动使用的场景(3种)：new 某个类的数组、使用父类的静态变量(static)**不会导致子类的初始化 (即对子类来说是被动使用，但对父类来说是主动使用，父子分明)、使用静态常量** 123456789101112131415161718192021// 使用父类的静态变量，对自己是没有影响的class Dfather{ static int count = 1; static{ System.out.println(&quot;Initialize class Dfather&quot;); } } class Dson extends Dfather{ static{ System.out.println(&quot;Initialize class Dson&quot;); } } public class Test4 { public static void main(String[] args) { int x = Dson.count; } } 这一部分可以跳过，仅仅与构造方法有关 1234567891011121314// static代码最先执行。当new Juice()的时候，输出：// Juice block// 构造方法public class Juice { public Juice() { System.out.println(&quot;构造方法&quot;); } static { System.out.println(&quot;Juice block&quot;); }} 类的加载过程详解12345678910111213141516171819202122public class Singleton { // ① private static int x = 0; // 静态常量 不会初始化 private static int y; // 静态变量 初始化 private static Singleton instance = new Singleton(); // ② private Singleton() { x++; y++; } // 主动使用 public static Singleton getInstance() { return instance; } public static void main(String[] args) { Singleton singleton = Singleton.getInstance(); System.out.println(singleton.x); // 1 ②放到①输出0 System.out.println(singleton.y); // 1 ②放到①输出1 }} 这里解释一下为什么更换位置后x的值会变成0。当调用getInstance()静态方法后，会导致类的初始化，会按顺序执行如下代码： 12345private static Singleton instance = new Singleton(); // 执行完构造方法后x=1private static int x = 0 // x被重新赋值0private static int y 初始化按static代码位置顺序执行，和调用顺序无关。比如你先调用了静态方法getInstance, 但还是会按顺序执行第一行static代码。 2.6 类加载器的作用作用：让根加载器委托子类加载器去加载厂商提供的SPI(Service Provider Interface)具体实现。其实就是通过SPI机制实现功能的扩展。关于类加载器的更多内容参考JVM。 2.7 深入理解 volatile 关键字初识 volatile 关键字 volatile 只能修饰变量；而 synchronized 可以修饰代码块和方法名 实例变量：init_value 去掉 static 就是普通的实例变量 类变量 (静态变量)：加 static 1234567891011121314151617181920212223242526272829303132333435public class VolatileFoo { final static int MAX = 5; static volatile int init_value = 0; // 尝试不加 volatile 的输出结果 public static void main(String[] args) { // Reader 线程 new Thread(() -&gt; { int localValue = init_value; while (localValue &lt; MAX) { if (init_value != localValue) { System.out.printf(&quot;The init_value is updated to [%d]\\n&quot;, init_value); // 对 localValue 进行重新赋值 localValue = init_value; } } }, &quot;Reader&quot;).start(); // Update 线程 new Thread(() -&gt; { int localValue = init_value; while (localValue &lt; MAX) { // 修改 init_value System.out.printf(&quot;The init_value will be changed to [%d]\\n&quot;, ++localValue); init_value = localValue; try { // 短暂休眠，使 Reader 线程有机会执行。 TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;Update&quot;).start(); }} CPU Cache 模型 和 Java 内存模型的结构类似： a. 读取操作，不做任何处理，只是将 Cache 中的数据读取到寄存器中。 b. 写入操作，发出信号通知其他 CPU 将该变量的 Cache line 置为无效状态，其他 CPU 在进行该变量读取的时候必须到主内存中再次获取，即再 copy 一份副本。 并发编程的三个重要特性 原子性、有序性、可见性 原子性：一个事务包含多个操作，这些操作要么全部执行，要么全都不执行 有序性：为了优化程序性能而对指令序列进行重排序，也就是你编写的代码顺序和最终执行的指令顺序是不一致的，重排序可能会导致多线程程序出现内存可见性问题 可见性：多个线程访问同一个共享变量时，其中一个线程对这个共享变量值的修改，其他线程能够立刻获得修改以后的值 volatile 和 synchronized 的区别 volatile 修饰实例变量和类(静态)变量；synchronized 修饰方法和代码块 volatile 不能保证原子性 可见性的实现原理：volatile 使用机器指令(偏硬件) “lock” 的方式迫使其他线程的工作内存中的数据失效，必须到主内存中进行再次加载。而 synchronized 使用 JVM 指令 monitor enter 和 monitor exit 串行化代码，在 monitor exit 时所有的共享资源都会被刷新到主内存中 volatile 不会使线程进入阻塞状态，synchronized 则不同 volatile 的使用场景开关控制，状态标记，Singleton 的 double-check 七种单例模式的设计比较方法：线程安全、高性能、懒加载。 1) 饿汉式12345678910111213141516171819/*** 特点：可以保证多线程下的唯一实例，getInstance 方法性能比较高，但是无法进行懒加载。* 使用场景：占用内存资源少，因为Instance被CL加载后很长一段时间才使用的话，会在堆内存驻留很长时间。*/// final 不允许被继承public final class Singleton { // 实例变量 private byte[] data = new byte[1024]; // 在定义实例对象的时候直接初始化 private static Singleton instance = new Singleton(); // 私有构造函数，不允许外部 new private Singleton() { } public static Singleton getInstance() { return instance; }} 2) 懒汉式12345678910111213141516171819202122/*** 特点： 使用实例的时候再创建(即懒加载)，无法保证多线程下的唯一实例。* 使用场景：*///final 不允许被继承public final class Singleton { // 实例变量 private byte[] data = new byte[1024]; // 定义实例，但是不直接初始化 private static Singleton instance = null; // 私有构造函数，不允许外部 new private Singleton() { } public static Singleton getInstance() { if (null == instance) { // 可能会有两个(或以上)线程同时看到 instance == null instance = new Singleton(); } return instance; }} 3) 懒汉式 + 同步方法12345// 向 getInstance 方法加入 synchronized 同步控制，每次只有一个线程能进入。// 特点：因synchronized，getInstance 方法只能被一个线程访问，性能低下。public static synchronized Singleton getInstance() { ....} 4) Double-Check1234567891011121314151617181920212223242526/*** 特点：懒加载 + 保证多线程下的唯一实例 + 提高效率，可能造成空指针异常。* 空指针异常的分析：线程1创建instance实例完后，conn,socket 的实例可能尚未创建完成（由JVM发生指令重排* 导致），在此期间，线程2拿到instance实例不幸使用实例变量conn或者socket，则会产生空指针异常。*/public final class Singleton { private byte[] data = new byte[1024]; private static Singleton instance = null; Connection conn; Socket socket; private Singleton() { } public static Singleton getInstance() { if (null == instance) { // 减少排队进入同步代码块的线程数量(减少阻塞)，提高效率。 synchronized (Singleton.class) { if (null == instance) { // 防止下一个获得 monitor 锁的线程进入执行。add: // 可能出现：线程 1 还没初始化结束，线程 2 就直接返回 instance 了。从而导致空指针异常。 instance = new Singleton(); } } } return instance; }} 5) Volatile + Double-Check12// 利用 volatile 禁止 JVM 的指令重排。private volatile static Singleton instance = null; 6) Holder 方式1234567891011121314151617181920/*** 特点：Singleton 初始化过程中不会创建 Instance 实例，只有当 Holder 被主动引用的时候才创建。* Holder 方式的单例设计是最好的设计之一，也是目前使用比较广的设计之一。*/public final class Singleton { private byte[] data = new byte[1024]; private Singleton() { } // 在静态内部类中持有 Singleton 的实例，并且可被直接初始化。 private static class Holder { private static Singleton instance = new Singleton(); } // 调用 getInstance 方法，事实上时获得 Holder 的 instance 静态属性 public static Singleton getInstance() { return Holder.instance; }} 7) 枚举方式123456789101112131415161718192021/*** 特点：枚举类型不允许被继承，同样是线程安全的且只能被实例化一次，但是不能懒加载。**/public enum EnumSingleton { INSTANCE; // 实例变量 private byte[] data = new byte[1024]; EnumSingleton() { System.out.println(&quot;INSTANCE will be initialized immediately.&quot;); } public static void method() { // 调用该方法则会主动使用 Singleton，INSTANCE 将会被实例化。 } public static EnumSingleton getInstance() { return INSTANCE; }} 1234567891011121314151617181920212223242526272829/*** 特点可实现懒加载*/public class Singleton { // 实例变量 private byte[] data = new byte[1024]; private Singleton() { } // 使用枚举充当 holder private enum EnumHolder { INSTANCE; private Singleton instance; EnumHolder() { this.instance = new Singleton(); } private Singleton getEnumSingleton() { return instance; } } public static Singleton getInstance() { return EnumHolder.INSTANCE.getEnumSingleton(); }} 2.8 多线程设计架构模式暂无 3. 集合类3.1 Map (双列集合) 集合类 Key Value Supper 说明 HashTable 不允许为 null 不允许为 null Dictionary 线程安全 ConcurrentHashMap 不允许为 null 不允许为 null AbstractMap 锁分段技术(JDK8:CAS) TreeMap 不允许为 null 允许为 null AbstractMap 线程不安全 HashMap 允许为 null 允许为 null AbstractMap 线程不安全 LinkedHashMap HashMap 扩容机制默认大小为16(1&lt;&lt;4)。当容量达到75%时(默认负载因子是0.75)自动扩容，扩容为原来的2倍，保证容量是2^n。 在确定存放元素位置的时候，使用(n-1) &amp; hash来确定存放位置。因为位与运算符 &amp; 在操作系统中效率很高，同时n为2的n次幂时，hash值计算出的结果分布更加均匀，可以减少hash冲突。 ArrayList扩容为原来的1.5倍。 3.2 Collection (单列集合)a. List (有序) - 性能 说明 Vector 查询快，增删慢，效率低 线程安全 ArrayList 查询快，增删慢，效率高 线程不安全 LinkedList 查询慢，增删快，效率高 线程不安全 线程安全的List/Set:CopyOnWriteArrayList,实现原理如下： 写操作在copy且加锁的副本上(串行)，读操作则在原容器读(并行)。 优点: 1.解决的开发工作中的多线程的并发问题。 缺点: **1.内存占有高:**很明显，两个数组同时驻扎在内存中，如果实际应用中，数据比较多，而且比较大的情况下，占用内存会比较大，针对这个其实可以用ConcurrentHashMap来代替。 **2.数据一致性:**CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器 b. Set (有序) - - 说明 HashSet LinkedHashSet TreeSet 4. 零散知识 String.trim(): 去掉首尾空格 String.split(&quot; &quot;): 根据regex切分返回String数组 1234Scanner in = new Scanner(System.in);int n = Integer.parseInt(in.nextLine().trim()); // input a number in line and trim the space of head and end.String[] strArr = in.nextLine.trim().split(&quot; &quot;); // input &quot; hello world &quot;.System.out.println(strArr); // ouput [hello, world]. Context 是 MetaData 的具体表现？？？ 4.1 java 关键字总结final 关键字final 关键字主要用在三个地方：类(除了接口和抽象类) 方法 变量 下面是几个注意事项： 修饰类/方法时，表明这个类/方法不能被继承，并且 final 类中的所有 fields, methods 都会被隐式地指定为final 变量/方法 private 方法也隐式地指定为 final final修饰的方法虽然不能被继承但可以被重载(@Overload) final 修饰的变量不一定都是常量。例如当 final 修饰任意 Object 时，如 map (引用数据类型)时，仅代表不能指向其它对象，但是 map 的值还是能够被改变的（final的是内存地址），这就会产生线程安全问题。只有当 final 修饰基本数据类型的变量时才是常量。 static 关键字 修饰变量、方法、代码块、静态内部类、静态导包 修饰变量或方法：静态变量存放在JVM的方法区/永久代/meta space 修饰类时，由于没有内部引用(指针)，故不能使用任何外围类的非static变量和方法 static方法只能调用static field/method，非static方法可以调用static field/method。换个方式说，就是metaspace无法访问外部空间。 this 关键字引用类的当前实例。 super 关键字对父类的引用。 this 和 super 必须放在首行；并且不能用在 static 方法中，因为this, super对static metasapce而言是外部空间。 4.2 抽象类和接口的区别抽象类：可以自行实现方法；无多继承 1234567891011// 可以实现多个接口，但是 java 不能实现多继承public abstract class Beverage { public String getDescription() { return description; } // 抽象方法，与接口类似 public abstract double cost();} 4.3 Overload 和 Override 的区别重载 ：发生在同一个类中。方法名相同，参数必须不同，返回值和访可修饰符可以不同，发生在编译时。（其实就是方法名一样就好了，本质上重载方法其实是一个新的方法） 重写 ：发生在父子类中。方法名相同、参数必须相同，返回值范围、抛出的异常范围小于等于父类,；访问修饰符范围大于等于父类；如果父类方法访问修饰符为 private 则子类就不能重写该方法。 4.4 封装、继承和多态多态： 是指在super class中定义的属性和方法被子类继承之后，可以具有不同的数据类型或表现出不同行为 编译时多态：重载 运行时多态：继承 4.5 泛型泛型的语法： 12345678910// 类class ArrayList&lt;T&gt; {}// 方法public &lt;T&gt; void printList(List&lt;T&gt; data) {}// 调用 static泛型 方法LinkedList.&lt;Integer&gt;newEmptyList()// T 也可以做返回值 运行时如何知道泛型的类型？ 将类型作为参数传递,如： &lt;T&gt; void printList(List&lt;T&gt; data, class&lt;T&gt; elementType) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package com.macro.mall.common.api;/** * 通用返回对象 */public class CommonResult&lt;T&gt; { private long code; private String message; private T data; protected CommonResult() { } protected CommonResult(long code, String message, T data) { this.code = code; this.message = message; this.data = data; } /** * 成功返回结果 * * @param data 获取的数据 */ public static &lt;T&gt; CommonResult&lt;T&gt; success(T data) { return new CommonResult&lt;T&gt;(ResultCode.SUCCESS.getCode(), ResultCode.SUCCESS.getMessage(), data); } /** * 成功返回结果 * * @param data 获取的数据 * @param message 提示信息 */ public static &lt;T&gt; CommonResult&lt;T&gt; success(T data, String message) { return new CommonResult&lt;T&gt;(ResultCode.SUCCESS.getCode(), message, data); } /** * 失败返回结果 * @param errorCode 错误码 */ public static &lt;T&gt; CommonResult&lt;T&gt; failed(IErrorCode errorCode) { return new CommonResult&lt;T&gt;(errorCode.getCode(), errorCode.getMessage(), null); } /** * 失败返回结果 * @param errorCode 错误码 * @param message 错误信息 */ public static &lt;T&gt; CommonResult&lt;T&gt; failed(IErrorCode errorCode,String message) { return new CommonResult&lt;T&gt;(errorCode.getCode(), message, null); } /** * 失败返回结果 * @param message 提示信息 */ public static &lt;T&gt; CommonResult&lt;T&gt; failed(String message) { return new CommonResult&lt;T&gt;(ResultCode.FAILED.getCode(), message, null); } /** * 失败返回结果 */ public static &lt;T&gt; CommonResult&lt;T&gt; failed() { return failed(ResultCode.FAILED); } /** * 参数验证失败返回结果 */ public static &lt;T&gt; CommonResult&lt;T&gt; validateFailed() { return failed(ResultCode.VALIDATE_FAILED); } /** * 参数验证失败返回结果 * @param message 提示信息 */ public static &lt;T&gt; CommonResult&lt;T&gt; validateFailed(String message) { return new CommonResult&lt;T&gt;(ResultCode.VALIDATE_FAILED.getCode(), message, null); } /** * 未登录返回结果 */ public static &lt;T&gt; CommonResult&lt;T&gt; unauthorized(T data) { return new CommonResult&lt;T&gt;(ResultCode.UNAUTHORIZED.getCode(), ResultCode.UNAUTHORIZED.getMessage(), data); } /** * 未授权返回结果 */ public static &lt;T&gt; CommonResult&lt;T&gt; forbidden(T data) { return new CommonResult&lt;T&gt;(ResultCode.FORBIDDEN.getCode(), ResultCode.FORBIDDEN.getMessage(), data); } public long getCode() { return code; } public void setCode(long code) { this.code = code; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public T getData() { return data; } public void setData(T data) { this.data = data; }} 4.6 值传递 &amp; 引用传递值传递：基本数据类型的传递。copy了值，实际上是2份数据。 引用传递：引用数据类型的传递(数组 类 接口)。只传递引用的地址，实际上是1份数据。 5. MySQL5.1 三范式&amp;四特性 第一范式：每个字段都 不可再分(原子性) 第二范式：每个字段都 和主键相关(唯一性) 第三范式：每个字段都 和主键列直接相关，而不是间接相关/依赖(冗余性) 四特性：ACID 5.2 事务隔离级别 并发事务带来的问题： 脏读：读取了被修改过但是未提交到数据库的数据 不可重复读：一个事务多次读取同一数据但是结果不一样(数据被修改) 幻读：同上，但是数据增加或删除了 MySQL默认的事务隔离级别 (Repeatable Read) 是如何避免幻读的？ **快照读 **(无锁，如 select) 的实现方式 通过 MVCC(多版本控制) 和 undo log 当前读 (有锁，如 select .. [for update]/[lock in share mode] 和 所有修改操作，即 update , delete , insert) 的实现方式 通过 行锁 和 gap 锁 (mysql官方文档称为 Next-Key Locks) 例如，假设要update一条记录，但是另一个事务已经delete这条数据并且commit了，如果不加锁就会产生冲突。所以update的时候肯定要是当前读，得到最新的信息并且锁定相应的记录。 MVCC多版本控制 实现：DB_REX_ID, DB_ROLL_PTR(undo log?), DB_ROW_ID gap锁的介绍 123select *from user where age&gt;0 and age&lt;10 for update;或者select *from user where age&gt;0 and age&lt;10 in share mode; 举个栗子，我们在一个事务中执行上述的SQL语句,数据库中只有age=1，age=4，age=7，age=8 这三条满足条件的记录,那么gap锁会加到age=2，3，5，6，9上面，如果另外一个事务里面想insert age=2，3，5，6，9 是会被阻塞的，因为第一个事务拿到了gap锁。 gap锁会作用在普通索引或无索引的当前读中。 5.3 索引 索引的作用：避免全表扫描，提高查询性能 索引的种类 索引的数据结构B-Tree 索引的优点哈希索引：对于哈希索引来说，其底层的数据结构就是啥希表。因此在查询1条记录时速度最快，为O(1)的时间复杂度。其余大部分场景，建议选择 Btree 索引。 B-Tree 索引：Mysql的 Btree 索引使用的是B+树。但对于主要的两种存储引( MYISAM和NNODB)的实现方式是不同的。 B-Tree 相对二叉树：因为一个节点有多个孩子，所以相对于二叉树深度k阶降低，减少了系统的IO次数。 B+树和B树的区别：非叶子节点仅用做索引，将数据都存放在了叶子节点上且数据有序。同时，B+树上的叶子结点增加了顺序访问指针，所以同级/范围内的(叶子节点)数据能够互相访问，不需要再回到父节点查找数据，减少了磁盘IO次数。 总结： I/O次数降低，故磁盘读写代价更低 查询效率更稳定。查的时间复杂度O(logn)， 哈希索引最好为O(1)，最坏为O(n)) Hash 索引的缺点在功能上： 仅能满足=、in，不能使用范围查询（包括模糊查询） 因为原先是有序的键值，但是经过hash算法后，有可能变成不连续的，就没有办法利用索引完成范围查询检索数据。 无法使用部分索引：不支持多列联合索引的最左前缀匹配规则 在性能上： 当发生hash冲突时，性能低下 并且由于hash冲突的存在，无法100%避免全表扫描 最左匹配原则从左向右匹配(组合索引)直到有范围查询 (&gt;,&lt;,between,like) 就停止（但是能达到这个范围的索引）。 例如：对组合索引（a,b,c,d）来说，where a = 3 and b = 4 and c &lt; 5 and d = 6 中到 c 终止，d 的索引是达不到的，所以不会使用该组合索引。但如果组合索引为（a,b,d,c）则都可以用到。 注意：**= 条件可以乱序，mysql 会自动识别的** 5.4 优化查询速度 一些优化的 Tips： 可以通过 Druid 等工具来找到慢SQL 使用 join 关键字的时候，遵循小表驱动大表 方案一，优化SQL 索引 限定查询数据范围 方案二，优化架构 Replications读写分离 / Cluster 垂直/水平分区（事务复杂） 数据库分片 另外还有一些比较好用的命令… 12345678910# query commandsshow variables like '%query%'; explain ..; # 其实用 druid 更方便吧...# set commands # 用命令改的参数在 mysql 重启后会失效，推荐的方式是在 my.ini/my.cnf 配置文件中修改set global slow_query_log = on;set global long_query_time = 1;# 慢 sql 相关变量有： long_query_time=10(s) / slow_query_log=OFF（慢 sql 将会被记录在日志中） / slow_query_log_file=... explain 关键字 reference 也有”索引”的含义 all index range ref(常见) eq_ref(常见) const 全表扫描 有顺序的全表扫描 索引范围扫描 使用索引，索引值不唯一 唯一索引查找 以主键为查询条件 1234EXPLAIN select m.* from base_mobile_menu m inner join base_mobile_authority a on m.id = a.menu_id and a.role_id = &quot;d0278641a3d04e64987c2fbec1e778da&quot;; 当 exta 中出现以下 2 项意味着 MYSQL 根本不能使用索引，效率会受到重大影响。应尽可能对此进行优化。 extra 说明 Using filesort 表示 MySQL 会对结果使用一个外部索引排序(指 file )，而不是从表里按索引次序读到相关内容。可能在内存或者磁盘上进行排序。MSQL 中无法利用索引完成的排序操作称为文件排序——filesort Using temporary 表示 MSQL 在对查询结果排序时使用 temporary 临时表。常见于排序 order by 和分组查询 group by 5.5 部分语法group by ..：根据..进行分组 having：一般用做筛选 group by 的分组结果，也可以像 where 一样使用。可以接聚合函数。 聚合函数：count, sum, max, min, avg 优先级： where &gt; group by &gt; having (with func) 5.6 InnoDB 和 MyISAMMyISAM 从锁和事务两方面看有如下缺点： 只有表锁。MyISAM select 的时候会做全表锁(排它锁)，此时无法执行更新等操作（即查询&amp;修改操作不能同时执行，但是可以同时执行多个读操作）；而 InnoDB select 默认不加锁，修改操作默认使用行锁+gap锁（读操作也可以通过在select语句后加for update实现行锁+gap锁）。表锁不存在死锁，因为全部资源被一个线程占用了。 不支持事务。没有事务性能更高。 对于InnoDB： 若走索引，则默认使用行锁 若无索引，则默认使用全表锁 因此 MyISAM 适用场景：只查询，不需要事务 5.7 常见问题时区在连接数据库的 url 指定参数：?serverTimezone=GMT%2B8 修改最大连接数通常，mysql的最大连接数默认是100, 最大可以达到16384。1、查看最大连接数:show variables like ‘%max_connections%’;2、修改最大连接数 方法一：修改配置文件，永久生效 (Recommend) 进入MySQL安装目录 打开MySQL配置文件 my.ini 或 my.cnf查找 max_connections=100 修改为 max_connections=1000 服务里重起MySQL即可. 方法二：命令行修改，重启失效 12# 命令行连接 MySQL server 后，设置新的 MySQL 最大连接数为 200MySQL &gt; set global max_connections=200 因为在命令行设置的最大连接数只在 mysql 当前服务进程内有效，一旦mysql重启，又会恢复到初始状态。因为mysql启动后的初始化工作是从其配置文件中读取数据的，而这种方式没有对其配置文件做更改。 8 小时连接自动失效查看失效时间：show variables like 'wait_timeout'; 设置失效时间：set global wait_timeout = xxx; 不过一般情况下，应检查代码配置！！ 为什么单机推荐用自增id做主键 这里不包括分布式的场景，因为不能保证主键的唯一性 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。 总的来说就是可以提高查询和插入的性能。 聚簇索引 &amp; 非聚簇索引 6. Redis redis 的所有 keys 必须设置过期时间+微小的随机值（除了常量需要由手动触发更新外） 6.1五种数据结构 对Redis来说，所有的 key 都是字符串。value 不是 string 就是collections string、hash(map)、list set zset(SortedSet) 6.2 六种内存淘汰策略 LRU (Least recently used) 最近最少使用；volatile adj. 易变的；易挥发的 总结：默认noeviction，2种LRU，2种Random，还有 TTL 6.3怎么存放热点数据提供一种简单实现绶存失效的思路：可以结合 volatile-LRU 过期策略，每命中一次 key 就给它增加过期时间。 6.4 RDB 和 AOF两者对比 RDB 快照备份：保存某个时间点的全量数据快照。 好处是文件体积小(二进制格式+自动压缩)，恢复速度快(类似于sql的批量操作)，缺点是丢失数据时数据量较大。 AOF (append-only file)：保存写状态，即每条 redis 命令。（不保存查询命令） Redis 持久化默认为 RDB 持久化，若需要 AOF 在 conf 文件中把append-only参数改成 yes。 RDB和AOF可以同时配置的，当同时开启的时候启动的时候redis会优先加载AOF文件，因为通常情况下AOF持久化保存的数据更完整一些。若只打算用Redis 做缓存，可以关闭持久化。若打算使用 Redis 持久化，建议RDB和AOF都开启，AOF的优先级更高，若没有开启则使用RDB恢复。 AOF 配置1234567# AOF 3种备份策略appendfsync always #每次有数据修改发生时都会写入AOF文件。appendfsync everysec #每秒钟同步一次。默认策略appendfsync no #从不同步。高效但是数据不会被持久化。 压缩 AOF 文本文件的命令： 123456789# 手动压缩的命令（not recommended）bgrewriteaof# appendonly.aof 文件大小增加 100%(即原来的2倍) 则进行一次 rewirte 压缩# 如果之前没有重写过，则以启动时的 aof 文件大小为依据auto-aof-rewrite-percentage 100 # 默认值# appendonly.apf 文件若小于 64mb 则无需重写auto-aof-rewrite-min-size 64mb # 默认值 AOF 日志记录方式： Always（同步回写）: 执行完指令后必须同步写完日志后请求才响应。 Everysec（定时回写）： 异步回写，执行完指令后先把日志记录到内存缓冲区里面，然后每隔一段时间把缓冲区刷到日志记录里。 No（系统触发回写）: 异步回写，执行完指令后先把日志记录到内存缓冲区里面，由系统决定什么时候把缓冲数据刷到日志里。 RDB 配置123456# RDB 快照备份说明# save 时间(s) keys数量save 900 1 : 在15分钟内有至少一个键被修改则触发RDB快照备份save 300 10 : 在5分钟内至少有10个键被修改则触发。save 60 10000 : 在一分钟内有10000个键被修改则触发。 主从同步的原理主从模式核心问题是主节点和从节点之间的数据同步的机制，Redis的主从数据同步主要分为两个阶段，初始化阶段的数据同步和更新时的数据同步，初始化数据同步主要是通过 RDB 完成，更新数据同步通过replication buffer来完成，主要流程如下： 从库向主库发起同步请求 主库执行 bgsave 命令，生成并发送 RDB 文件到从库 主库继续发送 replication buffer 里的命令，补全数据 从上述的同步过程来看，其实就是借助了 RDB 与 类AOF 的功能 6.5 缓存雪崩和缓存穿透缓存雪崩 缓存真的崩了 缓存同一时间keys大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决方法：集群 =&gt; **限流/降级/**加锁/exTime过期时间随机值 =&gt; 再使用 aof, rdb 恢复 redis 数据库 缓存穿透 缓存没问题，是有意为之 一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决方法：先使用布隆过滤器限流，再缓存结果(即便这个结果可能为空)。 布隆过滤器布隆过滤器是一种数据结构，可以看成一个二进制数组。每当有数据进来时，会先通过一系列哈希函数计算出该数据的hashcode，然后再根据hashcode存放在对应的位置上。但是由于hashcode有可能重复（即哈希冲突），所以我们可以得到一个结论：布隆过滤器可以判断某个数据一定不存在，但是无法判断一定存在。（即发生哈希冲突时，谁都不知道这个数据有没有存在） 下面是 guava 类库的 bloomfilter 演示代码，其实一些 Redis lib 也有该过滤器的实现。 12345678910111213141516171819// 这里使用的是guava工具包, redis工具包应该也有提供package com.ys.rediscluster.bloomfilter;import com.google.common.base.Charsets;import com.google.common.hash.BloomFilter;import com.google.common.hash.Funnel;import com.google.common.hash.Funnels;public class GuavaBloomFilter { public static void main(String[] args) { BloomFilter&lt;String&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01); bloomFilter.put(&quot;10086&quot;); System.out.println(bloomFilter.mightContain(&quot;123456&quot;)); System.out.println(bloomFilter.mightContain(&quot;10086&quot;)); }} 6.6 如何使用Redis做异步队列使用 List 数据结构作为队列；rpush生产消息，lpop消费消息。(先进先出) pub/sub：发布订阅模式（类似消息队列的架构），如下图： 6.7 Redis 和 Memcached2021年看来memcached还是不行了，etcd yyds！ 6.8 常见问题当出现大量 keys 同时过期的情况，由于清除 key 需要时间，所以会出现短暂的卡顿现象。可在设置过期时间的时候给每个key加上随机值。 7. Spring spring MVC 运行流程：1.Request 2.DispatcherServlet 3.HandlerMapping 4.HandlerAdaper(Controller) 5.ViewResolver 7.1 Bean的生命周期 singleton(默认值) prototype @Scope(&quot;prototype&quot;) request session 7.2 事务隔离级别与MySQL类似，有read uncommited，read commited，repeatable read(默认)，serializable 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public enum Isolation { /** * Use the default isolation level of the underlying datastore. * All other levels correspond to the JDBC isolation levels. * @see java.sql.Connection */ DEFAULT(TransactionDefinition.ISOLATION_DEFAULT), /** * A constant indicating that dirty reads, non-repeatable reads and phantom reads * can occur. This level allows a row changed by one transaction to be read by * another transaction before any changes in that row have been committed * (a &quot;dirty read&quot;). If any of the changes are rolled back, the second * transaction will have retrieved an invalid row. * @see java.sql.Connection#TRANSACTION_READ_UNCOMMITTED */ READ_UNCOMMITTED(TransactionDefinition.ISOLATION_READ_UNCOMMITTED), /** * A constant indicating that dirty reads are prevented; non-repeatable reads * and phantom reads can occur. This level only prohibits a transaction * from reading a row with uncommitted changes in it. * @see java.sql.Connection#TRANSACTION_READ_COMMITTED */ READ_COMMITTED(TransactionDefinition.ISOLATION_READ_COMMITTED), /** * A constant indicating that dirty reads and non-repeatable reads are * prevented; phantom reads can occur. This level prohibits a transaction * from reading a row with uncommitted changes in it, and it also prohibits * the situation where one transaction reads a row, a second transaction * alters the row, and the first transaction rereads the row, getting * different values the second time (a &quot;non-repeatable read&quot;). * @see java.sql.Connection#TRANSACTION_REPEATABLE_READ */ REPEATABLE_READ(TransactionDefinition.ISOLATION_REPEATABLE_READ), /** * A constant indicating that dirty reads, non-repeatable reads and phantom * reads are prevented. This level includes the prohibitions in * {@code ISOLATION_REPEATABLE_READ} and further prohibits the situation * where one transaction reads all rows that satisfy a {@code WHERE} * condition, a second transaction inserts a row that satisfies that * {@code WHERE} condition, and the first transaction rereads for the * same condition, retrieving the additional &quot;phantom&quot; row in the second read. * @see java.sql.Connection#TRANSACTION_SERIALIZABLE */ SERIALIZABLE(TransactionDefinition.ISOLATION_SERIALIZABLE); private final int value; Isolation(int value) { this.value = value; } public int value() { return this.value; }} 7.3 事务传播行为 支持当前事务(当前存在事务，则加入该事务；如果没有则如下：) TransactionDefinition.PROPAGATION_REQUIRED: 创建一个新事务。 supports：以非事务的方式继续运行。 mandatory：抛出异常。 不支持当前事务 requires_new: 创建一个新事务，挂起当前事务（若有）。 not_supported: 以非事务方式运行，挂起当前事务（若有） never: 以非事务方式运行，抛出异常（若有） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public enum Propagation { /** * Support a current transaction, create a new one if none exists. * Analogous to EJB transaction attribute of the same name. * &lt;p&gt;This is the default setting of a transaction annotation. */ REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED), /** * Support a current transaction, execute non-transactionally if none exists. * Analogous to EJB transaction attribute of the same name. * &lt;p&gt;Note: For transaction managers with transaction synchronization, * {@code SUPPORTS} is slightly different from no transaction at all, * as it defines a transaction scope that synchronization will apply for. * As a consequence, the same resources (JDBC Connection, Hibernate Session, etc) * will be shared for the entire specified scope. Note that this depends on * the actual synchronization configuration of the transaction manager. * @see org.springframework.transaction.support.AbstractPlatformTransactionManager#setTransactionSynchronization */ SUPPORTS(TransactionDefinition.PROPAGATION_SUPPORTS), /** * Support a current transaction, throw an exception if none exists. * Analogous to EJB transaction attribute of the same name. */ MANDATORY(TransactionDefinition.PROPAGATION_MANDATORY), /** * Create a new transaction, and suspend the current transaction if one exists. * Analogous to the EJB transaction attribute of the same name. * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; Actual transaction suspension will not work out-of-the-box * on all transaction managers. This in particular applies to * {@link org.springframework.transaction.jta.JtaTransactionManager}, * which requires the {@code javax.transaction.TransactionManager} to be * made available to it (which is server-specific in standard Java EE). * @see org.springframework.transaction.jta.JtaTransactionManager#setTransactionManager */ REQUIRES_NEW(TransactionDefinition.PROPAGATION_REQUIRES_NEW), /** * Execute non-transactionally, suspend the current transaction if one exists. * Analogous to EJB transaction attribute of the same name. * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; Actual transaction suspension will not work out-of-the-box * on all transaction managers. This in particular applies to * {@link org.springframework.transaction.jta.JtaTransactionManager}, * which requires the {@code javax.transaction.TransactionManager} to be * made available to it (which is server-specific in standard Java EE). * @see org.springframework.transaction.jta.JtaTransactionManager#setTransactionManager */ NOT_SUPPORTED(TransactionDefinition.PROPAGATION_NOT_SUPPORTED), /** * Execute non-transactionally, throw an exception if a transaction exists. * Analogous to EJB transaction attribute of the same name. */ NEVER(TransactionDefinition.PROPAGATION_NEVER), /** * Execute within a nested transaction if a current transaction exists, * behave like {@code REQUIRED} otherwise. There is no analogous feature in EJB. * &lt;p&gt;Note: Actual creation of a nested transaction will only work on specific * transaction managers. Out of the box, this only applies to the JDBC * DataSourceTransactionManager. Some JTA providers might support nested * transactions as well. * @see org.springframework.jdbc.datasource.DataSourceTransactionManager */ NESTED(TransactionDefinition.PROPAGATION_NESTED); private final int value; Propagation(int value) { this.value = value; } public int value() { return this.value; }} 8. 面试 FAQ如何排序 10G 的数据首先，数据量较大无法一次加载到内存，故需要对数据进行分段，分发到各个节点排序，最后再归并节点。因此可以采用 k 路归并算法，并结合缓冲区和 iterable 集合类框架List的常用方法及注意事项 在对List遍历的时候不能进行删除或者修改等操作，否则会出现ConcurrentModificationException异常。遍历推荐 Iterator。 Map的常用方法及注意事项 死锁定义两个或以上的线程互相持有对方需要的资源，导致这些线程处于等待状态，无法执行。 产生死锁的 4 个必要条件 互斥性(资源)：一个资源只能被一个线程占有。 请求和保持条件(A)：一个线程请求已被占有的资源发生阻塞时，自己占有的资源也不释放。 不可抢占(B)：线程无法剥夺被占用的资源。 循环等待(AB)：发生死锁时，线程进入死循环，永久阻塞。 产生死锁的原因 竞争不可抢占性资源 竞争可消耗资源 进程推进顺序不当 避免死锁的方法 破坏“请求和保持”条件：一次性申请所有需要的资源（像synchronized直接加在方法名上） 破坏“不可抢占”条件：抢不到资源就释放自己占有的资源（不太现实） 破坏“循环等待”条件：按顺序获取资源（推荐） 推荐工具visualvm，jprofiler(收费) Java 反射机制定义：**动态 **(Running Time) 获取类信息及调用方法的功能，称为反射。 反射的例子： 12345678910public class ReflectSample { public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException { Class robotClass = Class.forName(&quot;com.example.demo.reflect.Robot&quot;); Robot robot = (Robot) robotClass.newInstance(); Method sayHi = robotClass.getDeclaredMethod(&quot;sayHi&quot;, String.class); sayHi.invoke(robot, &quot;welcome&quot;); }} Class.forName() &amp; ClassLoader.loadClass()forName直接初始化类，loadClass懒加载 所以理论上使用loadClass性能更加，但是有些lib需要初始化才能使用，比如Mysql Driver驱动，所以使用forName加载类。 Java 内存模型进程和线程的区别两者的概念：进程是资源分配的最小单位，线程是CPU调度的最小单位。 区别：一个进程可能有多个线程；进程是一个独立的应用，有独立的地址空间；进程的切换开销大； 另外，一个线程挂掉可能会导致整个进程挂掉。Java采用单线程编程模型，每个进程对应一个JVM实例，多个线程共享JVM里的堆。 PC表示程序计数器；TLS为ThreadLocalStorage，用于线程间的数据隔离。 如何排查和解决死锁使用 jvisualvm 查看哪些线程发生死锁dufy [强制]对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会 造成死锁。说明：线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是 A、B、C，否则可能出现死锁。 如何排查和解决服务器CPU占用率100% top命令查看CPU使用情况(如mysql进程等等的cpu使用率，死锁不一定占用cpu)。 再通过jvisualvm查看相关进程的信息。 有哪些工具能够快速查看线程使用情况强软弱虚引用 Thread 线程相关 由于锁机制的存在，所以没有可立即运行的线程存在 Thread和Runnable的关系创建线程时可实现Runnable接口或继承Thread类(重写run方法)，而Thread类实际上也是实现了Runnable接口的。 因类的单一继承原则，推荐使用Runnable接口。 另外，调用start方法不一定立即执行run方法，而仅仅是进入Runnable状态，有可能需要等待线程获取资源后才能执行。 如何获取线程的返回值a. 主线程等待法 1234567891011121314151617181920212223public class CycleWait implements Runnable{ private String value; // 不需要加 static 也能在本方法中使用。 @Override public void run() { try { Thread.currentThread().sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } value = &quot;we have data now.&quot;; } public static void main(String[] args) throws InterruptedException { CycleWait wait = new CycleWait(); Thread thread = new Thread(wait); thread.start(); while(null == wait.value) { // 看这里 Thread.currentThread().sleep(1); } System.out.println(&quot;value: &quot; + wait.value); }} b. 使用Thread类的join()方法阻塞当前线程以等待子线程处理完毕 123456789101112131415161718192021public class CycleWait implements Runnable{ private String value; // 不需要加 static 也能在本方法中使用。 @Override public void run() { try { Thread.currentThread().sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } value = &quot;we have data now.&quot;; } public static void main(String[] args) throws InterruptedException { CycleWait wait = new CycleWait(); Thread thread = new Thread(wait); thread.start(); thread.join(); // 阻塞当前线程而不是自己==。 System.out.println(&quot;value: &quot; + wait.value); }} c. 通过Callable接口实现：使用FutureTask或者Executor线程池接收Callable对象 12345678910public class FutureTaskDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(new MyCallable()); new Thread(task).start(); if (!task.isDone()) { System.out.println(&quot;task has not finished, please wait!&quot;); } System.out.println(&quot;task return: &quot; + task.get()); }} 1234567public class ExecutorDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService threadPool = Executors.newCachedThreadPool(); Future&lt;String&gt; future = threadPool.submit(new MyCallable()); System.out.println(future.get()); }} 线程的6种状态 NEW 新建 RUNANBLE 可运行/运行中 BLOCKED 阻塞：等待获取锁(资源)。 WAITING 无限期等待：没有对Object.wait()或Thread.join()方法设置Timeout。因为wait让出锁，所以此时自己会变成等待状态。 TIMED_WAITING 限时等待 TERMINATED 结束：结束后不能再调用Thread.start()方法（即只能调用一次），否则会抛出异常。 notify 和 notifyAll 的区别notify 随机唤醒一个等待锁的线程，notifyAll则唤醒所有等待资源锁的线程。 如何中断线程 使用 Thread.interrupt() 方法。 若线程处于阻塞状态，则抛出InterruptedException。 若线程处于正常活动状态，则不起作用。可以将该线程的中断标记(使用volatile修饰的变量)设置为 true/false. 使用 Thread.stop() 方法，相当于电脑的强制关机，已弃用。 1234567891011121314151617181920212223242526/** * 1. volatile 标记 * 2. interrupt() 方法 * 3. stop() 方法(已弃用) */public class StopThread { static volatile boolean mark = true; public static void main(String[] args) throws InterruptedException { Thread tickTop = new Thread(new Runnable() { @Override public void run() { while(mark) { System.out.println(System.currentTimeMillis()/1000); } } }); tickTop.start(); TimeUnit.SECONDS.sleep(3); System.out.println(&quot;即将结束&quot;); // tickTop.stop(); // tickTop.interrupt(); // useless mark = false; }} BIO、NIO 和 AIO 对比 ABN Spring IOC 和 AOPIOC(Inversion of Control，控制反转)： Interceptor和Filter的区别Interceptor 拦截器是基于java反射机制实现，在action的生命周期中可以多次调用; 而 Filter 基于函数回调实现，只能在容器初始化时被调用一次，但是Filter对所有的请求起作用，即作用范围更广。最适合最网关。 创建对象的 4 种方法 new 反射 Object.clone(): 需要重写 clone 方法，这是浅拷贝，即成员变量的引用与原对象是相同的。 反序列化…? 保存日志日志级别：error &gt; warn &gt; info &gt; debug 日志配置： 12345678logging: file: ${spring.application.name}.log # 日志文件超过 10MB 后，自动分片 file.max-size: 10MB # 日志文件最多存放 10 天 file.max-history: 10 level: root: info # DAO 层可以为 DEBUG 级别，生产环境尽量少！！","link":"/2021/02/28/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"ServiceMesh, Serverless, K8s","text":"关于ServiceMesh, Serverless, K8s的概念与联系。 ServiceMesh微服务存在的问题： 框架底层实现复杂(分布式系统的通信协议) 框架没有多语言支持 版本兼容问题，可能依赖库升级，系统也要升级。 ServiceMesh，服务网格： 服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但对应用程序透明。 网格 = sidecar = 网络代理 它将分布式服务的通信抽象为单独一层，在这一层中实现负载均衡、服务发现、认证授权、监控追踪、流量控制等分布式系统所需要的功能，作为一个和服务对等的代理服务，和服务部署在一起，接管服务的流量，通过代理之间的通信间接完成服务之间的通信请求，这样上边所说的三个问题也迎刃而解。（抽象化微服务通用组件的通信功能） 因此说，Service Mesh 是微服务时代的 TCP/IP 协议。 如果我们暂时略去服务，只看Service Mesh的单机组件组成的网络： 第二代 Service Mesh，增加了管理各个 sidecar 网格的控制面板： 总结一下，Service Mesh具有如下优点： 屏蔽分布式系统通信的复杂性(负载均衡、服务发现、认证授权、监控追踪、流量控制等等)，服务只用关注业务逻辑； 真正的语言无关，服务可以用任何语言编写，只需和Service Mesh通信即可； 对应用透明，Service Mesh组件可以单独升级； 当然，Service Mesh目前也面临一些挑战： Service Mesh组件以代理模式计算并转发请求，一定程度上会降低通信系统性能，并增加系统资源开销； Service Mesh组件接管了网络流量，因此服务的整体稳定性依赖于Service Mesh，同时额外引入的大量Service Mesh服务实例的运维和管理也是一个挑战； 历史总是惊人的相似。为了解决端到端的字节码通信问题，TCP协议诞生，让多机通信变得简单可靠；微服务时代，Service Mesh应运而生，屏蔽了分布式系统的诸多复杂性，让开发者可以回归业务，聚焦真正的价值。 Serverless无服务器计算是一种按需提供后端服务的方法。无服务器提供程序允许用户编写和部署代码，而不必担心底层基础结构。从无服务器供应商处获得后端服务的公司将根据其计算费用，而不必保留和支付固定数量的带宽或服务器数量，因为该服务是自动扩展的。 也就是说，不用你处理服务器上的部署、运维、服务器容量和服务器的扩展和失败容错，还有服务器上选择什么OS操作系统，语言的更新，日志等等问题。请注意，尽管称为无服务器，但仍使用物理服务器，但开发人员无需了解它们。 当前业界最常见的 Serverless 实现方案为 FaaS（Function as a Service, 函数即服务） + BaaS（Backend as a Service, 后端即服务），我们经常听到的「云服务」就是基于 FaaS + BaaS 架构。 KubernetesRancher有分为v1和v2版本，都是提供容器调度与编排，不同之处在于在k8s盛行之前有许多人都搞过容器编排，所以rancher v1上会有几种不同的编排模式，例如cattle ,swarm,kubernetes。从这里可以看出Rahcner v1时代，它给自己的定位是各种编排工具的上层，也就是k8s的上层，然后你再通过它去管理k8s。 因为k8s后来发展得势不可挡，所以Rancher v2应运而生，移除了其他类型的编排工具，只剩下k8s。 所以总结一下，两者的关系是Rancher对k8s进行了功能的拓展与实现了和k8s集群交互的一些便捷工具，包括执行命令行，管理多个 k8s集群，查看k8s集群节点的运行状态等等。","link":"/2021/10/29/ServiceMesh-Serverless-K8s/"},{"title":"etcd","text":"… etcd1. 介绍1.1 什么是etcd 官方介绍 etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node. Learn more 百度找的 它是一种用于共享配置和服务发现的分布式、强一致性的K-V存储系统，基于HTTP+JSON的API让你用curl就可以轻松使用，可选SSL客户认证机制，每个实例每秒支持一千次写操作，使用Raft算法充分实现了分布式。 分布式系统中的数据分为控制数据和应用数据，ectd默认处理的数据都是控制数据。 至于传统数据库，大家比较熟悉的有Oracle、MySQL、Redis、MongoDB等，随着云计算的发展，传统数据库的弊端越来越明显，移动互联网、物联网产生海量数据，要求数据库有更高的扩展性，但传统数据库是集中式架构，在扩展性和灵活上先天不足，如果需要扩展通常只能是Scale up，为此需要购买昂贵设备，投资不菲。 这个时候NewSQL、NoSQL和云数据库应运而生，云数据库天然具备云上灵活性，支持市面上主流的商业数据库，其经济高效的部署方式和按需付费的支付模式给数据库开启了新时代的大门。 另外，etcd和分布式db差异很大，它只是一个kv存储，使用场景很有限。它不支持sql，存储数据量也很有限。分布式db有些会基于etcd来做集群管理等（如gauss和tbase），tdsql是用zookeeper做类似功能， 其他答主也有提到。etcd 作为一个高可用键值存储系统，天生就是为集群化而设计的。由于Raft 算法在做决策时需要多数节点的投票，所以etcd 一般部署集群推荐奇数个节点，推荐的数量为3、5 或者7 个节点构成一个集群。 在云计算时代，怎么样能让服务快速透明地接入到计算集群中，让共享配置信息快速被集群中的所有机器发现，以及如何构建一套高可用、安全、易于部署以及响应快速的服务集群，是迫切需要解决的问题。etcd 可以说是为解决这类问题带来了新的办法。 被k8s采用作为其数据库","link":"/2021/11/01/etcd/"},{"title":"Java虚拟机 (JVM)","text":"Java 虚拟机知识点，总结自《深入理解Java虚拟机》 1. JVM结构 堆+栈+程序计数器+方法区(MetaSpace1.8) Attention: 栈和程序计数器为线程私有 1.1 程序计数器 存放线程的字节码指令、分支、循环、异常处理等信息。 不会出现任何溢出异常。 1.2 虚拟机栈 -Xss 设置大小 方法执行的时候创建栈帧,方法的调用是栈帧出栈和入栈的过程。 栈帧：局部变量表等。 宽度：栈帧内存大小 虚拟机栈的深度：栈帧的数量 1.3 本地方法栈 调用的方法是本地方法的接口,也就是C/C++程序。 1.4 堆 1.5 方法区(永久代) / MetaSpace jdk1.8 存储已经被JVM加载的类信息、常量、静态变量、JIT编译后的代码等数据。jdk1.7开始，字符串放到了堆中。 2 Thread 和 JVM 的关系Java进程的内存大小(即计算机RAM内存) = 堆内存 + 线程数量 * 栈内存。 故 栈内存(-Xss)越大，线程数量就越少。 3 JVM 类加载器3.1 JVM 内置三大类加载器​ BootStrap CL &lt;- Extend CL &lt;- Application CL, 遵循 双亲/父 委托机制. ​ 根加载器负责虚拟机核心类库的加载，拓展加载器负责加载JAVA_HOME下jre\\lb\\ext下子目录的类库，系统类加载器负责加载classpath下的类库资源。 3.2 class 被加载后的内存情况 栈内存(指针) 堆区 方法区 Classloader的引用 –&gt; ClassLoader对象 A class 对象的引用 –&gt; A 的 class 对象 –&gt; A 类的数据结构 A 对象的引用 –&gt; A 对象 4 Images 5 配置&amp;调优配置说明 -Xmx：最大堆大小-Xms：初始堆大小-Xmn:年轻代大小（n：New generation）-XXSurvivorRatio：年轻代中Eden区与Survivor区的大小比值（一般对象放Eden区，S区是辅助） 为避免频繁GC，可将堆的初始值最大值改为相等。（-Xms &amp; -Xmx） 这是默认的配置(idea.vmoptions): 1234567891011121314151617-Xms128m-Xmx1024m-XX:ReservedCodeCacheSize=512m-XX:+UseConcMarkSweepGC // CMS 垃圾回收器-XX:SoftRefLRUPolicyMSPerMB=50-XX:CICompilerCount=2-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-ea-Dsun.io.useCanonCaches=false-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-Djdk.attach.allowAttachSelf=true-Djdk.module.illegalAccess.silent=true-Dkotlinx.coroutines.debug=off-XX:ErrorFile=$USER_HOME/java_error_in_idea_%p.log-XX:HeapDumpPath=$USER_HOME/java_error_in_idea.hprof 太困了之后再写… 6 Java 版本6.1 发布日期JDK 1.0 1996-01-23 发布 JDK 1.1 1997-02-19 发布 JDK 1.2 1998-12-04 发布 JDK 1.3 2000-05-08 发布 JDK 1.4 2002-02-13 发布正则表达式，异常链，NIO，日志类，XML解析器，XLST 转换器 JDK 1.5/5.0 2004-09-30 发布自动装箱、泛型、动态注解、枚举、可变长参数、遍历循环 JDK 1.6/6.0 2006-04 提供动态语言支持、提供编译 API 和卫星 HTTP 服务器 API，改进 JVM 的锁，同步垃圾回收，类加载 JDK 1.7/7.0 2011-07-28 发布提供GI回收器、加强对非Java语言的调用支持（JSR-292,升级类加载架构 JDK 1.8/8.0 2014-03-18 发布Lambda 表达式、方法引用、默认方法、新工具、Stream API、Date Time API 、Optional 类、Nashorn, JavaScript 引擎 JDK 9.0 2017-09-21 发布JShell、不可变集合工厂方法、模块系统、http协议2.0版本、Process API/CompletableFuture API/Optional Class/Stream API增强、匿名内部类的钻石操作符、默认G1垃圾回收器、try语句语法改进 JDK 10.0 2018-03-21 发布JIT 编译器、局部变量类型引用、数据类型共享、并行GC、root 证书、javah工具、堆分配 JDK 11.0 2018-09-25 发布单命令运行Java文件、Lambda 参数局部变量语法、基于嵌套访问控制、动态类文件常量、误操作垃圾回收器、删除Java EE和 CORBA 模块、ChaCha20与Poly1305加密算法、Aarch64增强、ZGC试用、弃用 Nashorn JS引擎 JDK 12.0 2019-03-19 发布JVM 增强、Switch 表达式、文件 mismatch() 方法、String 新方法 indent()/transform()/describeConstable()/resolveConstantDesc()、JVM常量API、instanceof 模式匹配 JDK 13.0 2019-09-17 发布支持编写文本块、Switch 表达式增强、重构遗留的 Socket API、取消提交未使用内存、动态CDS存档、支持Unicode 12.1、DOM 和 SAX 工厂支持命名空间 JDK 14.0 2020-03-17 发布空指针异常增强提示、Switch 表达式（标准）、instanceof 模式匹配（预览）、Records 类（预览）、文本块（第二次预览）、打包工具（孵化）、JFR 事件流、ZGC ( 支持 macOS 和 Windows )、外部存储器访问API（孵化） JDK 15.0 2020-09-15 发布密封类（预览）、instanceof 模式匹配（第二次预览）、Records 类（第二次预览）、文本块（标准）、隐藏类、删除 Nashorn JS引擎、重构遗留的 DatagramSocket API、外部存储器访问API（第二次孵化）、弃用RMI激活、移除 Solaris 和 SPARC 的端口 JDK 16.0 2020-12-10 第一次提案冻结2021-01-14 第二次提案冻结2021-02-04 发布第一个预览版本2021-02-18 发布第二个预览版本2021-03-16 正式发布 JDK 17.0 2021-09-15 正式发布 6.2 JDK 9~17 功能特性 java 9: G1 java 11: ZGC JDK9最大特性是引入了模块化机制，并把之前的rt.jar做了拆分。 在Java9之后引入了模块化的概念，是将类型和资源封装在模块中，并仅导出其他模块要访问其公共类型的软件包。如果模块中的软件包未导出或打开，则表示模块的设计人员无意在模块外部使用这些软件包。 这样的包可能会被修改或甚至从模块中删除，无需任何通知。 如果仍然使用这些软件包通过使用命令行选项导出或打开它们，可能会面临破坏应用程序的风险！ 以下几个包变成了独立的jar依赖： JAF(javax.activation） CORBA(java.corba) JTA (java.transaction) JAXB和JAX-WS Common Annotations 项目中如果有使用，需要添加引用。 ClassLoader变化带来的URLClassLoader的变化 Java 8的ClassLoader流程： bootstrap classloader加载rt.jar，jre/lib/endorsedext classloader加载jre/lib/extapplication classloader加载-cp指定的类 java9及之后的classloader流程： bootstrap classloader加载lib/modulesext classloader更名为platform classloader，加载lib/modulesapplication classloader加载-cp，-mp指定的类同时，我们注意到，JDK9开始，AppClassLoader他爹不再是 URLClassLoader JDK10最大特点是改进并行全垃圾回收器 G1。 大家如果接触过 Java 性能调优工作，应该会知道，调优的最终目标是通过参数设置来达到快速、低延时的内存垃圾回收以提高应用吞吐量，尽可能的避免因内存回收不及时而触发的完整 GC（Full GC 会带来应用出现卡顿）。 G1 垃圾回收器是 Java 9 中 Hotspot 的默认垃圾回收器，是以一种低延时的垃圾回收器来设计的，旨在避免进行 Full GC，但是当并发收集无法快速回收内存时，会触发垃圾回收器回退进行 Full GC。之前 Java 版本中的 G1 垃圾回收器执行 GC 时采用的是基于单线程标记扫描压缩算法（mark-sweep-compact）。为了最大限度地减少 Full GC 造成的应用停顿的影响，Java 10 中将为 G1 引入多线程并行 GC，同时会使用与年轻代回收和混合回收相同的并行工作线程数量，从而减少了 Full GC 的发生，以带来更好的性能提升、更大的吞吐量。Java 10 中采用并行化 mark-sweep-compact 算法，并使用与年轻代回收和混合回收相同数量的线程。具体并行 GC 线程数量可以通过：-XX:ParallelGCThreads 参数来调节，但这也会影响用于年轻代和混合收集的工作线程数 基于 Java 的 实验性 JIT 编译器：Java 10 中开启了基于 Java 的 JIT 编译器 Graal，并将其用作 Linux/x64 平台上的实验性 JIT 编译器开始进行测试和调试工作，另外 Graal 将使用 Java 9 中引入的 JVM 编译器接口（JVMCI）。 Graal 是一个以 Java 为主要编程语言、面向 Java bytecode 的编译器。与用 C++实现的 C1 及 C2 相比，它的模块化更加明显，也更加容易维护。Graal 既可以作为动态编译器，在运行时编译热点方法；亦可以作为静态编译器，实现 AOT 编译。在 Java 10 中，Graal 作为试验性 JIT 编译器一同发布（JEP 317）。将 Graal 编译器研究项目引入到 Java 中，或许能够为 JVM 性能与当前 C++ 所写版本匹敌（或有幸超越）提供基础。 Java 10 中默认情况下 HotSpot 仍使用的是 C2 编译器，要启用 Graal 作为 JIT 编译器，请在 Java 命令行上使用以下参数： -XX：+ UnlockExperimentalVMOptions -XX：+ UseJVMCICompiler JDK11（LTS）最大变化时Linux版本新增了ZGC。 ZGC在Linux x64下的JDK11以上可用，Mac和Windows上需要JDK15可用。 Java11 ZGC实测gc时间稳定在3ms左右（当然也许跟场景有关，官方口径一般在10ms以下）。 ZGC：这应该是JDK11最为瞩目的特性，没有之一。但是后面带了Experimental，说明还不建议用到生产环境。看看官方对这个特性的目标描述： GC暂停时间不会超过10ms； 即能处理几百兆小堆，也能处理几个T的大堆（OMG）； 和G1相比，应用吞吐能力不会下降超过15%； 为未来的GC功能和利用colord指针以及Load barriers优化奠定基础； 初始只支持64位系统； GC是Java主要优势之一。然而，当GC停顿太长，就会开始影响应用的响应时间。消除或者减少GC停顿时长，Java将对更广泛的应用场景是一个更有吸引力的平台。此外，现代系统中可用内存不断增长， 用户和程序员希望JVM能够以高效的方式充分利用这些内存，并且无需长时间的GC暂停时间。 ZGC一个并发，基于region，压缩型的垃圾收集器，只有root扫描阶段会STW，因此GC停顿时间不会随着堆的增长和存活对象的增长而变长。 ZGC和G1停顿时间比较： Plain Text ZGC avg: 1.091ms (+/-0.215ms) 95th percentile: 1.380ms 99th percentile: 1.512ms 99.9th percentile: 1.663ms 99.99th percentile: 1.681ms max: 1.681ms G1 avg: 156.806ms (+/-71.126ms) 95th percentile: 316.672ms 99th percentile: 428.095ms 99.9th percentile: 543.846ms 99.99th percentile: 543.846ms max: 543.846ms 用法： Plain Text -XX:+UnlockExperimentalVMOptions -XX:+UseZGC 因为ZGC还处于实验阶段，所以需要通过JVM参数UnlockExperimentalVMOptions 来解锁这个特性。 不过目前 ZGC 还处于实验阶段，目前只在 Linux/x64 上可用，如果有足够的需求，将来可能会增加对其他平台的支持。同时作为实验性功能的 ZGC 将不会出现在 JDK 构建中，除非在编译时使用 configure 参数：–with-jvm-features=zgc 显式启用。 在实验阶段，编译完成之后，已经迫不及待的想试试 ZGC，需要配置以下 JVM 参数，才能使用 ZGC，具体启动 ZGC 参数如下： -XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC -Xmx10g 其中参数：-Xmx 是 ZGC 收集器中最重要的调优选项，大大解决了程序员在 JVM 参数调优上的困扰。ZGC 是一个并发收集器，必须要设置一个最大堆的大小，应用需要多大的堆，主要有下面几个考量： - 对象的分配速率，要保证在 GC 的时候，堆中有足够的内存分配新对象。 - 一般来说，给 ZGC 的内存越多越好，但是也不能浪费内存，所以要找到一个平衡。 Java11中还新引入的Epsilon–神兽貔貅一般只吃不拉，所以就不回收和释放内存，非常适合用来做性能分析。 Epsilon垃圾回收器的目标是开发一个控制内存分配，但是不执行任何实际的垃圾回收工作。它提供一个完全消极的 GC 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间。 Java 版本中已经包含了一系列的高度可配置化的 GC 实现。各种不同的垃圾回收器可以面对各种情况。但是有些时候使用一种独特的实现，而不是将其堆积在其他 GC 实现上将会是事情变得更加简单。 Epsilon 垃圾回收器和其他垃圾回收器一样，可以通过参数-XX:+UseEpsilonGC 开启。 JDK12Java 12 中引入一个新的垃圾收集器：Shenandoah，它是作为一中低停顿时间的垃圾收集器而引入到 Java 12 中的，其工作原理是通过与 Java 应用程序中的执行线程同时运行，用以执行其垃圾收集、内存回收任务，通过这种运行方式，给虚拟机带来短暂的停顿时间。 Shenandoah 垃圾回收器是 Red Hat 在 2014 年宣布进行的一项垃圾收集器研究项目，旨在针对 JVM 上的内存收回实现低停顿的需求。该设计将与应用程序线程并发，通过交换 CPU 并发周期和空间以改善停顿时间，使得垃圾回收器执行线程能够在 Java 线程运行时进行堆压缩，并且标记和整理能够同时进行，因此避免了在大多数 JVM 垃圾收集器中所遇到的问题。 据 Red Hat 研发 Shenandoah 团队对外宣称，Shenandoah 垃圾回收器的暂停时间与堆大小无关，这意味着无论将堆设置为 200 MB 还是 200 GB，都将拥有一致的系统暂停时间，不过实际使用性能将取决于实际工作堆的大小和工作负载。 Shenandoah在Linux x64下的JDK12以上可用（在由Red Hat 公司发行的Linux版本redhat/centos上，可以backport到JDK8的高版本），Mac和Windows上需要JDK15可用。 Shennadoah工作周期如下： Init Mark 启动并发标记 阶段并发标记遍历堆阶段并发标记完成阶段并发整理回收无活动区域阶段并发 Evacuation 整理内存区域阶段Init Update Refs 更新引用初始化 阶段并发更新引用阶段Final Update Refs 完成引用更新阶段并发回收无引用区域阶段需要了解不是唯有 GC 停顿可能导致常规应用程序响应时间比较长。具有较长的 GC 停顿时间会导致系统响应慢的问题，但响应时间慢并非一定是 GC 停顿时间长导致的，队列延迟、网络延迟、其他依赖服务延迟和操作提供调度程序抖动等都可能导致响应变慢。 使用 Shenandoah 时需要全面了解系统运行情况，综合分析系统响应时间。各种 GC 工作负载对比如下所示： 推荐几个配置或调试 Shenandoah 的 JVM 参数: -XX:+AlwaysPreTouch：使用所有可用的内存分页，减少系统运行停顿，为避免运行时性能损失。 -Xmx == -Xms：设置初始堆大小与最大值一致，可以减轻伸缩堆大小带来的压力，与 AlwaysPreTouch 参数配合使用，在启动时提交所有内存，避免在最终使用中出现系统停顿。 -XX:+ UseTransparentHugePages：能够大大提高大堆的性能，同时建议在 Linux 上使用时将 /sys/kernel/mm/transparent_hugepage/enabled 和 /sys/kernel/mm/transparent_hugepage/defragv 设置为：madvise，同时与 AlwaysPreTouch 一起使用时，init 和 shutdownv 速度会更快，因为它将使用更大的页面进行预处理。 -XX:+UseNUMA：虽然 Shenandoah 尚未明确支持 NUMA（Non-Uniform Memory Access），但最好启用此功能以在多插槽主机上启用 NUMA 交错。与 AlwaysPreTouch 相结合，它提供了比默认配置更好的性能。 -XX:+DisableExplicitGC：忽略代码中的 System.gc() 调用。当用户在代码中调用 System.gc() 时会强制 Shenandoah 执行 STW Full GC ，应禁用它以防止执行此操作，另外还可以使用 -XX:+ExplicitGCInvokesConcurrent，在 调用 System.gc() 时执行 CMS GC 而不是 Full GC，建议在有 System.gc() 调用的情况下使用。不过目前 Shenandoah 垃圾回收器还被标记为实验项目，需要使用参数：- XX:+UnlockExperimentalVMOptions 启用。更多有关如何配置、调试 Shenandoah 的信息，请参阅 henandoah wiki。 注意，ZGC和Shenandoah GC都可以看做是Azul 公司提出的无停顿GC（Pauseless GC）的开源实现版本。 Java12中继续改善了G1 GC G1 是垃圾收集器，设计用于具有大量内存的多处理器机器，提高了垃圾回收效率。该垃圾收集器 设计的主要目标之一是满足用户设置的预期的 JVM 停顿时间，G1 采用一个高级分析引擎来选择在收集期间要处理的工作量，此选择过程的结果是一组称为 GC 回收集的区域。一旦收集器确定了 GC 回收集 并且 GC 回收、整理工作已经开始，则 G1 收集器必须完成收集集合集的所有区域中的所有活动对象之后才能停止；但是如果收集器选择过大的 GC 回收集，可能会导致 G1 回收器停顿时间超过预期时间。 Java 12 中将把 GC 回收集（混合收集集合）拆分为必需和可选两部分，使 G1 垃圾回收器能中止垃圾回收过程。其中必需处理的部分包括 G1 垃圾收集器不能递增处理的 GC 回收集的部分（如：年轻代），同时也可以包含老年代以提高处理效率。将 GC 回收集拆分为必需和可选部分时，需要为可选 GC 回收集部分维护一些其他数据，这会产生轻微的 CPU 开销，但小于 1 ％的变化，同时在 G1 回收器处理 GC 回收集期间，本机内存使用率也可能会增加，使用上述情况只适用于包含可选 GC 回收部分的 GC 混合回收集合。 在 G1 垃圾回收器完成收集需要必需回收的部分之后，便开始收集可选的部分，如果还有时间的话，但是粗粒度的处理，可选部分的处理粒度取决于剩余的时间，一次只能处理可选部分的一个子集区域。在完成可选收集部分的收集后，G1 垃圾回收器可以根据剩余时间决定是否停止收集。如果在处理完 必需处理的 部分后，属于时间不足，总时间花销接近预期时间，G1 垃圾回收器也可以中止可选部分的回收以达到满足预期停顿时间的目标。 Java12增强G1 垃圾收集器：自动返回未用堆内存给操作系统 Java 12 中增强了 G1 垃圾收集器关于混合收集集合的处理策略，使其能够在空闲时自动将 Java 堆内存返还给操作系统，这也是 Java 12 中的另外一项重大改进。 目前 Java 11 版本中包含的 G1 垃圾收集器 暂时无法及时将已提交的 Java 堆内存返回给操作系统， G1 垃圾收集器仅在进行完整 GC (Full GC) 或并发处理周期时才能将 Java 堆返回内存。由于 G1 回收器尽可能避免完整 GC，并且只触发基于 Java 堆占用和分配活动的并发周期，因此在许多情况下 G 1 垃圾回收器不能回收 Java 堆内存，除非有外部强制执行。 在使用云平台的容器环境中，这种不利之处特别明显。即使在虚拟机不活动，但如果仍然使用其分配的内存资源，哪怕是其中的一小部分，G1 回收器也仍将保留所有已分配的 Java 堆内存。而这将导致用户需要始终为所有资源付费，哪怕是实际并未用到，而云提供商也无法充分利用其硬件。如果在次期间虚拟机能够检测到 Java 堆内存的实际使用情况，并在利用空闲时间自动将 Java 堆内存返还，则两者都将受益。 为了尽可能的向操作系统返回空闲内存，G1 垃圾收集器将在应用程序不活动期间定期生成或持续循环检查整体 Java 堆使用情况，以便 G 1 垃圾收集器能够更及时的将 Java 堆中不使用内存部分返还给操作系统。对于长时间处于空闲状态的应用程序，此项改进将使 JVM 的内存利用率更加高效。 如果应用程序为非活动状态，在下面两种情况下，G1 回收器会触发定期垃圾收集： 自上次垃圾回收完成 以来已超过 G1PeriodicGCInterva l 毫秒， 并且此时没有正在进行的垃圾回收任务。如果 G1PeriodicGCInterval 值为零表示禁用快速回收内存的定期垃圾收集。 应用所在主机系统上执行方法 getloadavg()，一分钟内系统返回的平均负载值低于 G1PeriodicGCSystemLoadThreshold。如果 G1PeriodicGCSystemLoadThreshold 值为零，则此条件不生效。 如果不满足上述条件中的任何一个，则取消当期的定期垃圾回收。等一个 G1PeriodicGCInterval 时间周期后，将重新考虑是否执行定期垃圾回收。 G1 定期垃圾收集的类型根据 G1PeriodicGCInvokesConcurrent 参数的值确定：如果设置值了，G1 垃圾回收器将继续上一个或者启动一个新并发周期；如果没有设置值，则 G1 回收器将执行一个完整的 GC。在每次一次 GC 回收末尾，G1 回收器将调整当前的 Java 堆大小，此时便有可能会将未使用内存返还给操作系统。新的 Java 堆内存大小根据现有配置确定，具体包括下列配置：- XX:MinHeapFreeRatio、-XX:MaxHeapFreeRatio、-Xms、-Xmx。 默认情况下，G1 回收器在定期垃圾回收期间新启动或继续上一轮并发周期，将最大限度地减少应用程序的中断。如果定期垃圾收集严重影响程序执行，则需要考虑整个系统 CPU 负载，或让用户禁用定期垃圾收集。 JDK13Java13增强ZGC：释放未使用内存 ZGC 是 Java 11 中引入的最为瞩目的垃圾回收特性，是一种可伸缩、低延迟的垃圾收集器，不过在 Java 11 中是实验性的引入，主要用来改善 GC 停顿时间，并支持几百 MB 至几个 TB 级别大小的堆，并且应用吞吐能力下降不会超过 15%，目前只支持 Linux/x64 位平台的这样一种新型垃圾收集器。 通过在实际中的使用，发现 ZGC 收集器中并没有像 Hotspot 中的 G1 和 Shenandoah 垃圾收集器一样，能够主动将未使用的内存释放给操作系统的功能。对于大多数应用程序来说，CPU 和内存都属于有限的紧缺资源，特别是现在使用的云上或者虚拟化环境中。如果应用程序中的内存长期处于空闲状态，并且还不能释放给操作系统，这样会导致其他需要内存的应用无法分配到需要的内存，而这边应用分配的内存还处于空闲状态，处于”忙的太忙，闲的太闲”的非公平状态，并且也容易导致基于虚拟化的环境中，因为这些实际并未使用的资源而多付费的情况。由此可见，将未使用内存释放给系统主内存是一项非常有用且亟需的功能。 ZGC 堆由一组称为 ZPages 的堆区域组成。在 GC 周期中清空 ZPages 区域时，它们将被释放并返回到页面缓存 ZPageCache 中，此缓存中的 ZPages 按最近最少使用（LRU）的顺序，并按照大小进行组织。在 Java 13 中，ZGC 将向操作系统返回被标识为长时间未使用的页面，这样它们将可以被其他进程重用。同时释放这些未使用的内存给操作系统不会导致堆大小缩小到参数设置的最小大小以下，如果将最小和最大堆大小设置为相同的值，则不会释放任何内存给操作系统。 Java 13 中对 ZGC 的改进，主要体现在下面几点： 释放未使用内存给操作系统 支持最大堆大小为 16TB 添加参数：-XX:SoftMaxHeapSize 来软限制堆大小 这里提到的是软限制堆大小，是指 GC 应努力是堆大小不要超过指定大小，但是如果实际需要，也还是允许 GC 将堆大小增加到超过 SoftMaxHeapSize 指定值。主要用在下面几种情况：当希望降低堆占用，同时保持应对堆空间临时增加的能力，亦或想保留充足内存空间，以能够应对内存分配，而不会因为内存分配意外增加而陷入分配停滞状态。不应将 SoftMaxHeapSize 设置为大于最大堆大小（-Xmx 的值，如果未在命令行上设置，则此标志应默认为最大堆大小。 Java 13 中，ZGC 内存释放功能，默认情况下是开启的，不过可以使用参数：-XX：-ZUncommit 显式关闭，同时如果将最小堆大小 (-Xms) 配置为等于最大堆大小 (-Xmx)，则将隐式禁用此功能。 还可以使用参数：-XX：ZUncommitDelay = （默认值为 300 秒）来配置延迟释放，此延迟时间可以指定释放多长时间之前未使用的内存。 JDK14感觉变化不大。 加入了java打包工具jpackage的预览版。 加入了类似kotlin中的data object的数据类型：记录Record（https://openjdk.java.net/jeps/359）： record Point(int x, int y) { } 参见：https://www.infoworld.com/article/3436795/jdk-14-the-new-features-in-java-14.html JDK15ZGC将从实验功能升级为产品。ZGC已集成到2018年9月发布的JDK 11中，是一个可扩展的低延迟垃圾回收器。引入ZGC是一项实验功能，因为Java的开发人员决定应谨慎而逐步地引入这种大小和复杂性的功能。从那时起，已经添加了许多改进，从并发类卸载，未使用内存的未提交，对数据类共享的支持到改进的NUMA感知和多线程堆预触。此外，最大堆大小已从4 TB增加到16 TB。支持的平台包括Linux，Windows和MacOS。 同样的，还有Shenandoah GC。 参见：https://www.infoworld.com/article/3534133/jdk-15-the-new-features-in-java-15.html JDK161）最大的变化就是引入Record，Records 就是一种新的语法糖，目的还是为了简化代码，在 JDK 14 中首次成为预览特性，在 JDK 16 中正式转正。熟悉kotlin的同学，可以看做是data object类。 Records 可以在一定程度上避免低级冗余的代码，比如：constructors, getters, equals(), hashCode(), toString() 方法等，相当于 Lombok 的 @Data 注解，但又不能完全替代。 下面来看一个示例： Plain Text public record Student(String name, int id, int age) {} 这样就完成 完成了整个pojo类的定义。 2）JDK16 将提供一款名为 jpackage 的工具，用于独立打包 Java 应用程序。 jpackage 在 JDK 14 中被作为孵化工具引入，并在 JDK 15 中仍处于孵化阶段。到了JDK 16，jpackage 将投入生产，支持本地的软件包格式，从而为用户提供自然的安装体验，并允许在打包时指定启动时参数。支持的格式包括 Windows 上的 msi 和 exe ，MacOS 上的 pkg 和 dmg 以及 Linux 上的 deb 和 rpm 。该工具可以直接从命令行或以编程方式调用。新的打包工具解决了这样一种情况：许多Java应用程序需要以全局可用的方式安装在本机平台上，而不是简单地放置在类路径或模块路径上。因此提供适合本机平台的可安装软件包非常有必要。 参见：https://www.infoworld.com/article/3569150/jdk-16-the-new-features-in-java-16.html 3）Pattern Matching for instanceof 模式匹配 for instanceof，相当于是增强的 instanceof，在 JDK 14 中首次成为预览特性，在 JDK 16 中正式转正。 模式匹配的到来将使得 instanceof 变得更简洁、更安全，为什么这么说，请看下面的示例。 正常的 instanceof 写法： Plain Text if (object instanceof Kid) { Kid kid = (Kid) object; // … } else if (object instanceof Kiddle) { Kid kid = (Kid) object; // … } 模式匹配的 instanceof 写法： Plain Text if (object instanceof Kid kid) { // … } else if (object instanceof Kiddle kiddle) { // … } 此外，还把openjdk源码迁移到了github。 参见：https://www.cnblogs.com/javastack/p/14583578.html JDK171）增强了伪随机数算法。 2）移除AOT提前编译和JIT即时编译的功能，Oracle JDK16 未包含此功能。 3）sealed修饰的类和接口限制其他的类或者接口的扩展和实现。说白了就是限制类的继承或者接口的实现数量。 4）进一步增强了switch语法的模式匹配，万物皆可switch下使用了。 此版本的变化较小。 6.3 JDK版本机制Oracle Java 平台组的首席架构师 Mark Reinhold 在博客上介绍了有关 Java 未来版本的一些想法（你能接受 Java 9 的下一个版本是 Java 18.3 吗？）。他提到，Java 计划按照时间来发布，每半年一个版本，而不是像之前那样按照重要特性来确定大版本，如果某个大的特性因故延期，这个版本可能一拖再拖。 当时，Mark 也提出来一种基于时间命名版本号的机制，比如下一个将于 2018 年 3 月发布的版本，就是 18.3，再下一个版本是 18.9，以后版本依此类推。 不过经过讨论，考虑和之前版本号的兼容等问题，最终选择的命名机制是： $FEATURE.$INTERIM.$UPDATE.$PATCH $FEATURE，每次版本发布加 1，不考虑具体的版本内容。2018 年 3 月的版本是 JDK 10，9 月的版本是 JDK 11，依此类推。 $INTERIM，中间版本号，在大版本中间发布的，包含问题修复和增强的版本，不会引入非兼容性修改。 目前JDK每半年升一个大版本，其中JDK8和11是LTS长期维护版本，8的维护周期预计比11还要长。下一个可能是JDK17（大概会在2021年的Q3发布）。期望8以后，大家直接升级到17。 每六个月发布一个大更新（就是每年的3月还有9月） 对于每个大版本更新，会有两次小版本更新（在发布后一个月或者四个月之后） OpenJDK已可以作为新的线上标准JDK 在2018.9之前，Oracle JDK是大家普遍运用于线上的JDK，OpenJDK的特性并不完全，并且Oracle JDK号称做了很多优化。在2018.9之后，Oracle JDK正式商用（开发不收费，但是运行线上业务收费）。但是与此同时，Oracle宣布，OpenJDK与Oracle JDK在功能上不会有区别。并且，OpenJDK 11 RTS将会由红帽社区进行维护。这样，更加增加了可靠性与保证问题的及时解决。 2021-9-15 JDK17发布的同时，Oracle JDK宣布免费。 6.4 Oracle免费JDKOracle JDK收费一直被好多人吐槽，这次是推出了Free Java License 大致摘要： Oracle 长在免费提供JDK，包括所有季度安全更新，其中也包括商业和生产用途。 本次Oracle JDK许可证允许所有用户免费使用，再分发也允许； 程序员和企业现在无需点击即可轻松下载、使用、共享和重新分发 Oracle JDK。 Oracle 将从Oracle JDK 17开始提供这些免费版本和更新，并在下一个 LTS 版本之后继续提供整整一年。以前的版本不受此更改的影响。 Oracle 将继续按照自 Java 9 以来的相同版本和时间表提供GPL下的Oracle OpenJDK 版本。 解释一下目前在免费许可证下可以商用，其次就是Spring也官宣了，明年发布的Spring framework 6 和Spring Boot 3 都将基于JAVA 17，大家还要坚守Java8吗？","link":"/2021/03/02/JVM/"},{"title":"grpc","text":"… gRPCproject address: https://github.com/grpc/grpc-java","link":"/2021/11/01/grpc/"},{"title":"☁️ 我的网易云歌单 ☁️","text":"","link":"/2021/02/26/music/"},{"title":"mysql集群","text":"… MYSQL1. Cluster 集群MySQL 集群方案主要有下述几种： 常用的有Replications，即所谓的**读写分离(一主多从master+slaves机制)**；而MySQL Cluster 为官方推崇的方案。与常见的InnoBD不同，使用的是NDB引擎。当需要做分片的时候，InnoDB是不满足条件的。 MySQL Cluster 解决了主从的许多问题。比如最为严重的数据不一致情况(异步复制的缺陷)。故障恢复（由NDB管理节点控制）等。 1.1 Replications(读写分离)搭建todo ?? 相关命令SHOW SLAVE STATUS 读库延迟问题的处理数据在master主库更新成功后，再通过binlog异步复制到slaves上。而这个过程有一定的延迟，可能导致读出来的数据不是最新的。 解决方法：写操作语句并做事务提交(@Transational)。 主从切换的处理master意外挂掉后，需要其中一个slave来做新的master，即failover(故障切换)。该过程存在一定风险，因为异步复制的延迟性，可能导致新master的数据不完整。 解决方法：半同步。即master做事务提交前，需要至少一个slave ACK(通知)master数据已成功复制。再人工(DBM)找到有最新binlog的slave，并配置为新的master。但是当出现下图的情况，即master来不及收到ack导致没有提交事务，就会产生slave的数据比master多的情况(似乎也没有坏处)。虽然可以通过TCC来解决，但是由于性能考量故只能用半同步的方案折中解决。 1.2 PXC Percona XtraDB Cluster, 与 MySQL Cluster 功能相似，但是使用的是InnoDB引擎。两者对比使用者：微软，IBM官网地址：https://www.percona.com 搭建创建 docker 通信网络，可用 docker inpect 查询网络具体信息(IPAM) 1docker network create --subnet=172.18.0.0/24 pxc-net 由于无法映射目录，故在主机上创建 docker volume目录 123docker volume create v1docker volume create v2docker volume create v3 https://hub.docker.com/r/percona/percona-xtradb-cluster/ 12docker pull percona/percona-xtradb-cluster-operatordocker tag percona/percona-xtradb-cluster-operator pxc 运行 mysql 节点 (注意要等待运行完成后，才能继续运行下一个节点。) 1docker run -d -p 3306:3306 -v v1:/var/lib/mysql -e MYSQL_ROOOT_PASSWORD=123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=123456 --privileged --name=node1 --net=pxc-net --ip 172.18.0.2 pxc 1docker run -d -p 3307:3306 -v v2:/var/lib/mysql -e MYSQL_ROOOT_PASSWORD=123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_JOIN=node1 --privileged --name=node2 --net=pxc-net --ip 172.18.0.3 pxc 1docker run -d -p 3308:3306 -v v3:/var/lib/mysql -e MYSQL_ROOOT_PASSWORD=123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=123456 -e CLUSTER_JOIN=node1 --privileged --name=node3 --net=pxc-net --ip 172.18.0.4 pxc 数据库负载均衡 使用 Haproxy 仓库地址：https://hub.docker.com/_/haproxy 配置介绍：https://zhangge.net/5125.html 使用 MySQL-Proxy/Router 2. mysql 常见问题2.1 备份 mysql dump 命令：类似redis的rdb机制，全量备份。无法像aos一样增量备份 XtraBackup 最佳的备份方法：第一次备份使用全量备份，再使用增量备份。 进入容器内部安装 xtrabackup：apt-get install percona-xtrabackup-24安装完成后，执行全量备份：innobackupex --user=root --password=123456 /data/backup/full 恢复备份： 回滚未提交的事务：innobackupex --user=root --password=123456 --apply-back /data/backup/full 恢复备份：innobackupex --user=root --password=123456 --copy-back /data/backup/full 3. 主从搭建 bin_log：mysql-binlog是MySQL数据库的二进制日志，用于记录用户对数据库操作的SQL语句（除了select语句）信息。可以使用mysqlbin命令查看二进制日志的内容。 binary log 格式： 4. 数据分片 A 固定路由位：以 userId (hash + mod) 为维度分片，才方便在一个数据库中查询。以 orderId 为维度，则需要聚合多个不同库之间的数据。 B 时间自增分片：如 一年 内订单数据。 聚合数据处理：","link":"/2021/10/29/mysql%E9%9B%86%E7%BE%A4/"},{"title":"java开发手册","text":"… 第 1 章 编程规约1.1 命名风格 POJO 中的 Boolean 变量都不要加 is 前缀，否则部分框架（如 RPC）解析会引起序列化错误。 反例：如 Boolean isDeleted RPC 框架反向解析的时候，会识别为 deleted，导致属性获取不到抛出异常。 接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码简洁，并加上有效的 Javadoc 注释。尽量不要在接口中定义变量，除非是常量。 正例：方法签名：void commit() 基础常量：String COMPANY = &quot;alibaba&quot; 枚举类名建议带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。 说明：枚举其实就是特殊的常量类，且构造方法被默认强制为私有。正例：枚举类名为 ProcessStatusEnum，成员名称有 SUCCESS / UNKNOW_REASON 各层命名规约： 1). Service / DAO 层 method 命名规约： a. 获取单个对象的方法用 get 作为前缀b. 获取多个对象的方法用 list 作为前缀c. 插入的方法用 save / insert 作为前缀d. 删除的方法用 remove / delete 作为前缀e. 修改的方法用 update 作为前缀f. 获取统计值的方法用 count 作为前缀 2). 领域模型命名规约： a. 数据对象：xxxDO，xxx 为数据库表名。b. 数据传输对象：xxxDTO，xxx 为业务领域相关的名称。c. 展示对象：xxxVO，xxx 一般为网页名称。d. POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。 1.2 常量定义 不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。 反例： 12String key = &quot;Id#taobao_&quot; + tradeId; # &quot;Id#taobao&quot; 应该定义为常量。catch.put(key, value); 如果变量值仅在一个范围内变化，则用 enum 类型来定义。 正例： 1234567pubilc enum SeasonEnum { SPRING(1), SUMMER(2), AUTUMN(3), WINTER(4); private int seq; SeasonEnum(int seq) { this.seq = seq; }} 1.3 代码格式 一行代码的大括号不换行。 1.4 OOP 规约 Object 的 equals 方法容易抛空指针异常，应使用常量或有值的对象来调用 equals。 正例：&quot;test&quot;.equals(object);反例：object.equals(&quot;test&quot;); 所有相同类型的包装类对象之间 value 的比较，全部使用 equals 方法。但是要注意 Integer var = ？在 -128 ~ 127 范围内的赋值是同一个对象（取自 IntegerCache.cache ），所以可以直接使用 == 进行判断。但是推荐使用 equals 方法。 所有 POJO 的属性必须使用包装数据类型。POJO 类属性没有初始值，是要提醒使用者在需要使用时，必须自己显式地赋值，任何 NPE 问题，或者入库检查，都由使用者来保证。 正例：数据库的查询结果可能是 null，因为自动拆箱，所以用基本数据类型接收都有 NPE 风险。 POJO 必须写 toString 方法。 在循环体内，字符串的连接方式使用 StringBuilder 的 append 方法。用 String 拼接会产生很多个新的对象，造成内存资源浪费。 工具类不允许有 public 或 defaul 构造方法。因为工具类一般只需要一个对象，写 method 指定为 static 即可。 1.5 集合处理 在使用工具类 Arrays.asList() 把数组转换成集合后，不能使用修改集合相关的方法，如 add / remove / clear 的集合方法，否则会抛出 UnsupportOperationException 异常。因为 asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList 体现的是适配器模式，只是转换接口，后台的数据实际上还是数组。 不要再 foreach 循环里进行元素的 remove / add 操作。remove 元素使用 Iterator 方式，如果是并发操作，需要对 Iterator 对象加锁。 正例： 1234Iterator&lt;String&gt; iterator = list.iterator();while (iterator.hasNext()) { String item = iterator.next();} 在集合初始化时，推荐指定集合初始值大小。HashMap 使用 HashMap(itn initialCapacity) 初始化。 正例：initialCapacity = （元素个数 / 负载因子）+ 1。其中负载因子 load factor 默认为 0.75。如果暂时无法确定初始值大小，就设置为 16（即默认值）。反例：HashMap 需要放置 1024 个元素，由于没有设置容量初始大小，随着元素的不断增加，容量被扩大 7 次，resize 需要重建 hash 表，这会严重影响性能。 1.6 并发处理 获取单例对象需要保证线程安全，其中的方法也要保证线程安全。资源驱动类、工具类、单例工厂类都需要注意。 线程资源必须通过线程池提供，不允许在应用中自行显示创建线程。 线程池不允许使用 Executors 创建，而是通过 ThreadPoolExecutor 的方式创建，这样的处理方式能让编写代码的工程师更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 返回的线程池对象的弊端如下：1）FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2）CachedThreadPool 和 ScheduledThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 在并发修改同一记录时，为避免更新丢失需要加锁。要么在应用层加锁，要么在缓存层加锁，要么在数据库层使用乐观锁，使用 version 作为更新依据。 如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数要大于 3 次。 HashMap 在容量不够进行 resize 时，由于高并发可能出现死锁，导致 CPU 占用飙升，在开发过程中可以使用其他数据结构或加锁来规避此风险。 ThreadLocal 无法解决共享对象的更新问题， ThreadLocal 对象建议使用 static 修饰。 1.7 控制语句 在高并发场景中，避免使用 “==” 判断作为中断或退出的条件（if 语句不可信，== 条件不可取）。 说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，应使用大于或小于的区间判断条件来代替。反例：判断库存等于 0 时，停止出售。但可能因为并发问题导致库存数量小于 0 而无法停止出售。 在表达异常的分支时，尽量少用 if-else。可以改写成多个 if 语句。 不要在 if 条件语句中执行其它复杂的语句。可以将复杂的逻辑判断结果赋值给一个 boolean 变量（局部变量使用基本数据类型）。 1.8 注释规约 所有的类都必须加上作者和创建日期。 所有的枚举类型字段必须要有注释，说明每个数据项的用途。 1.9 其他 任何数据结构的构造或初始化，都应指定大小，避免因数据结构无限增长而内存。 及时清理不再使用的代码段或配置信息。 说明：对于暂时注释后续可能使用的代码，在代码三方用 “///“ 来说明注释掉代码的理由。 第 2 章 异常处理2.1 异常处理 Java 类库中定义的可以通过预检查方式规避的 RuntimeException 不应该用 catch 或 throws 的方式来处理。如：IndexOutOfBoundsException，NullPointerException 等。 正例：if (obj != null) { … }反例：try { obj.method() } catch (NullPointerException e) { … } 异常不要用来做流程控制、条件控制。 说明：异常设计的初衷是解决程序运行分钟的各种意外情况，况且异常的处理效率比条件判断的方式要低很多。 防止 NPE，是程序员的基本修养，注意产生 NPE 的场景。 1）当返回类型为基本数据类型， return 是一个包装数据类型的对象时，自动拆箱有可能产生 NPE。（equals 的值判断也会自动拆箱）反例：public int add() {return Integer 对象}，如果对象为 null，自动拆箱就会产生 NPE。即 int i = null; 会报异常。2）数据库的查询返回结果（Object）可能为 null。3）集合里的元素即使 isNotEmpty，但取出的元素也可能为 null。4）远程调用返回对象时，一律要求进行空指针判断，以防止 NPE。5）对于 Session 中获取的数据，建议进行 NPE 检查，以避免空指针。 避免出现重复的代码。Don’t repeat yourself. 2.2 日志规约 应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：appName_logType_logName.log。logType 有 stats/monitor/visit 等。 正例：在 mppserver 应用中单独监控时区转换异常，如 mppserver_monitor_timZoneConvert.log 第 3 章 单元测试 好的单元测试必须遵循 AIR 原则。即 Automatic,Independent and Repeatable. Automatic：自动执行。单元测试不准使用 System.out 进行人肉验证，不许使用 assert 验证。 123456789public void MyTest { @Rule public final SystemOutRule systemOutRule = new SystemOutRule().enableLog(); @Test public void overrideProperty() { System.out.print(&quot;hello world&quot;); assertEquals(&quot;hello world&quot;, systemOutRule.getLog()); }} … 单元测试应遵循 BCDE 原则。即 Border,Correct,Design and Error. 一般单元测试不要修改数据库的数据，自己 mock 数据测试。和数据库相关的单元测试，可以设置自动回滚机制，不给数据库造成脏数据。或者对单元测试产生的数据设立明确的 prefix or suffix。 第 4 章 安全规约第 5 章 MySQL 数据库5.1 建表规约 表达“是否”的字段，必须使用 is_xxx 的方式命名，且数据类型是 unsigned tinyint（1 表示 true，0 表示 false）。如果数据类型是 Boolean 则 POJO 对象被 RPC 调用会由于 is_xxx 属性解析错误产生问题。 表名不使用复数。DO 也一样。 小数类型为 decimal，禁止使用 float 和 double。 如果存储的字符串长度固定（或者几乎一样）（手机号、邮箱等等），则应使用 char 定长字符串。（节约空间） 任何表都应该有的 3 个字段：id，gmt_create &lt; datetime type &gt;， gmt_modified. 单表超过 500 万行或者容量超过 2 GB 时，才推荐进行分表分库。如果预计三年后的数据量无法达到这个级别，就不要在创建表时就分库分表。 设置合适的字符存储长度（包括 unsigned），不但可以节约空间，更重要的是能提高检索速度。 5.2 索引规约 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 页面搜索禁止使用左模糊或者全模糊搜索，若需要则通过搜索引擎解决。因为索引未见具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么就无法使用索引了。 注意 order by 的场景。 正例：where a = ? and b = ? order by c = ?; 索引是 a_b_c反例：索引中有范围查找，那么索引有序性无法利用，如 where a &gt; 10 order by b; 索引 a_b 无法排序。 利用延迟关联或子查询优化超多分页场景。 说明：MySQL 并不是跳过 offset 行，而是取 offset + N 行（全部），然后放弃前 offset 行，返回 N 行。所以当 offset 特别大的时候效率就会非常低。要么控制返回的总页数，要么对特定超过阈值的页数进行 SQL 改写。正例：先快速定位需要获取的 id 段，然后再关联： 1select a.字段 from 表 1 a, (select id from 表 1 where 条件 limit 100000, 20) b where a.id = b.id 建组合索引时，区分度最高的在最左边。 正例：如 where a = ? and b = ? 语句，其中 a 几乎接近唯一值，那么只需要单建 idx_a 索引即可。对 where a &gt; ? and b = ? 语句，b 的区分度更高。 5.3 SQL 语句 count(*) 统计所有，count(列名) 只统计该列不为 null 的行数。 在代码中写分页查询逻辑时，若 count 为 0 则应该直接返回，避免执行后面的分页语句。 5.4 ORM 映射 POJO 中的 Boolean 属性命名不能加 is 前缀，而数据库必须加 is_，要求在 resultMap 中进行字段与属性的映射。 SQL 相关的参数使用：#{}，用 ${} 的话容易出现 SQL 注入。 更新时也要同时更新 gmt_modified 字段。 第 6 章 工程结构6.1 应用分层6.2 二方库依赖6.3 服务器 高并发服务器建议调小 TCP 协议的 time_wait 超时时间（默认 240s）。 正例：在 Linux 服务器上可通过变更 /etc/sysctl.conf 文件去修改该默认值。# net.ipv4.tcp_fin_timeout = 30 调大服务器所支持的最大文件句柄数（File Description，简称 fd） 推荐给 JVM 设置 -XX:+HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出 dump 信息。 推荐在线上生产环境，JVM 的 Xms 和 Xmx 设置同一数值，避免在 GC 后调整堆大小带来的压力。 服务器内部重定向使用 forward；外部重定向地址使用 URL 拼装工具类来生成，否则会带来 URL 维护不一致的问题和潜在的安全风险。 第 7 章 设计规约附录 A 专有名词","link":"/2021/10/23/java%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C/"},{"title":"docker","text":"… Docker常用命令3306(本机):3306(容器) docker run hello-world(image) docker run –help docker start [容器id] docker image ls docker container ls （运行中） docker container ls –all docker container stop [name] docker container rm webserver docker rmi [iamge] docker stats docker network/volume crate/ls/rm docker inspect [image/container/network/volume] 命令的使用run 新容器docker run -p 6379:6379 -d redis:latest redis-server docker run --name test-mysql -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456. mysql 打开mysql client命令行docker run -it --rm mysql mysql -h47.94.128.66 -uroot -p 查看容器信息docker inspect [容器id] 进入容器路径docker exec -it [容器id] [/bin/bash] docker exec –help 路径映射docker -v docker run -d -p 8888:8888 -v C:/all/server/nginx-config/nginx.conf:/etc/nginx/nginx.conf:ro nginx build 构建镜像 cd 当前目录： 执行命令：docker build -t jackyofteamwang/cheers2019 .其中，jackyofteamwang/cheers2019 为镜像文件 推送：docker login docker push jackyofteamwang/cheers2019 删除 docker除了官网的方法： 查询相关软件包dpkg -l|grep docker sudo apt remove -purge dock.io 查看镜像信息1docker inspect rancher/rancher:latest 容器间的网络通信(https://blog.csdn.net/zhizhuodewo6/article/details/87706638) Docker有以下网络类型： bridge：多由于独立container之间的通信 host： 直接使用宿主机的网络，端口也使用宿主机的 overlay：当有多个docker主机时，跨主机的container通信 macvlan：每个container都有一个虚拟的MAC地址 none: 禁用网络 使用docker命令 创建 bridge 网络 1docker network create --driver bridge local-net 容器启动时指定--network [your net]和--name [your name] 这样，就可以在容器内ping [container_name]同个bridge的容器。 使用 docker-compose1234567networks: some-network: # Use a custom driver driver: custom-driver-1 other-network: # Use a custom driver which takes special options driver: custom-driver-2 Docker 构建 SpringBoot 应用基础使用命令：docker build -t jackyfangofteamwang/app.jar . Dockerfile 文件如下： 1234567891011FROM openjdk:8MAINTAINER jakcy &quot;jacky.teamwang@qq.com&quot;ENV TZ=&quot;Asia/Shanghai&quot;VOLUME /tmpADD tea-tea.jar app.jar# docker hints server portEXPOSE 8080ENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;, &quot;-jar&quot;, &quot;app.jar&quot;] 挂载日志目录： docker run -d -p 8085:8085 -v C:/all/volume/tmp:/tmp jackyfangofteamwang/chaos.jar docker-compose 构建运行docker-compose 实际上是 docker run 的命令封装。 docker-compose.yml 文件如下： 12345678910version: '2.2'services: demo: build: context: ./ dockerfile: Dockerfile image: jackyfangofteamwang/app.jar:1.0.0 # 本机端口号:docker端口 ports: - 8083:8083 注意事项 docker 的时区问题-启动容器时指定参数:-e TZ=&quot;Asia/Shanghai&quot; docker 可以使用 localhost，但是需要做端口映射（即还是使用主机端口）。 Jenkins启动命令： 12345678docker run \\ -u root \\ -d \\ -p 18080:8080 \\ -p 50000:50000 \\ -v /jacky/data/docker/jenkins-data:/var/jenkins_home \\ -v /jacky/data/docker/var/run/docker.sock:/var/run/docker.sock \\ jenkinsci/blueocean Jenkins默认用户不是root，所以连接github时需要再生成key： 进入jenkins容器后，执行命令：ssh-keygen -t rsa -C &quot;jenkins@git&quot;,cd ~/.ssh. docker cp a2119a11fbfa:/root/.ssh/id_rsa.pub /jacky/data/temp 另外一种方法，在jenkins容器内执行命令：git ls-remote -h git@github.com:cloris-cc/demo.git HEAD jenkins 插件下载速度慢 这个也可以：https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json http://mirror.xmission.com/jenkins/updates/current/update-center.json http://mirror.esuni.jp/jenkins/updates/update-center.json Docker 配置daemon.json[root@libresse-test01 ~]# cat /etc/docker/daemon.json 1234567891011{ &quot;registry-mirrors&quot;: [&quot;https://ndy7ld6k.mirror.aliyuncs.com&quot;,&quot;http://abcd1234.m.daocloud.io&quot;], &quot;graph&quot;: &quot;/guanke/datas/docker&quot;, &quot;dns&quot;: [&quot;8.8.8.8&quot;,&quot;8.8.4.4&quot;], &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2378&quot;,&quot;unix:///var/run/docker.sock&quot;], &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;:{ &quot;max-size&quot; :&quot;500m&quot;,&quot;max-file&quot;:&quot;3&quot; }} 修改 daemon.json 后1234567891011a.修改完成后reload配置文件sudo systemctl daemon-reloadb.重启docker服务sudo systemctl restart docker.servicec.查看状态sudo systemctl status docker -ld.查看服务sudo docker info 1sudo systemctl daemon-reloadsudo systemctl restart docker 远程访问见 Docker 官方文档 查看远程主机docker信息命令: docker -H tcp://ip-address:port info例如，docker -H tcp://10.100.240.124:2378 info Configuring remote access with systemd unit file Use the command sudo systemctl edit docker.service to open an override file for docker.service in a text editor. Add or modify the following lines, substituting your own values. 1[Service]ExecStart=ExecStart=/usr/bin/dockerd -H fd:// -H tcp://127.0.0.1:2375 Save the file. Reload the systemctl configuration. 1$ sudo systemctl daemon-reload Restart Docker. 1$ sudo systemctl restart docker.service Check to see whether the change was honored by reviewing the output of netstat to confirm dockerd is listening on the configured port. 1$ sudo netstat -lntp | grep dockerdtcp 0 0 127.0.0.1:2375 0.0.0.0:* LISTEN 3758/dockerd 镜像加速编辑/etc/docker/daemon.json,添加 registry-mirrors： 1{ &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;: [], &quot;debug&quot;: true, &quot;experimental&quot;: false} 挂载目录/卷目录均可自定义。如挂载自定义主机目录:/自定义容器目录。存放日志时，需要在主机上为各个微服务建立单独的日志存放目录/路径，避免存放在一起，使各个容器体积变大。 修改已启动容器时区 echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone dpkg-reconfigure -f noninteractive tzdata 使用 docker cp 命令：docker cp /etc/localtime [容器ID或者NAME]:/etc/localtime 项目应用打包 Dockerfiletag：将resources目录一同打包 1&lt;resources&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/docker&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/Dockerfile&lt;/include&gt; &lt;/includes&gt; &lt;targetPath&gt;${project.build.directory}&lt;/targetPath&gt; &lt;/resource&gt; &lt;/resources&gt; TEA Dockerfile1FROM openjdk:8MAINTAINER jakcy &quot;jacky.teamwang@qq.com&quot;ENV TZ=&quot;Asia/Shanghai&quot;VOLUME /tmpADD tea-tea.jar app.jar# docker hints server portEXPOSE 8080ENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;, &quot;-jar&quot;, &quot;app.jar&quot;] Jenkins 项目配置 1docker image rm github-demo-imgdocker build -t github-demo-img /jacky/data/docker/image/sleep 1docker psdocker stop github-demodocker run -d -p 8083:8083 -e TZ=&quot;Asia/Shanghai&quot; -v /jacky/data/docker/tmp:/tmp --rm --name github-demo github-demo-img ## 仍需挂载日志目录和切换时区 清除docker日志du -chs /tea/docker/containers/*/*json.log docker 清理命令docker system prune 找出大文件命令找出大文件命令：find . -type f -size +40M -print0 | xargs -0 du -h | sort -nr 启动 nginxnginx.conf 文件示例： 1user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events { worker_connections 1024;}http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server { listen 80; server_name www.teamwang.cn teamwang.cn; rewrite ^(.*) https://$server_name$1 permanent; } server { listen 18005; server_name www.teamwang.cn teamwang.cn; location /static { alias /usr/share/nginx/static; expires 1d; autoindex on; } }} 其中，*.conf默认有default.conf： 1server { listen 80; listen [::]:80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #}} 修改容器配置 参照该项目：https://github.com/nacos-group/nacos-docker其中的 docker-compose.yml 的 env 环境变量以文件方式提取， 如果要自定义容器的配置，建议使用 docker-compose up 命令。相应的配置在 xxx.yml 中修改即可，使用 docker-compose -f xxx.yml up。-f 是 -file 的意思。 下面是 nacos-docker 其中一个启动配置文件 standalone-mysql-5.7.yaml 1version: &quot;2&quot;services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone-mysql # 用文件方式读取 env env_file: - ../env/nacos-standlone-mysql.env volumes: - ./standalone-logs/:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot; depends_on: - mysql restart: on-failure mysql: container_name: mysql image: nacos/nacos-mysql:5.7 env_file: - ../env/mysql.env volumes: - ./mysql:/var/lib/mysql ports: - &quot;3306:3306&quot; prometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - &quot;9090:9090&quot; depends_on: - nacos restart: on-failure grafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failure 查看容器ip address命令：docker inspect container_id Gateway是本机！替代localhost! docker 进阶1. 服务编排1.1 Mesos1.2 DockerSwarm 教程：https://www.bookstack.cn/read/docker-swarm-guides/kai-shi-shi-yong-swarm-swarmmo-shi-duan-kou-lu-you.md 概念 服务发现机制： Ingress：overlay 网络 快速开始 Attention: 开放 manager 主机TCP 2377端口(也可以自定义) 开放所有节点的 TCP/UDP 7946端口用于container服务发现 UDP 4789端口用于overlay网络通信。 初始化集群(Manager * 1)docker swarm init --advertise-addr &lt;MANAGER-IP&gt;:&lt;PORT&gt; 1docker swarm join --token SWMTKN-1-28bihq1uqncv0whwd5laj01kmgdx32oqp1crkzopn80087tvl8-aokefgdf485ju7cj85zk9qapn 47.94.128.66:2377 加入工作节点(Node * n)docker swarm join --token &lt;TOKEN&gt; &lt;MANAGER-IP&gt;:&lt;PORT&gt; 疏散当前节点docker swarm leave 提升worker为managerdocker node lsdocker node promote [hostname] 常用命令创建自定义网络： docker network create --driver=overlay --attachable mynet 发布服务：docker service create --replicas 1 --name helloworld alpine ping docker.com服务更新：docker service update服务伸缩：docker service scale &lt;SERVICE-ID&gt;=&lt;NUMBER-OF-TASKS&gt;服务列表：docker service list查看服务状态：docker [service] inspect --pretty &lt;Service-Id&gt;查看服务所在节点：docker service ps nginx-all删除：docker service rm [service-id/name]端口映射： 1docker service create \\ --name &lt;SERVICE-NAME&gt; \\ --publish published=&lt;xx&gt;,target=&lt;xx&gt; \\ [--publish-add &lt;xx&gt;:&lt;xx&gt;] &lt;IMAGE&gt; 更新端口： 1docker service update \\ --publish-add published=&lt;PUBLISHED-PORT&gt;,target=&lt;CONTAINER-PORT&gt; \\ &lt;SERVICE&gt; 1.3 Kubernetes","link":"/2021/10/29/docker/"},{"title":"rancher","text":"… Rancher基础环境配置主机配置 修改主机名：cat /etc/hostname 编辑 /etc/hosts 文件： 修改时区：查看时区date -R 或者 timedatectl，修改时区：ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime rancher 启动命令sudo docker run -d --restart=unless-stopped -p 8080:8080 rancher/server 注意事项容器时区修改： 挂载主机时区：-v /etc/localtime:/etc/localtime 启动容器时添加参数：-e TZ=&quot;Asia/Shanghai&quot; 系统全局修改 centos with `ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime` Dockerfile 修改 环境变量：TZ=&quot;Asia/Shanghai&quot; rancher 集群https://rancher.com/docs/rancher/v1.6/en/installing-rancher/installing-server/#multi-nodes v1.6 迁移 v2.xMigration Cheatsheet Rancher 1.6 Rancher 2.0 Container Pod Services Workload Load Balancer Ingress Stack Namespace Environment Project (Administration)/Cluster (Compute) Host Node Catalog Helm Rancher 2.5 Rancher: 使用Rancher可以非常轻松地管理安装在本地或远程开发环境中的Kubernetes。Rancher 2.3全面支持Windows容器，集成Istio服务网格，并增强了云原生工作负载的安全性，有助于开发人员更快且更有信心地进行创新。 RKE: RKE是一款经过CNCF认证、极致简单易用且闪电般快速的Kubernetes安装程序，完全在容器内运行，解决了容器最常见的安装复杂性问题。借助RKE，Kubernetes可以完全独立于您正在运行的操作系统和平台，轻松实现Kubernetes的自动化运维。仅需几分钟，RKE便可通过单条命令构建一个集群，其声明式配置使Kubernetes升级操作具备原子性且安全。 K3s: k3s是经CNCF一致性认证的Kubernetes发行版，专为无人值守、资源受限、偏远地区或物联网设备内部的生产工作负载而设计。 k3s被打包成单个小于60MB的二进制文件，支持x86和ARM处理器，在小到树莓派或大到 AWS a1.4xlarge 32GiB服务器的环境中均能出色工作。 Rio: Rio是一款轻量级Kubernetes应用部署引擎，可以快速且简单地在任何Kubernetes集群中构建、测试、部署、扩展和编写无状态的应用程序。通过集成Istio、Knative和Prometheus等常见服务，Rio帮助您为用户提供最佳的应用程序发布体验。 1. 快速开始1.1 部署RancherServer在1.x版本，镜像地址为rancher/server；在2.x版本，镜像地址为rancher/rancher。下面的tag是适配了m1 mac的版本。 123docker run -d --privileged --restart=unless-stopped \\ -p 8080:80 -p 8081:443 \\ rancher/rancher:v2.5.10-linux-arm64 启动后如下界面： k3s有多轻量？ k3s大小仅有60MB，小于512MB RAM即可运行。为了减少运行Kubernetes所需内存，Rancher K3s开发团队主要专注于以下四个方面的主要变化： 删除旧的、非必须的代码：K3s不包括任何默认禁用的Alpha功能或者过时的功能，原有的API组件目前仍运行于标准部署当中。除此之外，Rancher还删除了所有非默认许可控制器，in- tree云提供商和存储驱动程序，但允许用户添加任何他们需要的驱动程序。 整合正在运行的打包进程：为了节省RAM，Rancher将通常在Kubernetes管理服务器上运行的多流程合并为单个流程。Rancher还将在工作节点上运行的kubelet、kubeproxy和flannel代理进程组合成一个进程。 使用containerd代替Docker作为运行时的容器引擎：通过用containderd替换Docker，Rancher能够显著减少运行时占用空间，删除libnetwork、swarm、Docker存储驱动程序和其他插件等功能。 除了 etcd 之外，引入 SQLite 作为可选的数据存储：Rancher在k3s中添加了SQLite作为可选的数据存储，从而为etcd提供了一个轻量级的替代方案。该方案不仅占用了较少的内存，而且大幅简化了操作。 使用如下命令添加工作节点node(linux服务器/虚拟机)： 1sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.5.10 --server https://localhost:8081 --token srvzmd2c95b9fxrfqpf45nx6wk2wntctd5qvmqhlnpsnzgtf8zmzdx --ca-checksum 23da76edbcca360b01ccaca56421c1a58097164a8c7eaf1ab4759991c947559c --etcd --controlplane --worker rancher等待页面： 不能把自己当作工作节点添加到rancher上吗？？？ Cluster must have at least one etcd plane host: failed to connect to the following etcd host(s) [192.168.64.3] 1.2 部署工作负载 上面的网络模式，其实就是k8s的Servcie(四种类型)。 1.3 命令行工具1.4 Istio操作步骤# 在 Rancher 集群资源管理器中，打开 kubectl shell。 然后运行kubectl label namespace &lt;namespace&gt; istio-injection=enabled。 结果： 命名空间现在有istio-injection=enabled标签。在该命名空间部署的所有新工作负载将默认注入 Istio sidecar。","link":"/2021/11/01/rancher/"},{"title":"kubernetes","text":"k8s 之快速入门快速出门 K8s Kubernetes 功能的设计文档归档，不妨考虑从 Kubernetes 架构 和 Kubernetes 设计概述 开始阅读。 1. 快速开始 Kubernetes 集群Kubernetes 协调一个高可用计算机集群，每个计算机作为独立单元互相连接工作。 Kubernetes 中的抽象允许您将容器化的应用部署到集群，而无需将它们绑定到某个特定的独立计算机。为了使用这种新的部署模型，应用需要以将应用与单个主机分离的方式打包：它们需要被容器化。与过去的那种应用直接以包的方式深度与主机集成的部署模型相比，容器化应用更灵活、更可用。 Kubernetes 以更高效的方式跨集群自动分发和调度应用容器。 Kubernetes 是一个开源平台，并且可应用于生产环境。 一个 Kubernetes 集群包含两种类型的资源: Master 调度整个集群 Nodes 负责运行应用(虚拟机/服务器) 1.1 安装方法一： 确保机器上已经安装了docker 安装kubectl命令行工具 安装并使用minikube运行一个单节点的k8s集群 方法二： 安装Docker Desktop 接着，验证是否安装成功。 1234kubectl version --clientkubectl cluster-info 2. 官方教程 一旦运行了 Kubernetes 集群，就可以在其上部署容器化应用程序。 2.1 创建一个k8s集群1234567891011# 版本信息minikube version# 启动一个单结点的k8s集群minikube start# 集群信息kubectl cluster-info# 节点信息kubectl get nodes 2.2 部署应用程序 1234567# 部署app的命令，默认添加了一个Pod（类似于 docker run ...）kubectl create deployment [name] --image=[imageURL]kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1# 查看所有deploymentkubectl get deployments 2.3 应用程序探索 Pod运行在工作节点node上，每个工作节点可以是虚拟机或物理计算机。所有的nodes由master主节点管理。 每个 Kubernetes 工作节点至少运行: Kubelet，负责 Kubernetes 主节点和工作节点之间通信的过程; 它管理 Pod 和机器上运行的容器。 **容器运行时(A container runtime)**（如 Docker）负责从仓库中提取容器镜像，解压缩容器以及运行应用程序。 Pod是 Kubernetes 平台上的原子单元。 当我们在 Kubernetes 上创建 Deployment 时，该 Deployment 会在其中创建包含容器的 Pod （而不是直接创建容器）。每个 Pod 都与调度它的工作节点绑定，并保持在那里直到终止（根据重启策略）或删除。 如果工作节点(服务器)发生故障，则会在群集中的其他可用工作节点上调度相同的 Pod。 最常见的操作可以使用以下 kubectl 命令完成： kubectl get - 列出资源 kubectl describe - 显示有关资源的详细信息 kubectl logs [pod_name] - 打印 pod 和其中容器的日志 kubectl exec [-it] [pod_name] - 在 pod 中的容器上执行命令 1234567# 获取所有podskubectl get pods#We see here details about the Pod’s container: IP address, the ports used and a list of events related to the lifecycle of the Pod.kubectl describe pods 2.4 应用外部可见通过 Serivce by service 通过Service实现了让pod可以被访问。Service有以下几种类型： ClusterIP (默认) - 在集群的内部 IP 上公开 Service 。这种类型使得 Service 只能从集群内访问。 NodePort- 使用 NAT 在集群中每个选定 Node 的相同端口上公开 Service 。使用&lt;NodeIP&gt;:&lt;NodePort&gt; 从集群外部访问 Service。是 ClusterIP 的超集。 LoadBalancer - 在当前云中创建一个外部负载均衡器(如果支持的话)，并为 Service 分配一个固定的外部IP。是 NodePort 的超集。 ExternalName - 通过返回带有该名称的 CNAME 记录，使用任意名称(由 spec 中的externalName指定)公开 Service。不使用代理。这种类型需要kube-dns的v1.7或更高版本。 1234567891011# 查看所有 podskubectl get pods# 查看所有 serviceskubectl get services# 创建 servicekubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080# 查看 service 详情kubectl describe services/kubernetes-bootcamp Labels 的用法12345678910# 查看deployment的labelkubectl describe deployment# 通过label查询(-l)kubectl get pods -l app=kubernetes-bootcampkubectl get services -l app=kubernetes-bootcamp# 通过label删除服务kubectl delete service -l app=kubernetes-bootcamp 2.5 应用可扩展扩展 Deployment目的：用 kubectl 扩缩应用程序 在之前的模块中，我们创建了一个 Deployment，然后通过 Service让其可以开放访问。Deployment 仅为跑这个应用程序创建了一个 Pod。 当流量增加时，我们需要扩容应用程序满足用户需求。 扩缩 是通过改变 Deployment 中的副本数量来实现的。 小结：扩缩一个Deployment 另外，在运行kubectl run命令是，可以设置 – replicas 参数来设置Deployment的副本数。 123456789101112# 先查看已有的 deploymentkubectl get deployments# 扩展到 4 个 Podskubectl scale deployments/kubernetes-bootcamp --replicas=4# 变成 2 个 Podskubectl scale deployments/kubernetes-bootcamp --replicas=2# 查看 deployment 和 podskubectl get deploymentskubectl get pods -o wide 2.6 应用更新滚动更新(Rolling Updates)的过程： 123456789101112# 查看deploymets, pods信息kubectl get deploymentskubectl get podskubectl describe pods# 更新镜像版本：使用 set image 命令kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2# 验证更新# 查看ip，端口等信息kubectl describe services/kubernetes-bootcamp 3. 配置在 Kubernetes 中，为 docker 容器设置环境变量有几种不同的方式，比如： Dockerfile、kubernetes.yml、Kubernetes ConfigMaps、和 Kubernetes Secrets。 使用 ConfigMaps 和 Secrets 的一个好处是他们能在多个容器间复用， 比如赋值给不同的容器中的不同环境变量。 3.1 配置java微服务 使用 MicroProfile、ConfigMaps、Secrets 实现外部化应用配置 部署2个java微服务到k8s，然后用MicroProfileConfig, k8sConfigMaps 和 Secrets 修改配置。 1kubectl apply -f kubernetes.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889apiVersion: apps/v1kind: Deploymentmetadata: name: system-deployment labels: app: systemspec: selector: matchLabels: app: system template: metadata: labels: app: system spec: containers: - name: system-container image: system:1.0-SNAPSHOT ports: - containerPort: 9080 # Set the APP_NAME environment variable env: - name: APP_NAME valueFrom: configMapKeyRef: name: sys-app-name key: name---apiVersion: apps/v1kind: Deploymentmetadata: name: inventory-deployment labels: app: inventoryspec: selector: matchLabels: app: inventory template: metadata: labels: app: inventory spec: containers: - name: inventory-container image: inventory:1.0-SNAPSHOT ports: - containerPort: 9080 # Set the SYSTEM_APP_USERNAME and SYSTEM_APP_PASSWORD environment variables env: - name: SYSTEM_APP_USERNAME valueFrom: secretKeyRef: name: sys-app-credentials key: username - name: SYSTEM_APP_PASSWORD valueFrom: secretKeyRef: name: sys-app-credentials key: password---apiVersion: v1kind: Servicemetadata: name: system-servicespec: type: NodePort selector: app: system ports: - protocol: TCP port: 9080 targetPort: 9080 nodePort: 31000---apiVersion: v1kind: Servicemetadata: name: inventory-servicespec: type: NodePort selector: app: inventory ports: - protocol: TCP port: 9080 targetPort: 9080 nodePort: 32000 3.2 使用ConfigMap来配置Redis12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: Podmetadata: name: redisspec: containers: - name: redis image: redis:5.0.4 command: - redis-server - &quot;/redis-master/redis.conf&quot; env: - name: MASTER value: &quot;true&quot; ports: - containerPort: 6379 resources: limits: cpu: &quot;0.1&quot; volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: {} - name: config configMap: name: example-redis-config items: - key: redis-config path: redis.conf 4. 应用4.1 无状态应用4.2 有状态应用5. 服务、负载均衡和联网5.1 IngressIngress 公开了从集群外部到集群内服务的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。 下面是一个将所有流量都发送到同一 Service 的简单 Ingress 示例： 可以将 Ingress 配置为服务提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及提供基于名称的虚拟主机等能力。 Ingress 控制器 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。 Ingress 不会公开任意端口或协议。 将 HTTP 和 HTTPS 以外的服务公开到 Internet 时，通常使用 Service.Type=NodePort 或 Service.Type=LoadBalancer 类型的服务。 你必须具有 Ingress 控制器 才能满足 Ingress 的要求。 仅创建 Ingress 资源本身没有任何效果。你可能需要部署 Ingress 控制器，例如 ingress-nginx。 你可以从许多 Ingress 控制器 中进行选择。Ingress控制器有许多种，例如：nginx ingress, Istio Ingress 等。 下面是一个最小的控制器资源service/networking/minimal-ingress.yaml: 123456789101112131415161718apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - http: paths: - path: /testpath pathType: Prefix backend: service: name: test port: number: 80","link":"/2021/11/01/kubernetes/"},{"title":"TensorFlow","text":"… Tensorflow从零开始学1. 机器学习基础 Tensorflow2.0 架构图 1.1 机器学习分类机器学习主要分为以下几类： 有监督学习(Supervised Learning)：根据有特征的数据进行训练、建模。包括分类、回归。常见算法有线性回归、逻辑回归、K-近邻朴素贝叶斯、决策树、随机森林、支持向量机。 无监督学习：直接建模。常见算法有K-means、EM 半监督学习 强化学习(Reinforcement Learning): 基于周围环境学习。 1.2 机器学习流程 引入数据集 &amp; 数据预处理 (特征工程：scikit-learn处理数据和提取特征) **训练和测试模型 **(判断问题类型，选择算法和模型) 评估模型 数据预处理的几种常见简单方法： 归一化：其作用包括无量纲化、加快模型的收敛速度等。使用min-max/Z-score算法。 标准化：将数据按比例缩放为一个限定区间。使用场景如距离度量、数据符合正态分布。 离散化：把连续的数值型数据进行很短。有助于消除异常数据，提高算法的效率。 二值化：简化数据，消除数据杂音。 哑编码：独热编码(One-Hot Encoding)。对特征(如形状、大小等)进行编码化。 特征工程：把原始数据转换为模型可用的数据。主要包括3方面：特征构造、特征提取和特征选择。 特征构造：在原有特征的基础上做组合操作。例如对原有特征进行四则运算，从而得到新的特征。 特征提取：使用映射或变换的方法，降高维特征转换为低维的新特征。即降低维度（sklearn）。 常用方法有主成分分析（Principe Component Analysis，PCA）、线性判别分析（Linear Discriminant Analysis，LDA）和独立成分分析（Independent Component Analysis，ICA） PCA：无监督降维算法。主要实现是用“减少噪声”和“去冗余”来降维。 LDA：有监督降维算法。借助协方差矩阵、广义瑞利熵等实现类间距离的最大化和最小化。 ICA：降维的过程中保留相互独立的维度特征。 特征选择：选择对模型影响大的特征，移除不太相关的特征。作用是减少过拟合、提高模型准确度、减少训练时间。 过滤式：Pearson相关系数法、方差选择法、假设检验、互信息法等。 包裹式 嵌入式 模型的评估和选择 基本概念： 参数：模型的内部变量。如模型的权重矩阵和偏置。 超参数：模型中可人为设定和修改的参数，或者称为训练过程中不变的参数，如神经网络的层数、学习率、隐藏层神经元的个数等。 评估的常见方法：留出法、交叉验证法、留一法、自助法。 留出法：按比例将数据集划分训练集、验证集、测试集 验证集，是模型训练过程中单独留出的样本集，它可以用于调整模型的超参数和用于对模型的能力进行初步评估。 通常用来在模型迭代训练时，用以验证当前模型泛化能力（准确率，召回率等），以决定是否停止继续训练。 交叉验证法：划分为k个数据集，其中一个作为验证集，剩下的k-1个作为训练集。将得到的k个结果取平均值，作为最终模型评估的结果。这种方法称为“k折交叉验证”。 模型的性能度量：正确率(Accuracy)、错误率(Error Rate)、查准率(Precision)、查全率/召回率(Recall) Precision和Recall的指标衡量使用F1公式。 1.3 术语 计算图：动态计算图(Eager Execution) 会话 运算操作和运算核 张量(Tensor)：多维的数组或列表。 Learning Rate 在机器学习和统计学中，学习率是优化算法中的一个调整参数，它确定每次迭代时梯度下降的步长，同时朝着损失函数的最小值移动。[1]由于它会影响新获取的信息覆盖旧信息的程度，因此它隐喻地代表了机器学习模型“学习”的速度。在自适应控制文献中，学习率通常称为增益。[2] 如果知道感知机原理的话，那很快就能知道，Learning Rate是调整神经网络输入权重的一种方法。如果感知机预测正确，则对应的输入权重不会变化，否则会根据Loss Function来对感知机重新调整，而这个调整的幅度大小就是Learning Rate，也就是在调整的基础上，增加一个比值。 如下图的权重w，在输出之后预测正确与否，若正确则保持权重w不变，若错误则用右边的公式来对权重w进行调整，如下图： 那一般Learning Rate的取值都在0.0001到0.01之间，这个效果就像你走路的步子，步子迈达了，很容易错过最佳点(指使loss损失函数为最小值时的 LR)，而迈小了又需要花更长的时间才能到最佳点。 所以，直观上来看，在这最好的办法是：先走快一些（大一些的Learning Rate），然后要到最佳点的时候，再降低Learning Rate来到达最佳点。 梯度下降(Gradient Descent)算法 loss 和 val_loss : loss 是训练集的损失值，val_loss(validation) 是验证集的损失值。 以下是loss与val_loss的变化反映出训练走向的规律总结： train loss 不断下降，test loss不断下降，说明网络仍在学习;（最好的） train loss 不断下降，test loss趋于不变，说明网络过拟合;（max pool或者正则化） train loss 趋于不变，test loss不断下降，说明数据集100%有问题;（检查dataset） train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;（减少学习率） train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。（最不好的情况） 1.4 Wide&amp;Deep 模型 论文地址(Wide &amp; Deep Learning for Recommender Systems )：https://arxiv.org/pdf/1606.07792v1.pdf https://www.jianshu.com/p/5b807e6c3801 稀疏特征+密集特征 2. 数据预处理2.1 归一化归一化：将数据集转换为(0,1)区间范围或者无量纲化(dimensionless，去维度)，使其位于激活函数有明显梯度的位置，才能使每一层神经网络之间感知到明显变化的loss损失函数值。如果在梯度不明显的地方(如函数平缓，即导数接近0；神经网络层数多，导致每一层神经网络的loss变化不大)，短时间内的训练效果会不明显。下面是 2 种归一化方法（均值MSE，方差STD）： 批归一化：对每层神经训练后的数据再进行归一化。参考文章：https://www.cnblogs.com/skyfsm/p/8453498.html a中左图是没有经过任何处理的输入数据，曲线是sigmoid函数，如果数据在梯度很小的区域，那么学习率就会很慢甚至陷入长时间的停滞。减均值除方差后，数据就被移到中心区域如右图所示，对于大多数激活函数而言，这个区域的梯度都是最大的或者是有梯度的（比如ReLU），这可以看做是一种对抗梯度消失的有效手段。 2.2 One-Hot 编码作为机器学习算法的输入，通常需要对其进行特征数字化。故使用one-hot编码可以将具备离散值特征的分类数据转化为二进制向量。例如，按照 N位状态寄存器 来 对N个状态 进行编码的原理，处理后应该是这样的： 12345678910111213性别特征：[&quot;男&quot;,&quot;女&quot;] （这里只有两个特征，所以 N=2）：男 =&gt; 10女 =&gt; 01祖国特征：[&quot;中国&quot;，&quot;美国，&quot;法国&quot;]（N=3）：中国 =&gt; 100美国 =&gt; 010法国 =&gt; 001 3. 前馈神经网络3.1 神经网络 感知器模型、多层神经网络 感知器模型(单层神经网络，是一种两类线性分类模型) 多层神经网络（可通过隐藏层的非线性激活函数，解决非线性问题） 3.2 激活函数激活函数的概念和作用 为什么要用激活函数？ 如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，这种情况就是最原始的感知机（Perceptron）。如果使用的话，激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。 为了解决非线性的分类或回归问题，激活函数必须是非线性函数。另外使用基于梯度(慢慢趋于某个值，才能分类)的方式来训练模型，因此激活函数也必须是连续可导的。 激活函数：Logistic(Sigmoid)函数、Tanh函数、ReLU函数(常用) 激活函数： 梯度消失：随着神经网络层数的加深，梯度后向传播到浅层网络时，基本无法引起参数的扰动，也就是没有将loss的信息传递到浅层网络，这样网络就无法训练学习了。(即随着隐藏层数目的增加，分类准确率反而下降了；更为直白的表达，就是梯度消失，函数成为横线变为不可导。) Cause：Sig函数求导后的导数最大值为0.25(当x=0时)。神经网络主要的训练方法是BP算法，而反向传播算法(Back Propagation)的基础是导数的链式法则，也就是多个导数的乘积。当层数过多时，导数乘积会变得非常小，就会造成梯度消失现象了。 Relu 衍生函数 3.3 输出单元输出单元：1.线性单元(回归) 2.Sigmoid单元(二分类) 3.Softmax单元(多分类) 3.4 损失函数 损失函数(目标函数)**用来表达模型的预测值和真实类标之间的误差。深度学习模型的训练就是使用基于梯度的方法使损失函数最小化**的过程。损失函数和输出单元有密切的关系？ 损失函数： 1.均方误差损失函数(Mean Squared Error, MSE)，用于回归问题。 2.交叉熵损失函数(Cross Entropy)，用于分类问题。 3.5 优化器 sgd：随机梯度下降 adam： RMSProp：https://zhuanlan.zhihu.com/p/34230849 3.6 示例：MNIST手写数字识别这是一个有监督的分类问题。（此处指类标label，而不是类别category） 4. 卷积神经网络 卷积神经网络(Convolutional Neural Network，CNN)是一种专门用来处理网格结构数据(如图像数据)的前馈神经网络。相对全连接神经网络参数更少，减少了模型训练的复杂性和过拟合问题，使模型的泛化能力更强。 4.1 CNN的基本特征与结构CNN主要有3大特征：1.局部连接 2.权值共享 3.子采样(池化) 4.2 卷积层卷积公式： 卷积的示例： 卷积的作用：将各种低级特征(输入层的图像的特征)卷积成高级特征(特征图)。 卷积层的基本结构 4.3 池化层 池化层(Pooling Layer)也称为子采样层(Subsampling Layer)，一般都紧跟在卷积层之后，它的作用是进行特征选择(对特征图进行采样)，减少特征的数量，从而减少网络参数的数量。 池化层的过程其实在卷积层也能完成。 4.4 CNN图像分类5. 循环神经网络 循环神经网络(Recurrent Neural Network, RNN)，用于解决具有数据时序前后关联性(如文本、语音、视频、无人驾驶等)的问题。强化学习应该是实时的。 5.1 RNN RNN的基本结构、前面计算的过程、参数优化的问题 记忆单元能记住有限时间范围内的信息，同时能将这些信息传递到下一层或上一层的神经元（即每个时刻的输出是由上下两个循环神经网络的输出共同决定的）。 梯度消失和梯度爆炸、解决方法(梯度截断、正则化及改进模型等) 5.2 门控RNN 在RNN基础上增加门控机制，用来控制神经网络中信息的传递。即保留或丢弃记忆单元中的信息。这样就可以使RNN学习时间跨度更大的依赖关系，而不会出现梯度消失和梯度爆炸问题。 长短期记忆网络(Long Short-Term Memory, LSTM):当趋于梯度消失时，被遗忘的信息越多；当趋于梯度爆炸时，记忆的信息越多。 1tf.keras.layers.LSTM 门控循环单元(Gated Recurrent Unit, GRU)：GRU网络结构比LSTM简单，它将LSTM的输入门和遗忘门合并为更新门。 1tf.keras.layers.GRU 5.3 RNN的应用 应用场景主要有：自然语言处理(Natural Language Processing，NLP)、语音识别/合成、聊天机器人、机器翻译等。 5.4 注意力模型（强化学习？）跳过 6. 深度强化学习 6.1 基础知识 行为模式：Do &amp; Correct动作空间(Action Space)：A状态空间(State Space)：S奖励(Reward)：R状态转移概率矩阵(Transition)：P 强化学习和传统的有监督学习的区别：有监督学习 Learning with a teacher，强化学习 Learning with a critic 6.2 有模型的强化学习方法6.3 无模型的强化学习方法6.4 强化学习算法6.5 深度强化学习算法7. 项目实战8. Tensorflow 代码TODO视频 3-6子类自定义 layer 3-9签名函数和图结构 3-12手动metrics mse 第4章csv 8.1 回归和分类本笔记本 (notebook) 介绍了一些处理回归问题的技术。 均方误差（MSE）是用于回归问题的常见损失函数（分类问题中使用不同的损失函数）。 类似的，用于回归的评估指标与分类不同。 常见的回归指标是平均绝对误差（MAE）。 当数字输入数据特征的值存在不同范围时，每个特征应独立缩放到相同范围。 如果训练数据不多，一种方法是选择隐藏层较少的小网络，以避免过度拟合。 早期停止是一种防止过度拟合的有效技术。 8.2 TF 基础 APItf.constant()9. Q&amp;A9.1 数据降维 9.2 防止过拟合todo: https://tensorflow.google.cn/tutorials/keras/overfit_and_underfit?hl=zh_cn Dropout、取更重要的特征，忽略不重要的特征、early stopping 10. TensorFlow 官网教程Todo https://keras.io/examples/ 10.1 快速开始10.2 Keras 机器学习基础知识基本图像分类基本文本分类使用 TF Hub 进行文本分类TensorFlow Hub，一个用于迁移学习的库和平台。关于迁移学习可参考该文章。 回归过拟合和欠拟合防止过度拟合的最简单方法是从一个小模型开始：一个具有少量可学习参数（由层数和每层单元数决定）的模型。在深度学习中，模型中可学习参数的数量通常被称为模型的“容量”。 L1、L2 正则化本质上也是使简化模型，使其具有较少参数。 &quot;L2&quot;正则化模型现在比&quot;Tiny&quot;模型更具竞争力。这种&quot;L2&quot;模式也更耐比过拟合&quot;Large&quot;，尽管有相同数量的参数，它是基于模型。 Dropout 是最有效和最常用的神经网络正则化技术之一，由 Hinton 和他在多伦多大学的学生开发。 对 dropout 的直观解释是，由于网络中的单个节点不能依赖其他节点的输出，因此每个节点必须输出对自己有用的特征。 应用于层的 Dropout 包括在训练期间随机“丢弃”（即设置为零）该层的许多输出特征。假设一个给定的层通常会在训练期间为给定的输入样本返回一个向量 [0.2, 0.5, 1.3, 0.8, 1.1] ；应用 dropout 后，该向量将随机分布一些零条目，例如 [0, 0.5, 1.3, 0, 1.1]。 “辍学率”是被归零的特征的比例；它通常设置在 0.2 到 0.5 之间。在测试时，没有单元被丢弃，而是层的输出值按与丢弃率相等的因子缩小，以平衡比训练时更多的单元处于活动状态这一事实。 过拟合的反面是欠拟合。当训练数据仍有改进空间时，就会发生欠拟合。发生这种情况的原因有很多：如果模型不够强大、过度规范化，或者只是训练时间不够长。这意味着网络还没有学习到训练数据中的相关模式。 总结 回顾一下：以下是防止神经网络过度拟合的最常见方法： 获取更多训练数据。 减少网络容量(模型参数)。 添加权重正则化(Weight Regularization)。 添加辍学。 本指南未涵盖的两种重要方法是： 数据增强 批量标准化(Batch Normalization) 请记住，每种方法都可以单独提供帮助，但通常将它们结合起来会更有效。 保存和加载选项 保存 Tensorflow 的模型有许多方法——具体取决于您使用的 API。本指南使用 tf.keras， 一个高级 API 用于在 Tensorflow 中构建和训练模型。有关其他方法的实现，请参阅 TensorFlow 保存和恢复指南或保存到 eager。 Keras 通过检查网络结构来保存模型。这项技术可以保存一切: 权重值 模型的架构 模型的训练配置(您传递给编译的内容) 优化器及其状态（如果有的话）（这使您可以在中断的地方重新开始训练） Keras 无法保存 v1.x 优化器（来自 tf.compat.v1.train），因为它们与检查点不兼容。对于 v1.x 优化器，您需要在加载-失去优化器的状态后，重新编译模型。 如果使用的是 SavedModel 格式，则可以跳过此部分。HDF5 和 SavedModel 之间的主要区别在于，HDF5 使用对象配置保存模型结构，而 SavedModel 保存执行图。因此，SavedModel 能够保存自定义对象，例如子类化模型和自定义层，而无需原始代码。 1https://www.tensorflow.org/tutorials/keras/save_and_load#%E4%BF%9D%E5%AD%98%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%B1%A1 使用 Keras Tuner 调整超参数超参数有两种类型： 影响模型选择的模型超参数，例如隐藏层的数量和宽度 to do 隐藏层是什么 影响学习算法速度和质量的算法超参数，例如随机梯度下降 (SGD) 的学习率和 ak 最近邻 (KNN) 分类器的最近邻数 您可以通过两种方法定义超模型： 通过使用模型构建器功能 here 通过HyperModel继承 Keras Tuner API的类 The Keras Tuner has four tuners available - RandomSearch, Hyperband, BayesianOptimization, and Sklearn 概括 在本教程中，您学习了如何使用 Keras Tuner 调整模型的超参数。要了解有关 Keras Tuner 的更多信息，请查看以下附加资源： TensorFlow 博客上的 Keras Tuner Keras Tuner website Also check out the HParams Dashboard in TensorBoard to interactively tune your model hyperparameters. 10.3 加载和预处理数据图像CSVNumPypandas.DataFrame文本UnicodeTF.Text子词分词化TFRecord 和 tf.Example","link":"/2021/09/03/TensorFlow/"},{"title":"rocketmq samples","text":"spring-boot-rocketmq 示例，具体见项目代码和文档。 示例代码：SC-alibaba/rocketmq/rocketmq-spring-boot at master · cloris-cc/SC-alibaba · GitHub 笔记：spring cloud alibaba - 茶茶日记 - winklog 官方中文文档：rocketmq/docs/cn at master · apache/rocketmq · GitHub 1. 快速开始1.1 启动服务下载地址：Quick Start - Apache RocketMQ 启动 Name Server： 123&gt; nohup sh bin/mqnamesrv &amp;&gt; tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success... 启动 Broker： 123&gt; nohup sh bin/mqbroker -n localhost:9876 &amp;&gt; tail -f ~/logs/rocketmqlogs/broker.log The broker[%s, 172.30.30.233:10911] boot success... 关闭服务： 1234567&gt; sh bin/mqshutdown brokerThe mqbroker(36695) is running...Send shutdown request to mqbroker(36695) OK&gt; sh bin/mqshutdown namesrvThe mqnamesrv(36664) is running...Send shutdown request to mqnamesrv(36664) OK 1.2 引入依赖在 spring-boot 项目 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${RELEASE.VERSION}&lt;/version&gt;&lt;/dependency&gt; 或者使用 spring-cloud-stream 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 1.3 发送消息在发送消息前，需要对生产(output)/消费者(input)做几项必要的配置 1234rocketmq: name-server: localhost:9876 producer: group: test-group # 一般为业务名(application name) 接着使用RocketMQTemplate发送消息 123456789101112// 按照名称装配。若是自己的Bean(eg:@Service/@Component/...)则用@Auowired按类型装配@Resourceprivate RocketMQTemplate rocketMQTemplate;/** * 1. string-topic 普通消息 */public void stringTopic() { SendResult sendResult = rocketMQTemplate.syncSend(Topic.STRING_TOPIC, &quot;一条普通的消息&quot;); log.info(&quot;======&gt; STRING_TOPIC：消息已发送&quot;); log.info(&quot;======&gt; sendResult: {}&quot;, sendResult);} 消费消息 12345678910// 当需要用到负载均衡时，group和topic都要相同。@RocketMQMessageListener(consumerGroup = &quot;consumer-group-1&quot;, topic = Topic.STRING_TOPIC)@Service@Slf4jpublic class StringTopicHandler implements RocketMQListener&lt;String&gt; { @Override public void onMessage(String s) { log.info(&quot;======&gt; 接受到消息：{}&quot;, s); }} 2. 使用示例2.1 基本概念参照：RocketMQ中Topic、Tag、GroupName的设计初衷 2.2 主要功能(消息之间的) 事务处理：生产者(服务A/本地事务) ==&gt; 消费者(服务B) 2.3 注意 &amp; todoRocketMQListener中的泛型消息体Payload T为对象时，需要有无参构造函数。包括RabbitMQ的(byte[])message.getBody()对象也一样。否则序列化对象时会抛出异常。 超级简单的 RocketMQ 流量削峰实战_xmt1139057136的专栏-CSDN博客 业务设计：主要围绕topic，设计上和service/controller等类似，尽量一个topic对应一个实体类，例如对于user对象，有User-Service/Controller/Topic/Listener。 分布式事务是消息事务的父集。 12345@Slf4j@Service@RocketMQMessageListener(consumerGroup = &quot;delay-consumer-group&quot;, topic = Topic.DELAY_TOPIC)// 此处的 T 为Payload的类型 或 MessageExtpublic class DelayTopicHandler implements RocketMQListener&lt;T&gt;","link":"/2021/04/02/rocketmq-samples/"},{"title":"Spring Cloud","text":"Spring Cloud 系列笔记… 第 1 章 微服务与SC1.1 微服务架构技术栈 – Spring Cloud Dubbo Motan MSEC 其他 功能 服务方案完整 服务治理框架 服务治理框架 服务开发运营框架 略 通信方式 REST / Http RPC 协议 RPC / Hessian2 Protocol buffer grpc, thrift 服务发现 / 注册 Eureka (AP) ZK, Nacos ZK / Conusl 只有服务发现 Etcd 负载均衡 Ribbon 客户端负载均衡 客户端负载均衡 客户端负载均衡 Nginx + Lua 容错机制 6种容错策略 6种容错策略 2种容错策略 自动容错 Keepalived、HeartBeat 熔断机制 Hystrix 无 无 提供过载保护 无 配置中心 Spring Cloud Config Nacos 无 无 Apollo, Nacos 网关 Zuul, Gateway 无 无 无 Kong, 自研 服务监控 Hystrix + Turbine Dubbo + Monitor 无 Monitor ELK 链路监控 Sleuth + Zipkin 无 无 无 PinPoint 多语言 Rest 支持多语言 Java Java Java, C++, PHP Java, PHP, Node.js 社区活跃 高 (Spring 社区) 高 (阿里) 一般 未知 略 1.2 架构演变单体应用 &gt;&gt; 分布式(水平复制) &gt;&gt; SOA(面向服务架构) &gt;&gt; 微服务 其中，微服务是更细粒度的划分；而SOA架构更庞重，主要包括有ESB（Enterprise Service Bus，企业服务总线。有SOAP/JMS技术），基于XML和WDSL语言。 1.3 SpringCloud D版中文文档第 2 章 Eureka2.1 服务的核心操作服务注册、下线、租约和剔除。 2.2 分布式系统的复制方式 主从复制对数据的写操作都提交到主副本，最后再由主副本更新到其它副本。读操作可以分配在从副本上以缓解压力。更新方式有：同步更新、异步更新、同步和异步混合。 对等复制Eureka就是实现了Peer to Peer. 2.3 CAP理论在Eureka中的体现Eureka会存留过期的实例信息，Eureka并不是强一致性的。C和A冲突的原因：为了保证数据一致性需要同步(加锁)，所以可能会造成阻塞(即牺牲了可用性)。 单机Redis为CA，没有P是因为不存在和其它网络分区通信。集群Redis为AP，牺牲强一致性保证高可用。 总结：由于CAP理论是存在于分布式系统中的，故一般情况下都是会与其它网络分区通信的，所以一般会保证P。另外，由于分布式系统主要以性能为主，故也会保证A。所以分布式组件大多都是保证了AP，再用最终一致性来保证数据安全。Eureka/Redis也如此。 2.4 Eureka的配置 Server 12345678910111213# bootstrap.ymlspring: application: name: eureka-server cloud: config: uri: http://localhost:8888management: endpoints: web: exposure: include: '*'&lt;/pre&gt; 123456789101112131415161718192021# application.ymlserver: port: 8761spring: application: name: eureka-servereureka: instance: hostname: localhost preferIpAddress: true client: registerWithEureka: false # 注册中心为false fetchRegistry: false # 注册中心为false serviceUrl:# defaultZone: http://localhost:8761/eureka/ # one eureka server# defaultZone: http://localhost:8762/eureka/ # two eureka server defaultZone: http://localhost:8762/eureka/,http://localhost:8763/eureka/ # three eureka server server: waitTimeInMsWhenSyncEmpty: 0 enableSelfPreservation: false Client 12345678910111213server: port: 8081spring: application: name: eureka-client1eureka: client: serviceUrl:# defaultZone: http://localhost:8761/eureka/ # one eureka server# defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/ # two eureka server defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/,http://localhost:8763/eureka/ # three eureka server 第 3 章 Feign3.1 概述 Feign 是一个声明式的 Web Service 客户端。Feign 会完全代理 HTTP 的请求。它的出现使开发 Web Service 客户端变得很简单。使用 Feign 只需要创建一个接口加上对应的注解，如：@FeignClient。 Feign 有可插拔的注解，包括 Feign 注解和 JAX-RS 注解。Feign 也支持编码器和解码器，Spring Cloud Open Feign 对 Feign 进行增强支持 Spring MVC 注解，可以像 Spring Web 一样使用 HttpMessageConverters. 此外，服务消费者调用提供者时，底层通过 HTTP Client 的方式访问。当然也可以使用 JDK 原生的 URLConnection、Apache 的 HTTP Client、Netty 的异步 HTTP Client，Spring 的 RestTemplate (实现 Ribbon 负载均衡的媒介) 去实现服务间的调用。 3.2 特性 可插拔的注解支持，包括 Feign 注解和 JAX-RS 注解。 支持可插拔的 HTTP 编码器和解码器。 支持 Hystrix 和它的 Fallback。 支持 Ribbon 的负载均衡。 支持 HTTP 请求和响应的压缩。 3.3 Feign 的基础用法12345678@SpringBootApplication@EnableFeignClientspublic class SpringCloudFeignApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudFeignApplication.class, args); }} 12345678910111213@FeignClient(name = &quot;github-client&quot;, url = &quot;https://api.github.com&quot;, configuration = HelloFeignServiceConfig.class)public interface HelloFeignService { /** * content: {&quot;message&quot;:&quot;Validation Failed&quot;,&quot;errors&quot;:[{&quot;resource&quot;:&quot;Search&quot;,&quot;field&quot;:&quot;q&quot;,&quot;code&quot;:&quot;missing&quot;}], * &quot;documentation_url&quot;:&quot;https://developer.github.com/v3/search&quot;} * @param queryStr * @return */ @RequestMapping(value = &quot;/search/repositories&quot;, method = RequestMethod.GET) String searchRepo(@RequestParam(&quot;q&quot;) String queryStr);} 12345678910111213@RestControllerpublic class HelloFeignController { @Autowired private HelloFeignService helloFeignService; // 服务消费者对位提供的服务 @GetMapping(value = &quot;/search/github&quot;) public String searchGithubRepoByStr(@RequestParam(&quot;str&quot;) String queryStr) { return helloFeignService.searchRepo(queryStr); }} 3.4 Feign 的基础功能3.4.1 @FeignClient 注解@FeignClient的常用属性如下： name：指定 FeignClient 的名称，如果项目使用了 Ribbon，name 属性会作为微服务的名称，用于服务发现。 url：url 一般用于调试，可以手动指定@FeignClient调用的地址。 decode404：当发生 404 错误时，如果该字段为 true，会调用 decoder 进行解码，否则抛出 FeignException。 configuration：Feign配置类。可以定义 Feign 的 Encoder、Decoder、LogLevel、Contract。 fallback：定义容错的处理类，当调用远程接口失败或超时时，会调用对应接口的容错逻辑，fallback 指定的类必须实现@FeignClient标记的接口并用@Component注册Bean。 fallbackFactory：工厂类，用于生成 fallback 类示例，通过这个属性我们可以实现每个接口通用的容错逻辑，减少重复的代码。也要注册到Spring容器内。 path：定义当前 FeignClient 的统一前缀。 3.4.2 Feign 开启 GZIP 压缩第 4 章 Ribbon4.1 Ribbon的基本用法1234567891011121314@SpringBootApplication@EnableDiscoveryClientpublic class RibbonLoadbalancerApplication { public static void main(String[] args) { SpringApplication.run(RibbonLoadbalancerApplication.class, args); } @Bean @LoadBalanced // Eureka 已经间接依赖了 Ribbon，所以不需要再导入 Ribbon 的依赖。 public RestTemplate restTemplate() { return new RestTemplate(); }} 1234567891011121314@RestControllerpublic class TestController { @Autowired private RestTemplate restTemplate; // 通过 RestTemplate 调用多个客户端，实现客户端负载均衡。 @GetMapping(&quot;/add&quot;) public String add(Integer a, Integer b) { String result = restTemplate .getForObject(&quot;http://CLIENT-A/add?a=&quot; + a + &quot;&amp;b=&quot; + b, String.class); System.out.println(result); return result; }} 4.2 Ribbon负载均衡策略与自定义配置4.2.1 策略详解 策略类 命名 描述 RandomRule 随机策略 随机选择 server RoundRobinRule（default） 轮询策略 按顺序循环选择 server RetryRule 重试策略 在一个配置时间段内选择 server 不成功，则一直尝试选择一个可用的 server BestAvailableRule 最低并发策略 逐个考察 server, 如果 server 断路器打开，则忽略，再选择其中并发连接最低的 server AvailabilityFilteringRule 可用过滤策略 过滤掉一直连接失败并被标记为 circuit tripped 的 server，过滤掉那些高并发连接的 server（active connections 超过配置的阈值） ResponseTimeWeightedRule 响应时间加权策略 根据 server 的响应时间改变权重 ZoneAvoidanceRule 区域权衡策略 综合判断 server 所在区域的性能和 server 的可用性轮询选择 server，并且判定一个 AWS Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有 server 4.2.2 代码实现 4.2.3 策略设置 全局策略设置 12345678@Configurationpublic class TestConfiguration { @Bean public IRule ribbonRule() { return new RandomRule(); }} 对特定的微服务设置 IRule 策略 使用@RibbonClient，设置 configuration 的属性值，eg: 1234567891011121314151617181920@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = &quot;client-a&quot;, configuration = TestConfiguration.class)//@RibbonClients(value = {// @RibbonClient(name = &quot;client-a&quot;, configuration = TestConfiguration.class),// @RibbonClient(name = &quot;client-b&quot;, configuration = TestConfiguration.class)//})@ComponentScan(excludeFilters = {@ComponentScan.Filter(type = FilterType.ANNOTATION, value = {AvoidScan.class})})public class RibbonLoadbalancerApplication { public static void main(String[] args) { SpringApplication.run(RibbonLoadbalancerApplication.class, args); } @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); }} 使用yaml配置文件配置，eg: 1234567891011121314151617181920212223spring: application: name: ribbon-loadbalancerserver: port: 7777eureka: client: serviceUrl: defaultZone: http://${eureka.host:127.0.0.1}:${eureka.port:8888}/eureka/ instance: prefer-ip-address: true#client-a:# ribbon:# ConnectTimeout: 3000# ReadTimeout: 60000# MaxAutoRetries: 1 #对第一次请求的服务的重试次数# MaxAutoRetriesNextServer: 1 #要重试的下一个服务的最大数量（不包括第一个服务）# OkToRetryOnAllOperations: true# NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule##ribbon:# eager-load:# enabled: true# clients: client-a, client-b, client-c 通过配置文件自定义 Ribbon 客户端的语法说明（官方文档均有说明），eg: 配置项 说明 clientName.ribbon.NFLoadBalancerClassName 指定 ILoadBalancer 的实现类 clientName.ribbon.NFLoadBalancerRuleClassName 指定 IRule 的实现类 clientName.ribbon.NFLoadBalancerPingClassName 指定 IPing 的实现类 clientName.ribbon.NIWSServerListClassName 指定 ServerList 的实现类 clientName.ribbon.NIWSServerListFilterClassName 指定 ServerListFilter 的实现类 实现自定义负载均衡策略：实现IRule接口的choose方法再注册到容器即可。 4.3 Ribbon 进阶4.3.1 Ribbon 的核心接口在 IDE 中查看具体实现 IRule、IPing 的 I 代表 Interface，以后的接口也使用此命名格式。如 IUserService… 接口 描述 默认实现类 IClientConfig 定义 Ribbon 中管理配置的接口 DefaultClientConfigImpl IRule 定义 Ribbon 中负载均衡策略的接口 ZoneAvoidanceRule IPing 定义定期 ping 服务检查可用性的接口 DummyPing ServerList&lt;Server 定义获取服务列表方法的接口 ConfigurationBasedServerList ServerListFilter&lt;Server 定义特定期望获取服务列表方法的接口 ZonePreferenceServerListFilter ILoadBalancer 定义负载均衡选择服务的核心方法的接口 ZoneAwareLoadBalancer ServerListUpdater 为 DynamicServerListLoadBalancer 定义动态更新服务列表的接口 PollingServerListUpdater 4.3.2 RestTemplate 达到负载均衡的原理 RestTemplate.classBean 的继承关系图： @LoadBalanced 注解： LoadBalancerClient 接口的方法和实现类，具体见注释文档： 其中LoadBalancerClient接口继承自ServiceInstanceChooser接口，该接口只有一个ServiceInstance choose(String serviceId);方法 。 第 5 章 Hystrix - Defend your APP5.1 设计目标 通过客户端库对延迟和故障进行保护和控制 在一个复杂的分布式系统中停止级联故障 快速失败和迅速恢复 在合理的情况下回退和优雅地降级 开启近实时监控、告警和操作控制 5.2 Hystrix 的基本用法使用@EnableHystrix、@HystrixCommand&lt;修饰方法&gt; 注解： @Client 的注解基本都是修饰类。 1234567891011121314151617181920212223@Componentpublic class UserService implements IUserService{ @Override @HystrixCommand(fallbackMethod=&quot;defaultUser&quot;) public String getUser(String username) throws Exception { if(username.equals(&quot;spring&quot;)) { return &quot;This is real user&quot;; }else { throw new Exception(); } } /** * 出错则调用该方法返回友好错误 * @param username * @return */ public String defaultUser(String username) { return &quot;The user does not exist in this system&quot;; } } Feign 中使用断路器，Feign 默认不开启 Hystrix： 1234567@FeignClient(name = &quot;sc-provider-service&quot;, fallback = UserServiceFallback.class)public interface IUserService { @RequestMapping(value = &quot;/getUser&quot;,method = RequestMethod.GET) public String getUser(@RequestParam(&quot;username&quot;) String username); } 5.3 Hystrix Dashboard Hystrix Dashboard 展示每个 HystrixCommand 执行过程中的信息。 使用方法：项目导入 actuator 依赖，暴露 hystrix.stream 端点。启动类增加 @EnableHystrixDashboard 注解。 5.4 Turbine 聚合 Hystrix主启动类： 123456789@SpringBootApplication@EnableDiscoveryClient@EnableTurbine@EnableHystrixDashboardpublic class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); }} YAML 配置文件： 1234567891011121314151617eureka: client: serviceUrl: defaultZone: http://${eureka.host:127.0.0.1}:${eureka.port:8761}/eureka/ instance: prefer-ip-address: truemanagement: security: enabled: false endpoints: web: exposure: include: hystrix.streamturbine: # 设置需要收集健康信息的服务名称 appConfig: sc-hello-service,sc-provider-service clusterNameExpression: &quot;'default'&quot; 5.5 Hystrix 详解5.5.1 Hystrix 异常机制和处理Hystrix 的异常处理中，有5种出错的情况下会被 fallback 截获，分别是： FAILURE：执行失败，抛出异常。 TIMEOUT：执行超时。 SHORT_CIRCUITED：断路器打开。 THREAD_POOL_REJECTED：线程池拒绝。 SEMAPHORE_REJECTED：信号量拒绝。 对于 BAD_REQUEST 异常是不会触发 fallback 且不会被计数进入熔断的，会抛出 HystrixBadRequestException. 5.5.2 Hystrix 配置说明5.5.3 Hystrix 线程调整和计算对业务的配置通用的做法： 超时时间默认为 1000ms，如果业务明显超过 1000ms，则根据自己的业务进行修改。 线程池默认为 10，需要更多时自行调整。 金丝雀发布，如果成功则保持。 在生产环境中运行超过 24 小时。 如果系统有警告和监控，那么可以依靠它们捕捉问题。 运行 24 小时之后，通过延迟百分位和流量来计算有意义的最低满足值。 在生产或者测试环境中实时修改值，然后用仪表盘监控。 如果断路器产生变化和影响，则需再次确认这个配置。 具体的调整和计算见官方说明文档。 5.5.4 Hystrix 请求缓存使用@CacheResult开启缓存，@CacheRemove清除缓存： 12345678910111213141516171819202122232425262728293031@Componentpublic class HelloService implements IHelloService{ @Autowired private RestTemplate restTemplate; @CacheResult @HystrixCommand public String hello(Integer id) { String json = restTemplate.getForObject(&quot;http://sc-provider-service/getUser/{1}&quot;, String.class, id); System.out.println(json); return json; } @CacheResult @HystrixCommand(commandKey = &quot;getUser&quot;) public String getUserToCommandKey(@CacheKey Integer id) { String json = restTemplate.getForObject(&quot;http://sc-provider-service/getUser/{1}&quot;, String.class, id); System.out.println(json); return json; } @CacheRemove(commandKey=&quot;getUser&quot;) @HystrixCommand public String updateUser(@CacheKey Integer id) { System.out.println(&quot;删除getUser缓存&quot;); return &quot;update success&quot;; }} 5.5.5 Hystrix Request Collapser使用注解进行请求合并： 和缓存类似，用拦截器实现 Hystrix 上下文的初始化和关闭： 12345678910111213141516171819202122public class CacheContextInterceptor implements HandlerInterceptor { private HystrixRequestContext context; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse respone, Object arg2) throws Exception { context = HystrixRequestContext.initializeContext(); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse respone, Object arg2, ModelAndView arg3) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse respone, Object arg2, Exception arg3) throws Exception { context.shutdown(); } } 未完待续… 第 6 章 Zuul6.1 简介 Zuul is the front door for all request from devices and web sites to the backend of the Netflix streaming application. Zuul 具有以下功能： 认证与授权 压力控制 金丝雀测试 动态路由 负载削减 静态响应处理 主动流量管理 6.2 Zuul 的快速入门6.2.1 基本配置 单实例配置： 12345zuul: routes: zuul-gateway: path: /client/** # 将所有 /client 开头的 URL 映射到 client-a 服务去。 serviceId: client-a # 服务名 or 123zuul: routes: client-a: /client/** 多实例配置： 默认情况下，Zuul 会使用 Eureka 集成的基本负载均衡功能，如果想使用 Ribbon 就需要制定一个 serviceId，此操作需要禁止 Ribbon 使用 Eureka，在 E 版之后新增了负载均衡策略的配置，如下： 1234567891011121314151617### 脱离eureka让zuul结合ribbon实现路由负载均衡 ###zuul: routes: ribbon-route: path: /ribbon/** serviceId: ribbon-routeribbon: eureka: enabled: false #禁止Ribbon使用Eurekaribbon-route: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #Ribbon LB Strategy listOfServers: localhost:7070,localhost:7071 #client services for Ribbon LB 6.2.2 路由通配符 规则 释义 示例 /** 匹配任意数量的路径与字符 /mul/a/b… /* 匹配任意数量的字符 /mul /? 匹配单个字符 /m 6.2.3 功能配置 路由前缀、服务屏蔽、路径屏蔽、敏感头信息、重定向问题、重试机制… 12345678910#### 服务忽略、路径忽略、前缀、重定向问题、重试机制 ####zuul: ignored-services: client-b # 忽略的服务，防服务侵入 ignored-patterns: /**/div/** # 忽略的接口，屏蔽接口 prefix: /pre # 前缀 add-host-header: true # 重定向header问题 routes: sensitiveHeaders: Cookie,Set-Cookie,Authorization # 敏感头信息 client-a: /client/** 12345678########################## 重试机制 ##########################zuul: retryable: true #开启重试ribbon: MaxAutoRetries: 1 #同一个服务重试的次数(除去首次) MaxAutoRetriesNextServer: 1 #切换相同服务数量 6.3 Zuul 进阶6.3.1 Zuul Filter 链 Zuul 本质上是 Filter 责任链。Zuul 内部提供了一个动态读取、编译和运行这些 Filter 的机制。Filter 之间不直接通信（内部用 ThreadLocal 实现），在请求线程中会通过 RequestContext（与 doFilter 在同一 ThreadLocal 中） 来共享状态。我们可以在 Filter 之间使用 ThreadLocal 来收集自己需要的状态或数据。 Java 中的 Filter 接口（在tomcat-embed-core.jar中）： 1234567891011package javax.servlet;import java.io.IOException;public interface Filter { void init(FilterConfig var1) throws ServletException; void doFilter(ServletRequest var1, ServletResponse var2, FilterChain var3) throws IOException, ServletException; void destroy();} com.netflix.zuul.context.RequestContext 中的注释，它继承自ConcurrentHashMap： 12345678910/** * The Request Context holds request, response, state information and data for ZuulFilters to access and share. * The RequestContext lives for the duration of the request and is ThreadLocal. * extensions of RequestContext can be substituted by setting the contextClass. * Most methods here are convenience wrapper methods; the RequestContext is an extension of a ConcurrentHashMap * * @author Mikey Cohen * Date: 10/13/11 * Time: 10:21 AM */ Zuul 中有四种不同生命周期的 Filter，分别是： pre：在 Zuul 按照规则路由到下级服务之前执行。如果需要对请求进行预处理，比如鉴权、限流等，都应考虑在此类 Filter 中实现。 route：这类 Filter 是 Zuul 路由动作的执行者，是 Apache HttpClient 或 Netflix Ribbon 构建和发送原始 HTTP 请求的地方，目前已支持 OkHttp。 post：这类 Filter 是在源服务返回结果或者异常信息发生后执行的，如果需要对返回信息做一些处理，则在此 Filter 进行处理。 error：在整个生命周期内如果发生异常，则会进入 error Filter，可做全局异常处理。 6.3.2 Zuul Filter 和 Actuator@EnableZuulProxy + Spring Boot Actuator 会多两个管控端点： /routes：返回当前 Zuul Server 中所有已生成的映射规则，加上 /details 可查看明细。 /filters：返回当前 Zuul Server 中所有已注册生效的 Filter。 6.3.3 多级业务处理实现自定义 Filter 继承 ZuulFIlter 抽象类，它包括以下等几个方法： String filterType()：抽象方法。使用返回值设置 Filter 类型，可以设置为 pre，route，post，error 类型。 int filterOrder()：抽象方法。使用返回值设置 Filter 的执行顺序，即优先权。 boolean shouldFilter()：使用返回值设置 Filter 是否执行，可作为开关使用。 Object run()：Filter 里面的核心执行逻辑，业务处理在此编写。该方法是重写了 IZuulFilter 接口类的方法，而不是 Thread / Runnable 的。 代码实例： 1234567891011121314151617181920212223public class FirstPreFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { System.out.println(&quot;这是第一个自定义Zuul Filter！&quot;); return null; }} 别忘记了注入该 Bean： 1234@Beanpublic FirstPreFilter firstPreFilter() { return new FirstPreFilter();} 业务处理实战这里模拟一个业务需求：使用 SecondPreFilter 来验证请求是否传入参数 a，使用 ThirdPreFilter 来验证是否传入 b 参数，最后在 PostFilter 里边统一处理返回内容。 注意： 从 RequestContext 获取 Request 的过程。 filterOrder 优先级的设置。 在 pre 禁止路由后的处理：设定 responseBody 供 PostFilter 使用；为同类型下游 Filter 设置执行开关。 以下为 SecondPreFilter.java: 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SecondPreFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 2; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { System.out.println(&quot;这是SecondPreFilter！&quot;); //从RequestContext获取上下文 RequestContext ctx = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = ctx.getRequest(); //从request尝试获取a参数值 String a = request.getParameter(&quot;a&quot;); //如果a参数值为空则进入此逻辑 if (null == a) { //对该请求禁止路由，也就是禁止访问下游服务 ctx.setSendZuulResponse(false); //设定responseBody供PostFilter使用 ctx.setResponseBody(&quot;{\\&quot;status\\&quot;:500,\\&quot;message\\&quot;:\\&quot;a参数为空！\\&quot;}&quot;); //logic-is-success保存于上下文，作为同类型下游Filter的执行开关 ctx.set(&quot;logic-is-success&quot;, false); //到这里此Filter逻辑结束 return null; } //设置避免报空 ctx.set(&quot;logic-is-success&quot;, true); return null; }} ThirdPreFilter.java: 123456789101112131415161718192021222324252627282930313233343536373839404142public class ThirdPreFilter extends ZuulFilter { @Override public String filterType() { return PRE_TYPE; } @Override public int filterOrder() { return 3; } @Override public boolean shouldFilter() { RequestContext ctx = RequestContext.getCurrentContext(); //从上下文获取logic-is-success值，用于判断此Filter是否执行 return (boolean)ctx.get(&quot;logic-is-success&quot;); } @Override public Object run() throws ZuulException { System.out.println(&quot;这是ThirdPreFilter！&quot;); //从RequestContext获取上下文 RequestContext ctx = RequestContext.getCurrentContext(); //从上下文获取HttpServletRequest HttpServletRequest request = ctx.getRequest(); //从request尝试获取b参数值 String b = request.getParameter(&quot;b&quot;); //如果b参数值为空则进入此逻辑 if (null == b) { //对该请求禁止路由，也就是禁止访问下游服务 ctx.setSendZuulResponse(false); //设定responseBody供PostFilter使用 ctx.setResponseBody(&quot;{\\&quot;status\\&quot;:500,\\&quot;message\\&quot;:\\&quot;b参数为空！\\&quot;}&quot;); //logic-is-success保存于上下文，作为同类型下游Filter的执行开关，假定后续还有自定义Filter当设置此值 ctx.set(&quot;logic-is-success&quot;, false); //到这里此Filter逻辑结束 return null; } return null; }} PostFilter 主要是用于检查有无定制 ResponseBody，以及设置响应字符集，避免中文乱码，此外还设定了 http 状态码。 PostFilter.java: 12345678910111213141516171819202122232425262728293031323334353637public class PostFilter extends ZuulFilter { @Override public String filterType() { return POST_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { System.out.println(&quot;这是PostFilter！&quot;); //从RequestContext获取上下文 RequestContext ctx = RequestContext.getCurrentContext(); //处理返回中文乱码 ctx.getResponse().setCharacterEncoding(&quot;UTF-8&quot;); //获取上下文中保存的responseBody String responseBody = ctx.getResponseBody(); //如果responseBody不为空，则说明流程有异常发生 if (null != responseBody) { //设定返回状态码 ctx.setResponseStatusCode(500); //替换响应报文 ctx.setResponseBody(responseBody); } return null; }} 6.3.4 Zuul 权限集成 Spring Cloud 不选择 Apache Shiro 的原因：Shiro 更适合单体应用的场景。在解决方案的选择上面，传统的譬如单点登陆（SSO），或者分布式 Session，要么致使权限服务器集中化导致流量臃肿，要么需要自己实现一套复杂的存储同步机制，都不是最好的解决方案。对于 Zuul，比较好的方案有： 自定义权限认证 Filter OAuth2.0 + JWT(JSON Web Token) 使用 OAuth2.0 协议的思想拉取认证生成 Token，再颁发给 JWT。使用 JWT 瞬时保存这个 Token，在客户端与资源端进行对称或非对称加密，使得这个规约具有定时、定量的授权认证功能，从而免去 Token 存储所带来的安全或系统拓展问题。 单点登陆（SSO）和分布式 Session 介绍认证 (authentication) 和授权 (authorization) 的区别User 和 Password Zuul + OAuth2.0 + JWT 实战 - Hardly1). zuul-server 编写说明 zuul-server 的作用是当请求接口时，判断是否登录鉴权。如果未登录，则跳转到 auth-server 的登录界面（默认为 Spring Security OAuth 的登录界面，也可以自行定制。），登录成功后 auth-server 颁发 jwt token，zuul-server 在访问下游服务时将 jwt token 放入 header 中即可。 具体实现： 在 pom.xml 中引入对 OAuth2 与 Security 的支持： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 编写核心配置文件 bootstrap.yml： 1234567891011121314151617181920212223242526272829spring: application: name: zuul-serverserver: port: 5555eureka: client: serviceUrl: defaultZone: http://${eureka.host:127.0.0.1}:${eureka.port:8888}/eureka/ instance: prefer-ip-address: truezuul: routes: client-a: path: /client/** serviceId: client-asecurity: basic: enabled: false oauth2: client: access-token-uri: http://localhost:7777/uaa/oauth/token #令牌端点 user-authorization-uri: http://localhost:7777/uaa/oauth/authorize #授权端点 client-id: zuul_server #OAuth2客户端ID client-secret: secret #OAuth2客户端密钥 resource: jwt: key-value: springcloud123 #使用对称加密方式，默认算法为HS256 编写主启动类，重写 WebSecurityConfigurerAdapter 适配器的 configure(HttpSecurity http) 方法，声明需要鉴权的 url 信息： 1234567891011121314151617181920212223@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxy@EnableOAuth2Ssopublic class ZuulServerApplication extends WebSecurityConfigurerAdapter{ public static void main(String[] args) { SpringApplication.run(ZuulServerApplication.class, args); } @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(&quot;/login&quot;, &quot;/client/**&quot;) .permitAll() .anyRequest() .authenticated() .and() .csrf() .disable(); }} 2). auth-server 编写说明 auth-server 作为认证授权中心，会生成颁发 jwt token 凭证。 具体实现： 在 pom.xml 中引入对 OAuth2 的支持： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 编写核心配置文件 bootstrap.yml： 12345678910111213spring: application: name: auth-serverserver: port: 7777 servlet: contextPath: /uaa #web基路径eureka: client: serviceUrl: defaultZone: http://${eureka.host:127.0.0.1}:${eureka.port:8888}/eureka/ instance: prefer-ip-address: true 编写认证授权服务适配器类 **OAuthConfiguration.java**： 123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAuthorizationServerpublic class OAuthConfiguration extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(&quot;zuul_server&quot;) .secret(&quot;secret&quot;) .scopes(&quot;WRIGTH&quot;, &quot;read&quot;).autoApprove(true) .authorities(&quot;WRIGTH_READ&quot;, &quot;WRIGTH_WRITE&quot;) .authorizedGrantTypes(&quot;implicit&quot;, &quot;refresh_token&quot;, &quot;password&quot;, &quot;authorization_code&quot;); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .tokenStore(jwtTokenStore()) .tokenEnhancer(jwtTokenConverter()) .authenticationManager(authenticationManager); } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(&quot;springcloud123&quot;); return converter; }} 编写主启动类： 12345678910111213141516171819202122232425262728@SpringBootApplication@EnableDiscoveryClientpublic class AuthServerApplication extends WebSecurityConfigurerAdapter { public static void main(String[] args) { SpringApplication.run(AuthServerApplication.class, args); } @Bean(name = BeanIds.AUTHENTICATION_MANAGER) @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth .inMemoryAuthentication() .withUser(&quot;guest&quot;).password(&quot;guest&quot;).authorities(&quot;WRIGTH_READ&quot;) .and() .withUser(&quot;admin&quot;).password(&quot;admin&quot;).authorities(&quot;WRIGTH_READ&quot;, &quot;WRIGTH_WRITE&quot;); } @Bean public static NoOpPasswordEncoder passwordEncoder() { return (NoOpPasswordEncoder) NoOpPasswordEncoder.getInstance(); }} 3). client-a 编写说明 client-a 按照规则解析 jwt token。 具体实现： 编写主启动类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@SpringBootApplication@EnableDiscoveryClient@EnableResourceServer@RestControllerpublic class ClientAApplication extends ResourceServerConfigurerAdapter { public static void main(String[] args) { SpringApplication.run(ClientAApplication.class, args); } @RequestMapping(&quot;/test&quot;) public String test(HttpServletRequest request) { System.out.println(&quot;----------------header----------------&quot;); Enumeration headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) { String key = (String) headerNames.nextElement(); System.out.println(key + &quot;: &quot; + request.getHeader(key)); } System.out.println(&quot;----------------header----------------&quot;); return &quot;hellooooooooooooooo!&quot;; } @Override public void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers(&quot;/**&quot;).authenticated() .antMatchers(HttpMethod.GET, &quot;/test&quot;) .hasAuthority(&quot;WRIGTH_READ&quot;); } @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources .resourceId(&quot;WRIGTH&quot;) .tokenStore(jwtTokenStore()); } @Bean protected JwtAccessTokenConverter jwtTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(&quot;springcloud123&quot;); return converter; } @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtTokenConverter()); }} 6.3.5 Zuul 限流 应对异常流量有许多方法，如：降级处理、限流、流量排队、分流等。 限流算法漏桶（Leaky Bucket）漏桶算法能够强制限定流量速率，溢出的流量并非完全丢弃。可将这部分流量收集到一个队列里，做流量排队，尽量做到合理利用资源。 令牌桶（Token Bucket）&nbsp; 令牌包装着数据流。当数据流涌来时，如果取到令牌则放行，同时桶内丢弃掉这个令牌；如果不能取到令牌，请求则会被丢弃。&nbsp; 令牌桶可以存在一定程度的流量突发。因为令牌桶可以存在一定数量的令牌，且令牌一直以恒定速率加入。 &amp;nbsp;代表 No-Break Space 限流实战 利用 spring-cloud-zuul-ratelimit zuul-server 编写说明pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;com.marcosbarbero.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-zuul-ratelimit&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; bootstrap.yml 1234567891011121314151617181920212223242526272829spring: application: name: zuul-serverserver: port: 5555eureka: client: serviceUrl: defaultZone: http://${eureka.host:127.0.0.1}:${eureka.port:8888}/eureka/ instance: prefer-ip-address: truezuul: routes: client-a: path: /client/** serviceId: client-a ratelimit: key-prefix: springcloud-book #按粒度拆分的临时变量key前缀 enabled: true #启用开关 repository: IN_MEMORY #key存储类型，默认是IN_MEMORY本地内存，此外还有多种形式 behind-proxy: true #表示代理之后 default-policy: #全局限流策略，可单独细化到服务粒度 limit: 2 #在一个单位时间窗口的请求数量 quota: 1 #在一个单位时间窗口的请求时间限制 refresh-interval: 3 #单位时间窗口 type: - user #可指定用户粒度 - origin #可指定客户端地址粒度 - url #可指定url粒度 当流量超限时，会返回 Too Many Reqeusts 429 状态码。 6.3.6 Zuul 动态路由 6.3.7 Zuul 灰度发布 6.3.8 Zuul 文件上传 6.3.8 Zuul 实用小技巧饥饿加载请求体修改使用 okhttp 代替 HttpClient重试机制Header 传递整合 Swagger2 调试源服务第 7 章 生产环境各组件参考配置7.1 Eureka 推荐配置123456# eureka server# ...eureka: server: enable-self-preservation: false eviction-interval-timer-in-ms: 30000 # 主动失效检测间隔，默认 60s，可以设置短一点。 7.2 Ribbon 推荐配置123456ribbon: ConnectTimeout: 5000 # 全局请求连接的超时时间，默认 5 秒。 ReadTimeout: 5000 # 全局请求的超时时间，默认 5 秒。 MaxAutoRetries: 0 # 对当前实例的重试次数。 MaxAutoRetriesNextServer: 0 # 切换下一个实例重试次数。 OktoRetryOnAllOperations: false # 对所有操作请求进行重试。 7.3 Hystrix 推荐配置1234567hystrix: command: default: executino: isolation: thread: timeoutInMilliseconds: 10000 # 全局请求连接的超时时间默认为 1s，通常会调整这个值的大小，推荐设为 10s。若请求需要的时间过长则对单个 command 设置单独时间。 7.4 Zuul 推荐配置12345678910111213141516171819202122232425262728zuul: ribbonIsolationStrategy: THREAD threadPool: useSeparateThreadPools: true threadPoolKeyPrefix: zuulgateway max: host: max-per-route-connections: 200 max-total-connections: 500 host: socket-timeout-millis: 5000 connect-timeout-millis: 10000hystrix: threadpool: default: coreSize: 20 maximumSize: 50 maxQueueSize: -1 allowMaximumSizeToDivergeFromCoreSize: true command: default: execution: timeout: enabled: false isolation: thread: interruptOnTimeout: false timeoutInMilliseconds: 15000 第 8 章 Spring Cloud Config8.1 Spring Cloud Config 入门案例 Config Server 配置 12345678910111213spring: cloud: config: server: git: uri: https://gitee.com/zhongzunfa/spring-cloud-config.git # 项目地址 #username: #password: search-paths: SC-BOOK-CONFIG # 配置文件的路径 application: name: sc-config-gitserver: port: 9090 Config Client 配置 12345678spring: cloud: config: label: master uri: http://localhost:9090 # 配置文件名：config-info-dev.yml name: config-info profile: dev ConfigInfoProperties.java: 1234567891011121314@Component@ConfigurationProperties(prefix = &quot;cn.springcloud.book&quot;)public class ConfigInfoProperties { private String config; public String getConfig() { return config; } public void setConfig(String config) { this.config = config; }} 8.2 结合 Spring Cloud bus 热刷新8.2.1 config-server-buspom.xml: 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-monitor&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 需要安装 rabbitmq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 做简单的安全和端点开放 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; SecurityConfiguration.java: 12345678@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); }} application.properties: 1 application.yml: 123456789101112131415161718192021222324252627spring: cloud: config: server: git: uri: https://gitee.com/zhongzunfa/spring-cloud-config.git #username: #password: search-paths: SC-BOOK-CONFIG bus: trace: enabled: true application: name: ch11-3-config-server-bus ## 配置rabbitMQ 信息 rabbitmq: host: localhost port: 5672 username: guest password: guestserver: port: 9090 8.2.2 config-client-bus-refreshpom.xml: 12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 做简单的安全和端点开放 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml: 1234567spring: cloud: config: label: master uri: http://localhost:9090 name: config-info profile: dev application.yml: 1234567891011121314151617server: port: 9095spring: application: name: ch11-3-config-client-bus-refresh ## 配置rabbitMQ 信息 rabbitmq: host: localhost port: 5672 username: guest password: guest cloud: bus: trace: enabled: true ConfigClientController.java: 12345678910111213@RefreshScope@RestController@RequestMapping(&quot;configConsumer&quot;)public class ConfigClientController { @Autowired private ConfigInfoProperties configInfoValue; @RequestMapping(&quot;/getConfigInfo&quot;) public String getConfigInfo(){ return configInfoValue.getConfig(); }} 执行服务端的端点 bus-refresh，地址为 http://localhost:9090/actuator/bus-refresh 可将其挂在 webhooks 上。 8.3 数据库的配置中心的实现8.3.1 MySQL 实现project of config-server-db: 123456789101112131415161718192021222324252627server: port: 9090spring: application: name: ch12-3-config-server-db cloud: config: server: jdbc: sql: SELECT `KEY`, `VALUE` FROM PROPERTIES WHERE application =? AND profile =? AND lable =? label: master refresh: refreshable: none profiles: active: jdbc ## 数据配置 datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud?useUnicode=true&amp;characterEncoding=UTF-8 username: root password: 123456 driver-class-name: com.mysql.jdbc.Driverlogging: level: org.springframework.jdbc.core: DEBUG org.springframework.jdbc.core.StatementCreatorUtils: Trace project of config-client-db: 123456789spring: cloud: config: # name, profile，label（按顺序） 是 sql 中的参数。 label: master uri: http://localhost:9090 name: config-info profile: dev 8.3.2 MongoDB 实现project of config-server-mongodb: pom.xml: 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server-mongodb&lt;/artifactId&gt; &lt;version&gt;0.0.2.BUILD-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml: 123456789server: port: 9090spring: application: name: ch12-4-config-server-mongodb data: mongodb: uri: mongodb://localhost/springcloud Application.java: 增加@EnableMongoConfigServer注解。 project of config-client-mongodb: 略 第 9 章 Spring Cloud 认证和鉴权9.1 认证和鉴权方案9.1.1 单体应用下的常用方案在传统的单体应用中，一般会写一个固定的认证和鉴权的包（利用shiro等），里面包含了很多认证和鉴权的类，当用户发起请求时可以利用 session 的方式，把用户存入 session 并生成一个 sessionId，之后返回客户端。客户端可以将 session 信息存在 Cookie 里，从而在后续的请求中顺利通过验证。 9.1.2 微服务下 SSO 单点登录方案对每个微服务都采用 SSO 单点登录方案。 9.1.3 分布式 Session 与网关结合方案Step： 用户在网关进行 SSO 登录，进行用户认证，检查用户是否存在和有效。 如果认证通过，则将用户的信息或数据存储在第三方部件中（如 MySQL，Redis）。 后端微服务可以从共享存储中拿到用户的数据。 推荐方案，因为方便同时可以做扩展，也可以保证高可用的方案（数据库集群），不过需要增加安全控制，所以实现起来有一定复杂性。 9.1.4 客户端 Token 与网关结合方案Step： 客户端持有一个 Token，通常可用 JWT 或者其他加密的算法实现自己的一种 Token，然后通过 Token 保存了用户的信息。 发起请求并携带 Token， Token 传到网关层后，网关层进行认证和校验。 校验通过，携带 Token 到后台的微服务中，可以进行具体的接口或者 url 验证。 如果要涉及用户的大量数据存放，则 Token 就有可能不大合适，或者和上面的分布式 Session 一样，使用第三方部件来存储这些信息，这种方案也是业界常用的方案，但对于 Token 来说，它的注销有点麻烦，需要在网关层进行 Token 的注销。 9.1.5 浏览器 Cookie 与网关结合方案把用户信息存在 Cookie 里，然后通过网关来解析 Cookie，从而获得用户相关的信息。适合作为老系统改造时采取的方案。 9.1.6 网关与 Token 和服务间鉴权结合Step: 在 Gateway 网关层做认证，通过对用户校验后，传递用户的信息到 header 中， 后台微服务在收到 header 后进行解析，解析完后查看是否有调用此服务或者某个 url 的权限，然后完成鉴权。 从服务内部发出的请求，在出去时进行拦截，把用户信息保存在 header 里，然后传出去，被调用方法获取到 header 后进行解析和鉴权。 9.2 还有一个看不懂的案例…第 10 章 Spring Cloud 全链路监控 （omission）10.1 术语 Span：基本工作单元。 Trace： 一系列 Span 组成的树状结构。 Annotation：标注，用来描述事件的实时状态。 cs：Client Sent。客户端发起请求，它表示一个 Span 的开始。 sr：Server Received。服务方收到请求并开始处理，它减去 cs 的时间就是网络延迟时间。 ss：Server Sent。请求处理完成，将响应数据返回给客户端。它减去 sr 的时间就是服务方处理时间。 cr：Client Received。客户端收到服务方的返回值，是当前 Span 结束的信号。 第 11 章 Spring Cloud Gateway第 12 章 Spring Cloud 与 gRPC12.1 gRPC 比 HTTP/JSON 客户端的性能更好的原因 gRPC 采用了 Protocol Buffers 作为序列化工具，这比采用 JSON 方式进行序列化性能提高了不少。 gRPC 采用了 HTTP2 协议，进行了头部信息压缩，对连接进行了多路复用，减少了 TCP 的(短)连接次数。 gRPC 采用了 Netty 作为 IO 处理框架，提高了性能。 HTTP2 是一个二进制协议，HTTP1.x 是文本协议。 12.2 gRPC 的一些核心概念12.2.1 服务定义gRPC 可以定义 4 种服务方法： Unary RPCS Server streaming RPCS Client streaming RPCS Bidirectional streaming RPCS","link":"/2021/03/04/SpringCloud/"},{"title":"spring cloud alibaba","text":"… 0. 前言 spring cloud alibaba 项目地址 0.1 版本说明 0.2 对比旧 SC 1. Nacos 一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。与 Eureka 相同，均引入了 Ribbon 依赖作负载均衡功能。 1.1 配置安装启动 nacos-server关于集群部署可参照官方指南：https://github.com/nacos-group/nacos-docker Discoveryapplication.yaml 123456spring: application: name: nacos-ribbon-consumer cloud: nacos: server-addr: localhost:8848 code@EnableDiscoveryClient pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; Ribbon12345678910111213141516171819202122232425262728293031323334@SpringBootApplication@EnableDiscoveryClient@RibbonClient(name = &quot;service-provider&quot;,configuration = RibbonSpecialConfig.class)public class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); } @Bean @LoadBalanced // 开启 ribbon，识别服务名并实现负载均衡 public RestTemplate restTemplate() { return new RestTemplate(); }// @Bean// public IRule randomRule() {// return new RandomRule();// } @RestController static class TestController { @Autowired RestTemplate restTemplate; @GetMapping(&quot;/test&quot;) public String test() { // getForObject 是返回一个对象，Entity是 http 报文System.out.println(restTemplate.getForObject(&quot;http://service-provider/echo/test&quot;, String.class)); return &quot;ribbon作用结束&quot;; } }} 12345678// 此处不加 @Configuration 注解是为了防止全局生效，因为该配置只作用于一个service。FeignClient 的独立配置也是一样的道理。public class RibbonSpecialConfig { @Bean public IRule roundRobinRule() { return new RoundRobinRule(); }} YML 文件配置 &lt;clientName&gt;.ribbon.NFLoadBalancerClassName: Should implement ILoadBalancer &lt;clientName&gt;.ribbon.NFLoadBalancerRuleClassName: Should implement IRule &lt;clientName&gt;.ribbon.NFLoadBalancerPingClassName: Should implement IPing &lt;clientName&gt;.ribbon.NIWSServerListClassName: Should implement ServerList &lt;clientName&gt;.ribbon.NIWSServerListFilterClassName: Should implement ServerListFilter 1.2 自定义 Ribbon 负载均衡算法基于 nacos 中服务的实例权重 Attention：直接使用框架自带的 NacosRule 即可，不需要手动实现。 12345678910111213141516171819202122232425262728293031@Configuration@Slf4jpublic class NacosWeightRule extends AbstractLoadBalancerRule { @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) { } /** * 服务名-&gt;服务实例-&gt;服务 */ @Override public Server choose(Object o) { BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer(); String serviceName = loadBalancer.getName(); try { // 基于 nacos 权重的负载均衡算法 Instance serviceInstance = nacosDiscoveryProperties.namingServiceInstance().selectOneHealthyInstance(serviceName); return new NacosServer(serviceInstance); } catch (NacosException e) { e.printStackTrace(); log.error(e.getErrMsg()); return null; } }} 1.3 作为配置中心快速开始首先，在pom.xml添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 在bootstrap.yml中配置nacos-config配置中心地址： 12345678spring: cloud: nacos: config: server-addr: 127.0.0.1:8848 file-extension: yaml # profiles: # active: prod Note${spring.profiles.active} 当通过配置文件来指定时必须放在 bootstrap.yml 文件中。 | 最后，在nacos新建如下配置即可（后缀yaml不能为yml）： 当配置了spring.profiles.active时，配置中心的dataId命名应为{appName}-{active}.yaml 另外，由于@Bean(单例)只会初始化一次，所以应在@Value注解所在类上增加@RefreshScope才能动态刷新配置。 获取环境变量的代码如下； 123456public static void main(String[] args) { ConfigurableApplicationContext applicationContext = SpringApplication.run(NacosConfigApplication.class, args); String userName = applicationContext.getEnvironment().getProperty(&quot;env.user.name&quot;); String userAge = applicationContext.getEnvironment().getProperty(&quot;env.user.age&quot;);} 多个环境通用配置配置在{appName}.yaml中即可，对应{appName}.yml文件。 多个应用的配置共享例如，当各个服务都配置了同一个服务注册中心时，这些配置其实都可以抽离出作为通用配置。 （已弃用） 123456789101112131415spring.application.name=opensource-service-providerspring.cloud.nacos.config.server-addr=127.0.0.1:8848# config external configuration# 1、Data Id 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新spring.cloud.nacos.config.extension-configs[0].data-id=ext-config-common01.properties# 2、Data Id 不在默认的组，不支持动态刷新spring.cloud.nacos.config.extension-configs[1].data-id=ext-config-common02.propertiesspring.cloud.nacos.config.extension-configs[1].group=GLOBALE_GROUP# 3、Data Id 既不在默认的组，也支持动态刷新spring.cloud.nacos.config.extension-configs[2].data-id=ext-config-common03.propertiesspring.cloud.nacos.config.extension-configs[2].group=REFRESH_GROUPspring.cloud.nacos.config.extension-configs[2].refresh=true 12345678# 配置支持共享的 Data Idspring.cloud.nacos.config.shared-configs[0].data-id=common.yaml# 配置 Data Id 所在分组，缺省默认 DEFAULT_GROUPspring.cloud.nacos.config.shared-configs[0].group=GROUP_APP1# 配置Data Id 在配置变更时，是否动态刷新，缺省默认 falsespring.cloud.nacos.config.shared-configs[0].refresh=true 通过 spring.cloud.nacos.config.shared-configs[n].data-id 来支持多个共享 Data Id 的配置。 通过 spring.cloud.nacos.config.shared-configs[n].group 来配置自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。 通过 spring.cloud.nacos.config.shared-configs[n].refresh 来控制该Data Id在配置变更时，是否支持应用中动态刷新，默认false。 其它特性namespace 用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 group Nacos 中的一组配置集，是组织配置的维度之一。通过一个有意义的字符串（如 Buy 或 Trade ）对配置集进行分组，从而区分 Data ID 相同的配置集。当您在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP 。配置分组的常见场景：不同的应用或组件使用了相同的配置类型，如 database_url 配置和 MQ_topic 配置。 1.4 生产环境部署clone并使用docker-compose启动：https://github.com/nacos-group/nacos-docker Attention 在docker-compose.yml和xxx.env文件中修改使用自己初始化后的mysql 初始化sql脚本：https://github.com/alibaba/nacos/blob/develop/distribution/conf/nacos-mysql.sql 2. Feign 应用2.1 日志打印 YML 全局配置1234567feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic YML 自定义配置12345678910111213141516feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder decoder: com.example.SimpleDecoder contract: com.example.SimpleContract 代码配置1logging.level.project.user.UserClient: DEBUG 1234567@Configurationpublic class FooConfiguration { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; }} 2.2 实现拦截器2.3 细节 多参数请求 12@GetMapping(&quot;/q&quot;) # 仅限GET请求，也可以使用@RequestParam替代@SpringQueryMap拆分为多个参数。也可以直接用@RequestParam + Map接受参数，但是不推荐UserDTO query(@SpringQueryMap UserDTO userDTO); 关闭 Hystrix 1234# To disable Hystrix in Feignfeign: hystrix: enabled: false 文件上传/下载 首先，添加依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 文件上传代码如下： 1234567891011121314151617@FeignClient( name = &quot;file-upload-service&quot;, configuration = FileUploadServiceClient.MultipartSupportConfig.class)public interface FileUploadServiceClient extends IFileUploadServiceClient { public class MultipartSupportConfig { @Bean public Encoder feignFormEncoder () { return new SpringFormEncoder(); } } @PostMapping(value = &quot;/upload&quot;) String fileUpload(@RequestPart(value = &quot;file&quot;) MultipartFile file);} 文件下载代码如下： 1234567891011121314151617181920212223242526272829303132333435363738@FeignClient( name = &quot;${feign.name}&quot;, url = &quot;${feign.url}&quot; configuration = DownloadClient.ClientConfiguration.class)public interface DownloadClient { @RequestMapping(&quot;/multipart/download/{fileId}&quot;) MultipartFile[] download(@PathVariable(&quot;fileId&quot;) String fileId); class ClientConfiguration { @Autowired private ObjectFactory&lt;HttpMessageConverters&gt; messageConverters; @Bean public Decoder feignDecoder () { List&lt;HttpMessageConverter&lt;?&gt;&gt; springConverters = messageConverters.getObject().getConverters(); List&lt;HttpMessageConverter&lt;?&gt;&gt; decoderConverters = new ArrayList&lt;HttpMessageConverter&lt;?&gt;&gt;(springConverters.size() + 1); decoderConverters.addAll(springConverters); decoderConverters.add(new SpringManyMultipartFilesReader(4096)); HttpMessageConverters httpMessageConverters = new HttpMessageConverters(decoderConverters); return new SpringDecoder(new ObjectFactory&lt;HttpMessageConverters&gt;() { @Override public HttpMessageConverters getObject() { return httpMessageConverters; } }); } }} 2.4 性能优化 连接池 使用feign-httpclient(Hotox版本已经集成，因为yml的配置已有？) 在pom.xml中添加该依赖12345&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;11.0&lt;/version&gt;&lt;/dependency&gt; 修改yml配置123feign: httpclient: enabled: true 3. Sentinel 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制（限流）、熔断降级（熔断）、系统负载保护等多个维度保护服务的稳定性。Sentinel 新手指南URLWith springcloud 3.1 基础概念断路器状态 主要功能 3.2 Quick start下载并启动 sentinel dashboard启动命令：java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 额外启动命令（-D）： demo1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839@SpringBootApplicationpublic class SentinelApplication { public static void main(String[] args) { SpringApplication.run(SentinelApplication.class, args); } @Service public static class TestService { @SentinelResource(value = &quot;sayHello&quot;,blockHandler = &quot;exceptionHandler&quot;) // ,fallback = &quot;protect&quot; public String sayHello(String name) { System.out.println(10/Integer.parseInt(name)); return &quot;Hello, &quot; + name; } public String protect(String name) { return &quot;生不出人，我很抱歉&quot;; } public String exceptionHandler(String name, BlockException ex) { // Do some log here. System.out.println(&quot;呵呵&quot;); return &quot;Oops, error occurred at &quot; + name; } } @RestController public static class TestController { @Autowired private TestService service; @GetMapping(value = &quot;/hello/{name}&quot;) public String apiHello(@PathVariable String name) { return service.sayHello(name); } }} 另外，Feign 的接入也和 Hystrix 相似。 3.3 Sentinel 配置基础配置 配置sentinel dashboard：localhost:8080 关闭所有节点的监控：spring.cloud.sentinel.filter.enabled=false，使用@SentinelResource注解在Service实现方法处埋点。 开启 Sentinel 对 feign 的支持：feign.sentinel.enabled=true(默认是 false)。另外，fallback 的类需要加上@Component注解。 配置 DataSource 若不配置datasource，流控、降级等规则无法持久化，容易造成丢失。 SentinelProperties 内部提供了 TreeMap 类型的 datasource 属性用于配置数据源信息。 比如配置 4 个数据源： 12345678910111213141516171819202122spring.cloud.sentinel.datasource.ds1.file.file=classpath: degraderule.jsonspring.cloud.sentinel.datasource.ds1.file.rule-type=flow#spring.cloud.sentinel.datasource.ds1.file.file=classpath: flowrule.json#spring.cloud.sentinel.datasource.ds1.file.data-type=custom#spring.cloud.sentinel.datasource.ds1.file.converter-class=com.alibaba.cloud.examples.JsonFlowRuleListConverter#spring.cloud.sentinel.datasource.ds1.file.rule-type=flowspring.cloud.sentinel.datasource.ds2.nacos.server-addr=localhost:8848spring.cloud.sentinel.datasource.ds2.nacos.data-id=sentinelspring.cloud.sentinel.datasource.ds2.nacos.group-id=DEFAULT_GROUPspring.cloud.sentinel.datasource.ds2.nacos.data-type=jsonspring.cloud.sentinel.datasource.ds2.nacos.rule-type=degradespring.cloud.sentinel.datasource.ds3.zk.path = /Sentinel-Demo/SYSTEM-CODE-DEMO-FLOWspring.cloud.sentinel.datasource.ds3.zk.server-addr = localhost:2181spring.cloud.sentinel.datasource.ds3.zk.rule-type=authorityspring.cloud.sentinel.datasource.ds4.apollo.namespace-name = applicationspring.cloud.sentinel.datasource.ds4.apollo.flow-rules-key = sentinelspring.cloud.sentinel.datasource.ds4.apollo.default-flow-rule-value = testspring.cloud.sentinel.datasource.ds4.apollo.rule-type=param-flow 3.4 异常处理全局异常处理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Componentpublic class MyUrlBlockHandler implements UrlBlockHandler { @Override public void blocked(HttpServletRequest request, HttpServletResponse response, BlockException ex) throws IOException { ErrorMsg msg = null; if (ex instanceof FlowException) { msg = ErrorMsg.builder() .status(100) .msg(&quot;限流了&quot;) .build(); } else if (ex instanceof DegradeException) { msg = ErrorMsg.builder() .status(101) .msg(&quot;降级了&quot;) .build(); } else if (ex instanceof ParamFlowException) { msg = ErrorMsg.builder() .status(102) .msg(&quot;热点参数限流&quot;) .build(); } else if (ex instanceof SystemBlockException) { msg = ErrorMsg.builder() .status(103) .msg(&quot;系统规则（负载/...不满足要求）&quot;) .build(); } else if (ex instanceof AuthorityException) { msg = ErrorMsg.builder() .status(104) .msg(&quot;授权规则不通过&quot;) .build(); } // http状态码 response.setStatus(500); response.setCharacterEncoding(&quot;utf-8&quot;); response.setHeader(&quot;Content-Type&quot;, &quot;application/json;charset=utf-8&quot;); response.setContentType(&quot;application/json;charset=utf-8&quot;); // spring mvc自带的json操作工具，叫jackson new ObjectMapper() .writeValue( response.getWriter(), msg ); }}@Data@Builder@AllArgsConstructor@NoArgsConstructorclass ErrorMsg { private Integer status; private String msg;} 方法内异常处理123456789101112@SentinelResource( value = &quot;test-sentinel-api&quot;, blockHandler = &quot;block&quot;, blockHandlerClass = TestControllerBlockHandlerClass.class, fallback = &quot;fallback&quot;)public String testSentinelResource(@RequestParam(required = false) String a) { if (StringUtils.isBlank(a)) { throw new IllegalArgumentException(&quot;a cannot be blank.&quot;); } return a;} 1234567891011121314@Slf4jpublic class TestControllerBlockHandlerClass { /** * 处理限流或者降级 * * @param a * @param e * @return */ public static String block(String a, BlockException e) { log.warn(&quot;限流，或者降级了 block&quot;, e); return &quot;限流，或者降级了 block&quot;; }} 3.5 网关限流 关键就是能把资源识别成 @SentinelSource参照：https://github.com/alibaba/Sentinel/wiki/%E7%BD%91%E5%85%B3%E9%99%90%E6%B5%81 Spring Cloud GatewayZuul 1.x &amp; 2.x4. RocketMQ 文档汇总：RocketMQ 开发者指南：https://github.com/apache/rocketmq/tree/master/docs/cnapache rocketmq 官方文档：https://rocketmq.apache.org/docs/quick-start/ RocketMQ-Spring 框架是 RocketMQ 与 Spring Boot 的整合，RocketMQ Spring 主要提供了 3 个特性： 使用 RocketMQTemplate 用来统一发送消息，包括同步、异步发送消息和事务消息 @RocketMQTransactionListener 注解用来处理事务消息的监听和回查 @RocketMQMessageListener 注解用来消费消息 4.1 基本概念 Addition标签(Tag)：为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。 4.2 最佳实践 TIPS:a. 不需要依赖返回值的 methods 可以使用 async 执行（耗时等于 0）。b. MQ 适用场景： Spring 实现异步的方法 AsyncRestTemplate @Async 注解（常用） WebClient 消息队列（次常用）：生产 + 消费架构 Kafka、RocketMQ、RabbitMQ 对比 面试围绕：1.业务(事务，定时/延迟消息，重试机制) 2.性能(TPS，集群) RocketMQ: 唯一支持事务，消息堆积性能稳定（和卡夫卡一样）RabbitMQ: 使用 Erlang 语言 a. 生产者发送消息注意事项 TAG: 一个应用尽可能用一个Topic，而消息子类型则可以用tags来标识。 1MessageBuilder builder = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TAGS, &quot;binder&quot;) .setHeader(RocketMQHeaders.KEYS, &quot;my-key&quot;) .setHeader(MessageConst.PROPERTY_DELAY_TIME_LEVEL, &quot;1&quot;); Message message = builder.build(); output().send(message); Keys: 每个消息在业务层面的唯一标识码要设置到keys字段，方便将来定位消息丢失问题。 123// 订单IdString orderId = &quot;20034568923546&quot;;message.setKeys(orderId); 日志的打印：消息发送成功或者失败要打印消息日志，务必要打印SendResult和key字段。 消息发送失败处理方式Producer的send方法本身支持内部重试，重试逻辑如下： 至多重试2次（同步发送为2次，异步发送为0次）。 如果发送失败，则轮转到下一个Broker。这个方法的总耗时时间不超过sendMsgTimeout设置的值，默认10s。 如果本身向broker发送消息产生超时异常，就不会再重试。（自行处理） 如果业务对消息可靠性要求比较高，建议应用增加相应的重试逻辑：比如调用send同步方法发送失败时，则尝试将消息存储到db，然后由后台线程定时重试，确保消息一定到达Broker。(RocketMQ不集成DB主要考虑2点：性能和安全) b. 消费者保证幂等性利用消息体中的唯一标识字段做判断。不能使用消息 id，因为可能会存在相同的消息有两个不同msgId的情况（消费者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行重复消费。 消费速度慢的处理方式提高消费并行度 绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法： 同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax实现。 批量方式消费 某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。 c. Broker Broker 角色分为 ASYNC_MASTER（异步主机）、SYNC_MASTER（同步主机）以及SLAVE（从机）。如果对消息的可靠性要求比较严格，可以采用 SYNC_MASTER加SLAVE的部署方式。如果对消息可靠性要求不高，可以采用ASYNC_MASTER加SLAVE的部署方式。如果只是测试方便，则可以选择仅ASYNC_MASTER或仅SYNC_MASTER的部署方式。 e. Message 结构 字段名 默认值 说明 Topic null 必填，消息所属topic的名称 Body null 必填，消息体 Tags null 选填，消息标签，方便服务器过滤使用。目前只支持每个消息设置一个tag Keys null 选填，代表这条消息的业务关键词，服务器会根据keys创建哈希索引，设置后，可以在Console系统根据Topic、Keys来查询消息，由于是哈希索引，请尽可能保证key唯一，例如订单号，商品Id等。 Flag 0 选填，完全由应用来设置，RocketMQ不做干预 DelayTimeLevel 0 选填，消息延时级别，0表示不延时，大于0会延时特定的时间才会被消费 WaitStoreMsgOK TRUE 选填，表示消息是否在服务器落盘后才返回应答。 系统配置JVM优化 推荐使用最新发布的JDK 1.8版本。通过设置相同的Xms和Xmx值来防止JVM调整堆大小以获得更好的性能。简单的JVM配置如下所示： -server -Xms8g -Xmx8g -Xmn4g 如果您不关心RocketMQ Broker的启动时间，还有一种更好的选择，就是通过“预触摸”Java堆以确保在JVM初始化期间每个页面都将被分配。那些不关心启动时间的人可以启用它： ​ -XX:+AlwaysPreTouch禁用偏置锁定可能会减少JVM暂停， ​ -XX:-UseBiasedLocking至于垃圾回收，建议使用带JDK 1.8的G1收集器。 1234-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 这些GC选项看起来有点激进，但事实证明它在我们的生产环境中具有良好的性能。另外不要把-XX:MaxGCPauseMillis的值设置太小，否则JVM将使用一个小的年轻代来实现这个目标，这将导致非常频繁的minor GC，所以建议使用rolling GC日志文件： 1234-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m 如果写入GC文件会增加代理的延迟，可以考虑将GC日志文件重定向到内存文件系统： 1-Xloggc:/dev/shm/mq_gc_%p.log123 集群部署 包括单Master模式、多Master模式、多Master多slave模式。详见https://github.com/apache/rocketmq/blob/master/docs/cn/operation.md 4.3 demo a. 安装部署参考：http://www.imooc.com/article/290089 或 quick start。b. 常用特性有：RocketMQTemplate，@RocketMQTransactionListener，@RocketMQMessageListenerc. RocketMQ Console 可视化工具：https://github.com/apache/rocketmq-externals/tree/master/rocketmq-console 4.4 事务处理基本概念2PC：Three-phase commit，二阶段提交。3PC：多了一个补偿机制。即本地服务挂了无法通知事务状态的时候，对方（mq）会由定时任务来主动询问他的状态，并且有超时机制。 实现原理原理：等本地事务（一阶段）完成，再根据本地事务的状态决定时候要消费还是丢弃这条消息（二阶段）。（以性能损耗为代价） 流程图： 代码实现Stream-rocketmq 若要发送带事务的消息，需要在yml中配置： 123456789spring.cloud.stream.bindings.output1.destination=test-topicspring.cloud.stream.bindings.output1.content-type=application/jsonspring.cloud.stream.rocketmq.bindings.output1.producer.group=binder-groupspring.cloud.stream.rocketmq.bindings.output1.producer.sync=truespring.cloud.stream.bindings.output2.destination=TransactionTopicspring.cloud.stream.bindings.output2.content-type=application/jsonspring.cloud.stream.rocketmq.bindings.output2.producer.transactional=true # 看这里spring.cloud.stream.rocketmq.bindings.output2.producer.group=myTxProducerGroup 示例一 12345678910111213141516171819202122232425262728293031@RocketMQTransactionListener(txProducerGroup = &quot;myTxProducerGroup&quot;, corePoolSize = 5, maximumPoolSize = 10)public class TransactionListenerImpl implements RocketMQLocalTransactionListener { @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) { Object num = msg.getHeaders().get(&quot;test&quot;); if (&quot;1&quot;.equals(num)) { System.out.println( &quot;executer: &quot; + new String((byte[]) msg.getPayload()) + &quot; unknown&quot;); return RocketMQLocalTransactionState.UNKNOWN; } else if (&quot;2&quot;.equals(num)) { System.out.println( &quot;executer: &quot; + new String((byte[]) msg.getPayload()) + &quot; rollback&quot;); return RocketMQLocalTransactionState.ROLLBACK; } System.out.println( &quot;executer: &quot; + new String((byte[]) msg.getPayload()) + &quot; commit&quot;); return RocketMQLocalTransactionState.COMMIT; } @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { System.out.println(&quot;check: &quot; + new String((byte[]) msg.getPayload())); return RocketMQLocalTransactionState.COMMIT; }} 示例二：结合事务表 1234567891011121314151617181920212223242526272829303132333435363738394041@RocketMQTransactionListener(txProducerGroup = &quot;tx-add-bonus-group&quot;)@RequiredArgsConstructor(onConstructor = @__(@Autowired))public class AddBonusTransactionListener implements RocketMQLocalTransactionListener { private final ShareService shareService; private final RocketmqTransactionLogMapper rocketmqTransactionLogMapper; @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) { MessageHeaders headers = msg.getHeaders(); String transactionId = (String) headers.get(RocketMQHeaders.TRANSACTION_ID); Integer shareId = Integer.valueOf((String) headers.get(&quot;share_id&quot;)); String dtoString = (String) headers.get(&quot;dto&quot;); ShareAuditDTO auditDTO = JSON.parseObject(dtoString, ShareAuditDTO.class); try { this.shareService.auditByIdWithRocketMqLog(shareId, auditDTO, transactionId); return RocketMQLocalTransactionState.COMMIT; } catch (Exception e) { return RocketMQLocalTransactionState.ROLLBACK; } } @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { MessageHeaders headers = msg.getHeaders(); String transactionId = (String) headers.get(RocketMQHeaders.TRANSACTION_ID); // select * from xxx where transaction_id = xxx RocketmqTransactionLog transactionLog = this.rocketmqTransactionLogMapper.selectOne( RocketmqTransactionLog.builder() .transactionId(transactionId) .build() ); if (transactionLog != null) { return RocketMQLocalTransactionState.COMMIT; } return RocketMQLocalTransactionState.ROLLBACK; }} 5. Spring Cloud StreamSpring Cloud Stream 是一个用于构建基于消息的微服务应用框架。它基于 SpringBoot 来创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Spring Cloud Stream 提供了消息中间件配置的统一抽象，推出了 publish-subscribe、consumer groups、partition 这些统一的概念。 Spring Cloud Stream 内部有两个概念：Binder 和 Binding。 Binder: 跟外部消息中间件集成的组件，用来创建 Binding，各消息中间件都有自己的 Binder 实现。 比如 Kafka 的实现 KafkaMessageChannelBinder，RabbitMQ 的实现 RabbitMessageChannelBinder 以及 RocketMQ 的实现 RocketMQMessageChannelBinder。 Binding: 包括 Input Binding(消费者) 和 Output Binding（生产者）。 Binding 在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，实现了开发者只需使用应用程序的 Provider 或 Consumer 生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。 NOTE（注解以后可能弃用）:我们正在使用函数式编程模型（请参阅Spring Cloud Function支持）将单个消息处理程序定义为Consumer 5.1 示例如何接入 RocketMQ在启动示例进行演示之前，我们先了解一下 Spring Cloud 应用如何接入 RocketMQ Binder。 注意：本章节只是为了便于您理解接入方式，本示例代码中已经完成**接入工作，您无需再进行修改。** 首先，修改 pom.xml 文件，引入 RocketMQ Stream Starter。 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 配置 Input 和 Output 的 Binding 信息并配合 @EnableBinding 注解使其生效 1234567@SpringBootApplication@EnableBinding({ Source.class, Sink.class })public class RocketMQApplication { public static void main(String[] args) { SpringApplication.run(RocketMQApplication.class, args); }} 配置 Binding 信息： 1234567891011# 配置rocketmq的nameserver地址spring.cloud.stream.rocketmq.binder.name-server=127.0.0.1:9876# 定义name为output的bindingspring.cloud.stream.bindings.output.destination=test-topicspring.cloud.stream.bindings.output.content-type=application/json# 定义name为input的bindingspring.cloud.stream.bindings.input.destination=test-topicspring.cloud.stream.bindings.input.content-type=application/json# input 的 group 不能省略，否则会报错spring.cloud.stream.bindings.input.group=test-group 示例代码 123456789101112131415161718192021222324252627282930313233@SpringBootApplication@EnableBinding({Source.class, Sink.class})public class RocketMQApplication { public static void main(String[] args) { SpringApplication.run(RocketMQApplication.class, args); } @Service static class TestService { @StreamListener(&quot;input&quot;) public void consumer(String msg) { System.out.println(&quot;接受到的消息为：&quot; + msg); } // 消费指定tag的消息 } @RestController static class TestController { @Autowired// private MessageChannel output; private Source source; @GetMapping(&quot;/test/{msg}&quot;) public String test(@PathVariable String msg) { source.output().send(MessageBuilder.withPayload(msg).build()); System.out.println(&quot;消息已发送&quot;); return msg; } }} 消息处理使用 name 为 output 对应的 binding 发送消息到 test-topic 这个 topic。 使用2个 input binding 订阅数据。 input1: 订阅 topic 为 test-topic 的消息，顺序消费所有消息(顺序消费的前提是所有消息都在一个 MessageQueue 中) input2: 订阅 topic 为 test-topic 的消息，异步消费 tags 为 tagStr 的消息，Consumer 端线程池个数为20 配置信息如下： 1234567891011121314151617spring.cloud.stream.rocketmq.binder.name-server=127.0.0.1:9876spring.cloud.stream.bindings.output.destination=test-topicspring.cloud.stream.bindings.output.content-type=application/jsonspring.cloud.stream.bindings.input1.destination=test-topicspring.cloud.stream.bindings.input1.content-type=text/plainspring.cloud.stream.bindings.input1.group=test-group1spring.cloud.stream.rocketmq.bindings.input1.consumer.orderly=truespring.cloud.stream.bindings.input2.destination=test-topicspring.cloud.stream.bindings.input2.content-type=text/plainspring.cloud.stream.bindings.input2.group=test-group2spring.cloud.stream.rocketmq.bindings.input2.consumer.orderly=falsespring.cloud.stream.rocketmq.bindings.input2.consumer.tags=tagStrspring.cloud.stream.bindings.input2.consumer.concurrency=20 消息发送使用 MessageChannel 进行消息发送： 123456789101112public class ProducerRunner implements CommandLineRunner { @Autowired private MessageChannel output; // 获取name为output的binding @Override public void run(String... args) throws Exception { Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;(); headers.put(MessageConst.PROPERTY_TAGS, &quot;tagStr&quot;); Message message = MessageBuilder.createMessage(msg, new MessageHeaders(headers)); output.send(message); }} 或者使用 RocketMQ 原生的 API 进行消息发送: 123456789public class RocketMQProducer { DefaultMQProducer producer = new DefaultMQProducer(&quot;producer_group&quot;); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); Message msg = new Message(&quot;test-topic&quot;, &quot;tagStr&quot;, &quot;message from rocketmq producer&quot;.getBytes()); producer.send(msg);} 消息接收使用 @StreamListener 注解接收消息： 1234567891011121314@Servicepublic class ReceiveService { @StreamListener(&quot;input1&quot;) public void receiveInput1(String receiveMsg) { System.out.println(&quot;input1 receive: &quot; + receiveMsg); } @StreamListener(&quot;input2&quot;) public void receiveInput2(String receiveMsg) { System.out.println(&quot;input2 receive: &quot; + receiveMsg); }} 消息过滤可参照：http://www.imooc.com/article/290424 主要包括Tags和@StreamListener的condition 5.2 配置说明Stream-RocketMQRocketMQ Consumer Properties下面的这些配置是以 spring.cloud.stream.rocketmq.bindings.&lt;channelName&gt;.consumer. 为前缀的 RocketMQ Consumer 相关的配置。 enable是否启用 Consumer。 默认值: true. tagsConsumer 基于 TAGS 订阅，多个 tag 以 || 分割。 默认值: empty. sqlConsumer 基于 SQL 订阅。 默认值: empty. broadcastingConsumer 是否是广播消费模式。如果想让所有的订阅者都能接收到消息，可以使用广播模式。 默认值: false. orderlyConsumer 是否同步消费消息模式。 默认值: false. delayLevelWhenNextConsume异步消费消息模式下消费失败重试策略： -1,不重复，直接放入死信队列 0,broker 控制重试策略 0,client 控制重试策略 默认值: 0. suspendCurrentQueueTimeMillis同步消费消息模式下消费失败后再次消费的时间间隔。 默认值: 1000. RocketMQ Provider Properties下面的这些配置是以 spring.cloud.stream.rocketmq.bindings.&lt;channelName&gt;.producer. 为前缀的 RocketMQ Producer 相关的配置。 enable是否启用 Producer。 默认值: true. groupProducer group name。 默认值: empty. maxMessageSize消息发送的最大字节数。 默认值: 8249344. transactional是否发送事务消息。 默认值: false. sync是否使用同步得方式发送消息。 默认值: false. vipChannelEnabled是否在 Vip Channel 上发送消息。 默认值: true. sendMessageTimeout发送消息的超时时间(毫秒)。 默认值: 3000. compressMessageBodyThreshold消息体压缩阀值(当消息体超过 4k 的时候会被压缩)。 默认值: 4096. retryTimesWhenSendFailed在同步发送消息的模式下，消息发送失败的重试次数。 默认值: 2. retryTimesWhenSendAsyncFailed在异步发送消息的模式下，消息发送失败的重试次数。 默认值: 2. retryNextServer消息发送失败的情况下是否重试其它的 broker。 默认值: false. 5.3 Stream 其它特性监控 引入 actuator 依赖即可。 异常处理 参照：http://www.imooc.com/article/290435 此处展示一种全局处理： 1234567891011@StreamListener(value = Processor.INPUT)public void handle(String body) { throw new RuntimeException(&quot;x&quot;);}@StreamListener(&quot;errorChannel&quot;)public void error(Message&lt;?&gt; message) { ErrorMessage errorMessage = (ErrorMessage) message; System.out.println(&quot;Handling ERROR: &quot; + errorMessage);} 之前做过的项目是，不管异常与否，都会 ACK 消费消息，再在特定方法中处理异常（最简单的就是记录日志，再手动处理）。 6. Gateway 微服务使用网关/路由的必要性（相比直接调用具体服务的 API）：登录，鉴权，api变动小，过滤器。 6.1 概念术语 Route: 构建网关的基本单位。由 ID, URI, predicates, filters 组成。 Predicate: JDK8 predicate. 用于匹配 HTTP 请求，如 headers 或者 parameters Filter: GatewayFilter,网关过滤器。 工作流程 6.2 快速开始配置predicates application.yml 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - After=2017-01-20T17:42:47.789-07:00[America/Denver] # 指定允许访问的时间，包括Before和After。如12306 12345678spring: cloud: gateway: routes: - id: between_route uri: https://example.org predicates: - Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver] 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - Cookie=mycookie,mycookievalue 12345678spring: cloud: gateway: routes: - id: path_route uri: https://example.org predicates: - Path=/red/{segment},/blue/{segment} # 匹配路径 12345678spring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=green # 匹配请求参数 12345678spring: cloud: gateway: routes: - id: remoteaddr_route uri: https://example.org predicates: - RemoteAddr=192.168.1.1/24 # 匹配允许请求主机的 ip 地址 filters 若需要自定义 filters，参考源码即可。 12345678spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-red, blue # 请求头过滤器 12345678910spring: cloud: gateway: routes: - id: add_request_parameter_route uri: https://example.org predicates: - Host: {segment}.myhost.org filters: - AddRequestParameter=foo, bar-{segment} # 请求参数过滤器 12345678spring: cloud: gateway: routes: - id: add_response_header_route uri: https://example.org filters: - AddResponseHeader=X-Response-Red, Blue 12345678spring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - PrefixPath=/mypath # So a request to `/hello` would be sent to `/mypath/hello`. 全局过滤器实现 GlobalFilter，Order接口： 123456789101112131415161718@Beanpublic GlobalFilter customFilter() { return new CustomGlobalFilter();}public class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { log.info(&quot;custom global filter&quot;); return chain.filter(exchange); } @Override public int getOrder() { return -1; }} CORS 配置123456789spring: cloud: gateway: globalcors: cors-configurations: '[/**]': allowedOrigins: &quot;https://docs.spring.io&quot; allowedMethods: - GET 实现负载均衡在服务 Application 上加上@RibbonClient注解即可，spring cloud gateway 默认开启 LB： 配置格式可参照如下： 12345678910111213141516spring: application: name: gateway cloud: nacos: server-addr: localhost:8848 gateway: discovery: locator: enabled: true # 获取服务中心的其它服务，改成false也不会影响下面的 routes 配置^ ^ routes: - id: useless uri: lb://service-provider predicates : - Path=/echo/{segment} # 访问 path 会自动在前面拼上 {serviceName} 这是另一种不实用的 Ribbon 官方 demo： 1234service-provider: ribbon: listOfServers: localhost:8070, localhost:8071 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 网关限流代码实现参照：官网或http://www.imooc.com/article/290828 这里说明一下限流算法： 漏桶算法： 想象有一个水桶，水桶以一定的速度出水（以一定速率消费请求），当水流速度过大水会溢出（访问速率超过响应速率，就直接拒绝）。 漏桶算法的两个变量： 水桶漏洞的大小：rate最多可以存多少的水：burst令牌桶算法： 系统按照恒定间隔向水桶里加入令牌（Token），如果桶满了的话，就不加了。每个请求来的时候，会拿走1个令牌，如果没有令牌可拿，那么就拒绝服务。 demo12345678910spring: application: name: gateway cloud: nacos: server-addr: localhost:8848 gateway: discovery: locator: enabled: true # 获取服务中心的其它服务，即可通过服务名称直接调用 API 7 微服务的认证和授权7.1 认证几种常用方案 大致分为两类：有状态（将 session 维护在服务端）、无状态（服务端不保存 session 等信息，仅对 jwt 做校验而已） 有状态的缺点：需要单个 redis 服务，和微服务理念违背，当 redis 挂了后，所有服务的 session 将全部失效。 我们现在的系统： 7.2 授权访问控制模型 JWT 项目地址：https://github.com/auth0/java-jwt Quick start 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 生成和校验 JWT 的工具类 * * @author Jacky * Date: 2019/9/26 17:26 */@Slf4j@Componentpublic class JWTHelper { // 应使用配置维护 private String SECRET = &quot;love&quot;; private final Algorithm algorithm = Algorithm.HMAC256(SECRET); // @Value 下的变量不能用 static 修饰符，否则不生效。并且所在类需要被spring容器加载，即需要@Component注解 @Value(&quot;${jwt.expireTime:60}&quot;) public Long expireTime; public String generateJWT(Map&lt;String, String&gt; claims) { JWTCreator.Builder builder = JWT.create(); claims.forEach(builder::withClaim); return builder .withExpiresAt(new Date(System.currentTimeMillis() + expireTime * 1000)) .sign(algorithm); } /** * 需要处理异常情况+判断是否过期 */ public Map&lt;String, String&gt; verifyToken(String jwt) { DecodedJWT decodedJWT = JWT.require(algorithm).build().verify(jwt); log.info(&quot;decodedJWT is : {}&quot;, decodedJWT); Map&lt;String, Claim&gt; claims = decodedJWT.getClaims(); Map&lt;String, String&gt; res = new HashMap&lt;&gt;(); claims.forEach((k, v) -&gt; res.put(k, v.asString())); return res; } public void main(String[] args) { Map&lt;String, String&gt; claims = new HashMap&lt;&gt;(); claims.put(&quot;name&quot;, &quot;jacky&quot;); String jwt = generateJWT(claims); log.info(jwt); verifyToken(jwt).forEach((k, v) -&gt; System.out.println(&quot;key: &quot; + k + &quot; value: &quot; + v)); }} 7.3 认证代码实现 主要有 3 种实现 Servlet 过滤器 拦截器（继承 HandlerInterceptorAdapter） Spring AOP（每个接口都需要加上自定义注解） 过滤器拦截器123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 对未登录的用户进行拦截 * * @author Jacky * Date: 2019/9/26 18:33 */@Slf4jpublic class AuthInterceptor extends HandlerInterceptorAdapter { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (!(handler instanceof HandlerMethod)) { // 如果不是映射到方法则直接通过 return true; } HandlerMethod handlerMethod = (HandlerMethod) handler; String jwt = request.getHeader(&quot;Authorization&quot;); if (StringUtils.isEmpty(jwt)) { throw new Exception(&quot;jwt为空！&quot;); } else { Map&lt;String, String&gt; res = JWTHelper.verifyToken(jwt); String username = res.get(&quot;username&quot;); if (StringUtils.isEmpty(username)) { throw new Exception(&quot;jwt不正确！&quot;); } // 假装验证通过 User user = new User(); user.setUsername(username); UserContext.setUser(user); response.setHeader(&quot;Authorization&quot;, jwt); return true; } } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { String jwt = request.getHeader(&quot;Authorization&quot;); response.setHeader(&quot;Authorization&quot;, jwt); UserContext.remove(); }} AOP概述 执行顺序 around &gt; before &gt; around &gt; after &gt; afterReturning 代码示例 需引入 spring-boot-starter-aop 依赖 例一： 123456789101112@Aspect@Componentpublic class AOPProcess { // @checkLogin 只能作用再方法(aop)上。 @Around(&quot;@annotation(CheckLogin)&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable { System.out.println(&quot;ccccheck login！&quot;); return joinPoint.proceed(); }} 例二： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Aspect@Component@RequiredArgsConstructor(onConstructor = @__(@Autowired))public class AuthAspect { private final JwtOperator jwtOperator; @Around(&quot;@annotation(com.itmuch.usercenter.auth.CheckLogin)&quot;) public Object checkLogin(ProceedingJoinPoint point) throws Throwable { checkToken(); return point.proceed(); } private void checkToken() { try { // 1. 从header里面获取token HttpServletRequest request = getHttpServletRequest(); String token = request.getHeader(&quot;X-Token&quot;); // 2. 校验token是否合法&amp;是否过期；如果不合法或已过期直接抛异常；如果合法放行 Boolean isValid = jwtOperator.validateToken(token); if (!isValid) { throw new SecurityException(&quot;Token不合法！&quot;); } // 3. 如果校验成功，那么就将用户的信息设置到request的attribute里面 Claims claims = jwtOperator.getClaimsFromToken(token); request.setAttribute(&quot;id&quot;, claims.get(&quot;id&quot;)); request.setAttribute(&quot;wxNickname&quot;, claims.get(&quot;wxNickname&quot;)); request.setAttribute(&quot;role&quot;, claims.get(&quot;role&quot;)); } catch (Throwable throwable) { throw new SecurityException(&quot;Token不合法&quot;); } } private HttpServletRequest getHttpServletRequest() { RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes attributes = (ServletRequestAttributes) requestAttributes; return attributes.getRequest(); } @Around(&quot;@annotation(com.itmuch.usercenter.auth.CheckAuthorization)&quot;) public Object checkAuthorization(ProceedingJoinPoint point) throws Throwable { try { // 1. 验证token是否合法； this.checkToken(); // 2. 验证用户角色是否匹配 HttpServletRequest request = getHttpServletRequest(); String role = (String) request.getAttribute(&quot;role&quot;); MethodSignature signature = (MethodSignature) point.getSignature(); Method method = signature.getMethod(); CheckAuthorization annotation = method.getAnnotation(CheckAuthorization.class); String value = annotation.value(); if (!Objects.equals(role, value)) { throw new SecurityException(&quot;用户无权访问！&quot;); } } catch (Throwable throwable) { throw new SecurityException(&quot;用户无权访问！&quot;, throwable); } return point.proceed(); }} 7.4 其它要点Feign 实现 token 传递 使用@RequestHeader注解，接收token参数。 使用Feign的拦截器 RequestInterceptor(常用) 对于第 2 种方法的实现，重点是能够获取 request 中的header（在Spring HandlerInterceptor中，就已经提供了该request参数），即 RequestContextHolder。 1234567891011121314151617181920212223242526272829@FeignClient(name = &quot;service-provider&quot;,configuration = DiscoveryFeign.FeignInterceptor.class)public interface DiscoveryFeign { @GetMapping(&quot;/echo/{string}&quot;) String echo(@PathVariable(&quot;string&quot;) String string); /** * 也可改写成: * @Bean * public xxxIntercetor xxx() { * return new xxxIntercetor(); * } */ class FeignInterceptor implements RequestInterceptor, HandlerInterceptor { @Override public void apply(RequestTemplate requestTemplate) { System.out.println(&quot;经过feign拦截器了&quot;); // 1. 获取 request (通过 RequestContextHolder) ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 2. (feign)传递 token requestTemplate.header(&quot;Authorization&quot;, request.getHeader(&quot;Authorization&quot;)); } }} 在DiscoveryApplication打印token： 123456789@Configurationpublic class WebConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new WebInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/&quot;); }} 12345678public class WebInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String token = request.getHeader(&quot;Authorization&quot;); System.out.println(token); return true; }} 8 分布式跟踪 Spring Cloud Sleuth provides Spring Boot auto-configuration for distributed tracing.官方文档：https://spring.io/projects/spring-cloud-sleuth项目地址：https://github.com/spring-cloud/spring-cloud-sleuth Zipkin是一个分布式跟踪系统。它有助于收集解决服务体系结构中的延迟问题所需的时序数据。功能包括该数据的收集和查找。官网：https://zipkin.io/项目地址：https://github.com/openzipkin/zipkin 8.1 介绍 8.2 快速开始运行 ZipKin-server 1docker run -d -p 9411:9411 openzipkin/zipkin 在项目中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; 配置 zipkin-server 地址 12345678910spring: application: name: monitor cloud: nacos: server-addr: localhost:8848 zipkin: # look at here base-url: http://localhost:9411 discovery-client-enabled: false 8.3 ZipKin 数据持久化建议使用 ES + spark job。参考：https://github.com/openzipkin/zipkin-dependencies zipkin支持以下环境变量（https://github.com/openzipkin/zipkin/tree/master/zipkin-server）： 故在启动时增加es的环境变量即可： 1docker run -e &quot;STORAGE_TYPE=elasticsearch&quot; -e &quot;ES_HOSTS=172.17.0.1:9200&quot; -d -p 9411:9411 openzipkin/zipkin 注意： ES_HOSTS 参数不能直接使用 localhost 与其他容器通信，要使用 docker 网络通信，在容器启动时指定--net，也可以用--link [容器名称]： 12docker network create somenetworkdocker run -d --name kibana --net somenetwork -p 5601:5601 kibana:tag OR use the java command: 1STORAGE_TYPE=elasticsearch ES_HOSTS=localhost:9200 java -jar zipkin.jar spark job 为 zipkin-denpendencies 子项目，使用方法同上。 8.4 zipkin-dependenciesdocker 地址：https://hub.docker.com/r/openzipkin/zipkin-dependencies 9 代码质量9.1 工具 本章节仅演示sonarQube的用法。官方文档：https://docs.sonarqube.org/latest/setup/install-server/ SonarQube 快速开始https://hub.docker.com/_/sonarqube 安装指南https://docs.sonarqube.org/latest/setup/install-server/ 测试用 1docker run -d --name sonarqube -p 9000:9000 sonarqube:community 另外需注意，sonarQube 不支持 mysql 分析代码 12345mvn sonar:sonar \\ -Dsonar.projectKey=SC-alibaba \\ -Dsonar.host.url=http://localhost:9000 \\ -Dsonar.login=42c0f2e5fb71cac3ce38392935f47955c8851e75 \\ -Dsonar.java.binaries=target/sonar 结合 Jenkinshttps://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/ 10 监控工具10.1 SBA 快速开始 包括监控 JVM 等指标。 参照：https://codecentric.github.io/spring-boot-admin/2.2.3/#getting-started 10.2 JVM 监控 除了 Jvisualvm 外，也可以用 SBA GC日志/线程Dump日志/堆Dump可视化分析增加启动参数 VM options: -XX:+PrintGCDetails -Xloggc:gc.log GCEasy(直接上传GC日志即可)、GCPlot FastThread HeapHero 10.3 日志监控 ELK 11. Seata Attention:192.168.1.1是内网地址，是网卡的实际地址；可以是本机也可以是其他机器127.0.0.1是loopback地址，是专门用于本机网络应用的实现，不依赖于实际的网卡(容器不能使用)。 11.1 概述 Pre description:分布式事务场景：后面出现异常，前面成功的远程服务（feign，RestTemplate，消息队列）无法回滚。因为它们的本地事务已经结束了。 两阶段提交协议。本地事务提交的结果上报给 TC。TCC模式， TCC 模式要求的三个接口？ Seata 由 3 部分组成： TC (Transaction Coordinator) - 事务协调者维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 快速开始部署 seata-server 1docker run --name seata-server -p 8091:8091 seataio/seata-server:latest 或者用 docker-compose 自定义配置启动 12345678910version: &quot;3&quot;services: seata-server: image: seataio/seata-server hostname: seata-server ports: - &quot;8091:8091&quot; environment: - SEATA_PORT=8091 - STORE_MODE=file 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt; 注意：如果不是 springcloud，则需要手动实现 xid（类似一串分布式事务的token） 跨服务传递。 YML 配置 1234567891011121314spring.cloud.alibaba.seata.tx-service-group=business-service # 事务组(必须)seata.service.vgroup-mapping.business-service=default # 事务组所在的 TC 集群名称(必须)seata.service.grouplist.default=127.0.0.1:8091 # 仅注册中心为 file 时使用 (seata.registry.type = file)seata.service.disable-global-transaction=false # 默认就是 false## if use registry center#seata.registry.type=nacos#seata.registry.nacos.cluster=default#seata.registry.nacos.server-addr=localhost### if use config center#seata.config.type=apollo#seata.config.apollo.apollo-meta=http://192.168.1.204:8801#seata.config.apollo.app-id=seata-server 创建 undo_log 表 是所有数据库都要创建吗？@EnableDiscoveryClient(autoRegister = false)？ 1234567891011121314-- 注意此处0.3.0+ 增加唯一索引 ux_undo_logCREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 到此完成，使用@GlobalTransactional(timeoutMills = 300000, name = &quot;spring-cloud-demo-tx&quot;)即可开启分布式事务。 配置说明 11.2 高可用部署 Seata 的高可用依赖于注册中心、配置中心和数据库来实现 store.mode 不使用默认的 file。建议使用高可用HA db/redis 存放事务数据。 Description: file模式为单机模式，全局事务会话信息内存中读写并持久化本地文件root.data，性能较高; 若使用db，则需要建3张表。全局事务会话信息由3块内容构成，全局事务–&gt;分支事务–&gt;全局锁，对应表global_table、branch_table、lock_table ，对应脚本 https://github.com/seata/seata/tree/develop/script/server/db 快速开始 使用注册中心 + db/redis a. 修改registry.conf的注册中心配置 123456789101112131415161718192021222324registry { type = &quot;nacos&quot; nacos { application = &quot;seata-server&quot; serverAddr = &quot;192.168.199.2&quot; # 容器内用hostname或者xxx（应该不能用localhost），在nacos启动日志看ip。 namespace = &quot;&quot; cluster = &quot;default&quot; username = &quot;nacos&quot; password = &quot;nacos&quot; }}config { type = &quot;nacos&quot; nacos { serverAddr = &quot;192.168.199.2&quot; namespace = &quot;&quot; group = &quot;SEATA_GROUP&quot; username = &quot;&quot; password = &quot;&quot; }} Location： b. 需要修改配置中心的以下几个配置(含db与redis,二者选其一 注:redis需seata-server 1.3版本及以上) 1234567891011121314151617service.vgroupMapping.my_test_tx_group=defaultstore.mode=db|redis-----db-----store.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=truestore.db.user=rootstore.db.password=123456----redis----store.redis.host=127.0.0.1store.redis.port=6379store.redis.maxConn=10store.redis.minConn=1store.redis.database=0store.redis.password=nullstore.redis.queryLimit=100 c. docker 启动 12345docker run --name seata-server \\ -p 8091:8091 \\ -e SEATA_CONFIG_NAME=file:/root/seata-config/registry \\ -v /User/seata/config:/root/seata-config \\ seataio/seata-server 11.3 集成 nacosseata-server 服务端配置 获取配置文件和 nacos-config.sh 初始化脚本文件：https://github.com/seata/seata/tree/develop/script/config-center 修改 conf/registry.conf 配置 注意：nacos的serverAddr不能有 http:// 前缀** 1234567891011121314151617181920registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; nacos { serverAddr = &quot;192.168.21.89&quot; namespace = &quot;&quot; cluster = &quot;default&quot; }}config { # file、nacos 、apollo、zk、consul、etcd3 type = &quot;nacos&quot; nacos { serverAddr = &quot;192.168.21.89&quot; namespace = &quot;&quot; cluster = &quot;default&quot; }} 修改conf/nacos-config.txt 配置 增加service.vgroup_mapping.${your-service-gruop}=default(本质上还是应用application.yml处读取)，其中${..}为服务组名称。例如，demo中有两个服务，分别是storage-service和order-service，所以配置如下： 1增加`service.vgroup_mapping.${your-service-gruop}=default`，其中${..}为服务组名称。例如，demo中有两个服务，分别是storage-service和order-service，所以配置如下 初始化seata的nacos配置 1sh ${SEATAPATH}/script/config-center/nacos/nacos-config.sh -h localhost -p 8848 -g SEATA_GROUP -t 5a3c7d6c-f497-4d68-a71a-2e5e3340b3ca -u username -w password 最后，启动seata-server 1docker run --name seata-server-complex -p 8091:8091 -e SEATA_CONFIG_NAME=file:/root/seata-config/registry -v C:\\Users\\Administrator\\Desktop\\seata-config\\config:/root/seata-config seataio/seata-server 1234567891011121314Parameter Description:-h: host, the default value is localhost.-p: port, the default value is 8848.-g: Configure grouping, the default value is 'SEATA_GROUP'.-t: Tenant information, corresponding to the namespace ID field of Nacos, the default value is ''.-u: username, nacos 1.2.0+ on permission control, the default value is ''.-w: password, nacos 1.2.0+ on permission control, the default value is ''. 客户端服务配置初始化undo_log表； 每个应用的resource里需要配置一个registry.conf ，demo中与seata-server里的配置相同(也可以在application.yml配置) application.yml 的各个配置项，注意spring.cloud.alibaba.seata.tx-service-group 是服务组名称，与nacos-config.txt 配置的service.vgroup_mapping.${your-service-gruop}具有对应关系 Other (for Tests):import static org.assertj.core.api.Assertions.assertThat;","link":"/2021/03/07/spring-cloud-alibaba/"},{"title":"分布式事务理论","text":"… 分布式事务理论 Seata、ShardingSphere 的分布式事务都是基于 XA、Base 。两/三阶段 XA 就不提了，只适用于短事务 &amp; 低并发的场景。ShardingSphere和Seata会对SQL进行重复解析。 背景数据库事务需要满足ACID（原子性、一致性、隔离性、持久性）四个特性。 原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。 一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。 隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability）指已提交的事务修改数据会被持久保存。 在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。 关系型数据库虽然对本地事务提供了完美的ACID原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是分布式事务的重点工作。 本地事务在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。 两阶段提交XA协议最早的分布式事务模型是由X/Open国际联盟提出的X/Open Distributed Transaction Processing（DTP）模型，简称XA协议。 基于XA协议实现的分布式事务对业务侵入很小。 它最大的优势就是对使用方透明，用户可以像使用本地事务一样使用基于XA协议的分布式事务。 XA协议能够严格保障事务ACID特性。 严格保障事务ACID特性是一把双刃剑。 事务执行在过程中需要将所需资源全部锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将导致对热点数据依赖的业务系统并发性能衰退明显。 因此，在高并发的性能至上场景中，基于XA协议的分布式事务并不是最佳选择。 柔性事务如果将实现了ACID的事务要素的事务称为刚性事务的话，那么基于BASE事务要素的事务则称为柔性事务。 BASE是基本可用、柔性状态和最终一致性这三个要素的缩写。 基本可用（Basically Available）保证分布式事务参与方不一定同时在线。 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉。 而最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性。 在ACID事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。通过放宽对强一致性要求，来换取系统吞吐量的提升。 基于ACID的强一致性事务和基于BASE的最终一致性事务都不是银弹，只有在最适合的场景中才能发挥它们的最大长处。 可通过下表详细对比它们之间的区别，以帮助开发者进行技术选型。 - 本地事务 两（三）阶段事务 柔性事务 业务改造 无 无 实现相关接口 一致性 不支持 支持 最终一致 隔离性 不支持 支持 业务方保证 并发性能 无影响 严重衰退 略微衰退 适合场景 业务方处理不一致 短事务 &amp; 低并发 长事务 &amp; 高并发 具体实现 Saga模式：Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 挑战由于应用的场景不同，需要开发者能够合理的在性能与功能之间权衡各种分布式事务。 强一致的事务与柔性事务的API和功能并不完全相同，在它们之间并不能做到自由的透明切换。在开发决策阶段，就不得不在强一致的事务和柔性事务之间抉择，使得设计和开发成本被大幅增加。 基于XA的强一致事务使用相对简单，但是无法很好的应对互联网的高并发或复杂系统的长事务场景；柔性事务则需要开发者对应用进行改造，接入成本非常高，并且需要开发者自行实现资源锁定和反向补偿。 目标整合现有的成熟事务方案，为本地事务、两阶段事务和柔性事务提供统一的分布式事务接口，并弥补当前方案的不足，提供一站式的分布式事务解决方案是ShardingSphere分布式事务模块的主要设计目标。","link":"/2021/03/24/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%90%86%E8%AE%BA/"},{"title":"","text":"缝缝补补终于差不多写完代码 凌晨4点多又熬夜啦！！ 洗洗睡觉 明天思考人生🤔","link":"/2021/02/25/%E5%8E%9F%E5%9C%B0%E7%9D%A1%E8%A7%89/"},{"title":"在m1-mac安装tensorflow","text":"… Installation Instructions 需要先安装arm64的miniforge替代暂未兼容的anaconda Step 1: Environment setupx86 : AMDCreate virtual environment (recommended): 123python3 -m venv ~/tensorflow-metalsource ~/tensorflow-metal/bin/activatepython -m pip install -U pip NOTE: python version 3.8 required arm64 : Apple SiliconDownload and install Conda env: 123chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.shsh ~/Downloads/Miniforge3-MacOSX-arm64.shsource ~/miniforge3/bin/activate Install the Tensorflow dependencies: 1conda install -c apple tensorflow-deps NOTE: python versions 3.8 and 3.9 supported Step 2: Install base TensorFlow1python -m pip install tensorflow-macos Step 3: Install tensorflow-metal plugin1python -m pip install tensorflow-metal 安装完成后，即可在python命令行中导入tensorflow模块。在PyCharm中新建项目如下，注意需要使用miniforge的python环境。 适配查询https://isapplesiliconready.com/zh/app/TensorFlow https://doesitarm.com/ 在M1上安装所有python的库1.下载安装miniforge3(arm64)https://github.com/conda-forge/miniforge/#download 2. 更改conda的mirror镜像源在terminal输入以下命令： 123456conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 修改condarc文件： 1234channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 之后你想要下载某些库就直接打开terminalconda install numpyconda install pandasconda install pyspark…..(速度比挂VPN快多了！ 各种模块都可以在此处找到：https://anaconda.org/ 3. conda 常用命令conda [env] -h：帮助 conda env list：列出所有conda环境 conda remove –name your_env_name –all：删除某个环境","link":"/2021/10/11/%E5%9C%A8m1-mac%E5%AE%89%E8%A3%85tensorflow/"},{"title":"快速部署","text":"… 该文章仅提供开发、测试环境的部分部署流程。另外，生产环境请参考其它文章。 1. Spring Cloud Alibaba1.1 Nacos使用docker-compose -f xxx.yml up命令，下面为相关文件，可根据自己的需要修改配置，如指定mysql、日志目录等。 xxx.yml 12345678910111213141516171819202122232425version: &quot;2&quot;services: nacos: image: nacos/nacos-server:1.3.1 container_name: nacos-standalone-mysql env_file: - ../env/nacos-standlone-mysql.env volumes: - ./standalone-logs/:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - &quot;8848:8848&quot; - &quot;9555:9555&quot; depends_on: - mysql restart: always mysql: container_name: mysql image: nacos/nacos-mysql:8.0.16 env_file: - ../env/mysql.env volumes: - ./mysql:/var/lib/mysql ports: - &quot;3306:3306&quot; nacos-standlone-mysql.env 12345678PREFER_HOST_MODE=hostnameMODE=standaloneSPRING_DATASOURCE_PLATFORM=mysqlMYSQL_SERVICE_HOST=mysqlMYSQL_SERVICE_DB_NAME=nacos_devtestMYSQL_SERVICE_PORT=3306MYSQL_SERVICE_USER=nacosMYSQL_SERVICE_PASSWORD=nacos mysql.env 1234MYSQL_ROOT_PASSWORD=rootMYSQL_DATABASE=nacos_devtestMYSQL_USER=nacosMYSQL_PASSWORD=nacos 1.2 seata1.3 rocketmqDocker 方式部署 生产环境使用集群部署：多Master多Slave-同步双写模式(docker-compose / Kubernetes)。同步双写类似于Mysql-Cluster，而异步双写类似于Mysql-Replications。 具体参照： https://github.com/apache/rocketmq-docker/blob/master/product/README.md https://github.com/apache/rocketmq-docker https://github.com/apache/rocketmq/blob/master/docs/cn/operation.md https://hub.docker.com/r/foxiswho/rocketmq 2. MySQL2.1 Cluster &amp; Replications 区别具体可参考这 2 篇文章：https://stackoverflow.com/questions/5300490/mysql-cluster-ndb-vs-mysql-replication-innodb-for-rails-3-apps-pros-conshttp://www.mysqlab.net/knowledge/kb/detail/topic/cluster/id/5184 功能主要有以下几点区别： Clust 实时同步 vs Rep异步同步。binlog 异步同步无法保证强一致性。 自动故障转移。MySQL Cluster 还使用同步复制以从系统中消除任何单点故障。 使用方便。应用不需要知道数据库在哪里（不用配置和处理 master/slave 等规则）。 2.2 集群搭建Docker 搭建 主要流程：管理节点–&gt;数据节点 &amp; MySQL服务器节点具体参照：https://hub.docker.com/r/mysql/mysql-cluster项目地址：https://github.com/mysql/mysql-docker.git 首先，我们创建一个内部Docker网络，容器将使用该网络进行通信 1docker network create cluster --subnet=192.168.0.0/16 然后我们启动管理节点 1docker run -d --net=cluster --name=management1 --ip=192.168.0.2 mysql/mysql-cluster ndb_mgmd 两个数据节点 12docker run -d --net=cluster --name=ndb1 --ip=192.168.0.3 mysql/mysql-cluster ndbddocker run -d --net=cluster --name=ndb2 --ip=192.168.0.4 mysql/mysql-cluster ndbd 最后是 MySQL 服务器节点。其中MYSQL_ROOT_HOST是宿主机的 localhost，与doceker inspect containerId 的 gateway ip 一致。 1docker run -d --net=cluster --name=mysql1 --ip=192.168.0.10 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_ROOT_HOST=192.168.0.1 mysql/mysql-cluster mysqld 总结 添加节点等等mysql-cluster.conf 123456789101112131415161718192021222324[ndbd default]NoOfReplicas=2DataMemory=80MIndexMemory=18M[ndb_mgmd]NodeId=1hostname=192.168.0.2datadir=/var/lib/mysql[ndbd]NodeId=2hostname=192.168.0.3datadir=/var/lib/mysql[ndbd]NodeId=3hostname=192.168.0.4datadir=/var/lib/mysql[mysqld]NodeId=4hostname=192.168.0.10 my.conf 1234567[mysqld]ndbclusterndb-connectstring=192.168.0.2user=mysql[mysql_cluster]ndb-connectstring=192.168.0.2 bin 文件搭建 具体参照：https://dev.mysql.com/doc/refman/8.0/en/mysql-cluster-install-linux-binary.html","link":"/2021/03/25/%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2/"},{"title":"好困好困！！！","text":"凌晨04:32 好困好困 折腾了好几天新小破网站终于有雏形了！！ 允许我偷懒今天少写点日记刷牙洗脸爬床了！ 茶茶哦呀粟米030 补充：凌晨5点多快六点了！茶茶为了可乐点了外卖哈哈啊哈！","link":"/2021/02/24/%E5%A5%BD%E5%9B%B0%E5%A5%BD%E5%9B%B0%EF%BC%81%EF%BC%81%EF%BC%81/"},{"title":"操作系统&amp;计算机网络&amp;算法","text":"… 1. 操作系统1.1 FAQ 虚拟内存：当物理内存不足时，把物理内存中少用的数据转储在虚拟内存的分页文件上。 2. 计算机网络2.1 FAQ在浏览器输入RUL后的过程 dns解析出ip地址 =&gt; 建立tcp连接 =&gt; 发送http请求 =&gt; 处理请求并返回http报文 Get 和 Post 的区别 从功能上来讲，Get请求的数据能够被缓存，所以浏览器倒退的时候不会像Post请求出现重复提交表单的情况。 从参数上来讲，Get的参数在URL可见，Post在Rquset Body可见；并且Get传递的参数大小有限制(url有长度限制)。 在HTTP协议中建议，Get用于查询请求，Post、Put、Delete用于数据修改。 HTTP请求，最初设定了八种方法。这八种方法本质上没有任何区别。只是让请求，更加有语义而已。 OPTIONS 返回服务器所支持的请求方法 GET 向服务器获取指定资源 HEAD 与GET一致，只不过响应体不返回，只返回响应头 POST 向服务器提交数据，数据放在请求体里 PUT 与POST相似，只是具有幂等特性，一般用于更新 DELETE 删除服务器指定资源 TRACE 回显服务器端收到的请求，测试的时候会用到这个 CONNECT 预留，暂无使用 Cookie 和 Session 的区别 Cookie是由服务端发送给客户端，并保存在客户端的数据。客户端再次请求的时候，会回发Cookie给服务端。(如登录选项的“请记住我”) Cookie的设置以及发送过程： –&gt; HTTP Request –&lt; HTTP Response + Set-Cookie(:JSESSIONID=xxxxx) –&gt; HTTP Request + Cookie(:JSESSIONID=xxxxx) –&lt; HTTP Response Session是保存在服务端上的信息。 Session相对Cookie更加安全，但是占用服务器资源。 HTTP 和 HTTPS 的区别 SSL(security Sockets Layer，安全套接层)：采用身份认证+数据加密保证网络通信的安全和数据的完整性，避免数据在网络中明文传输。 加密方式有对称加密和非对称加密，区别在于加密跟解密使用的是否是同一个密钥。此外还有哈希算法，数字签名等。 HTTP 明文传输，默认使用80端口(HTTPS默认使用443)。 HTTP请求报文的组成结构 请求方法 （method） 请求URL 协议(HTTP/HTTPS)及版本 报文头（header） 报文体（body） HTTP1.0 &amp; 1.1区别 HTTP(超文本传输协议)是一个应用层协议，是目前万维网数据通信的基础。 Connection:keep-alive/close,Host(multi machine tied common IP)。现在默认使用长连接了。 http2 &amp; http1.1 updated on 2021.11.2 Http2由国际互联网工程任务组于2015年发布。开发http2的主要目标是：提高页面加载速度；请求头压缩；二进制协议；服务端推送；TCP连接的多路复用。 TCP连接的多路复用：在1.0中，一个TCP连接会在一个HTTP请求后断开（TCP连接无法复用）。在1.1中，由于keep-alive机制的存在，在完成一个HTTP请求后该TCP连接不会立即断开，即连接可以复用（TCP连接单路复用）。在2.0中，可以在一个 TCP 连接中同时完成多个 HTTP 请求（TCP连接多路复用）。 此外，现在的dubbo、gRPC框架都是基于HTTP2的协议了。 **二进制协议：从文本协议转换为了二进制协议。HTTP1.x通过处理文本命令来完成请求-响应循环。HTTP/2则是使用二进制命令来执行相同的任务。二进制协议减轻了构造的复杂性，并简化了由于命令包含文本和可选空格而易被混淆的命令的实现。 浏览器如果使用了HTTP/2的实现，会将命令转化为二进制再进行传输。 http状态码 2.2 五层模型 e. 应用层(DNS SMTP FTP HTTP Telnet)d. 运输层(TCP UDP)c. 网络层(IP)(数据报) – 路由器b. 数据链路层a. 物理层 – 网卡 模型 功能 TCP/IP 协议族 应用层 各种服务和应用程序同通过该层利用网络 DNS SMTP FTP HTTP(应用于超文本传输) Telnet 运输层 进行数据传送 TCP UDP 网络层 选择路由，还负责建立和维护连接，控制网络拥塞 IP 数据链路层 将数据封装成帧 PPP 物理层 利用物理传输介质为数据链路层提供物理连接，以便透明传输比特流 2.3 TCP 和 UDPTCP(Transmission Control Protocol): 是一种面向连接的、可靠的、基于字节流的传输层通信协议。 UDP(User Datagram Protocol): 是一种无连接、不可靠(i.e 数据丢包 游戏掉线)的传输层协议。但UDP速度更快，适合视频聊天，游戏交互，在线聊天等场景。 2.4 TCP 的滑动窗口 TCP使用滑动窗口做流量控制与乱序重排。（即保证了TCP的可靠性）窗口内的数据包是按顺序ack的，当前面的某个包无法ack则会重试。保证了数据的完整性。 RTT(Round Trip Time)：发送一个数据包到响应ACK的时间。 Client 和 Server 的 sequence number 都是从 0 开始的： 滑动窗口：发送SYN（synchronous，同步信号，用于建立连接） + ACK（acknowledgement，确认信号） TCP 三次握手、四次挥手、长连接(TCP-KeepAlive)短连接： 四次挥手：FIN（结束信号，用于释放连接）、ACK;(没有直接发送FIN信号是因为服务端可能仍有数据需要传输给客户端) FIN、ACK 三次握手是因为server端第二次握手 ACK+SYN 几种拥塞控制方法： 慢开始( slow-start ) 拥塞避免( congestion avoidance ) 快重传( fast retransmit ) 快恢复( fast recovery ) 3. 算法和数据结构 参照 github project 时间复杂度(从大到小)： O(n!) &gt; O(2^n) &gt; O(n^2) &gt; O(nlogn) &gt; O(n) &gt; O(logn) O(n!) O(2^n) O(n^2) O(nlogn) O(n) O(logn) 二分查找(log2n) 3.1 白板编程单例模式,反转链表,二分查找,树的遍历… 3.2 常见排序算法 3.3 必备基础 各种排序算法 基础数据结构和算法的实现：如堆、二叉树、图… 基础数据结构的使用：如链表、栈、队列、哈希表、图、Trie、并查集… 基础算法：深度优先、广度优先、二分查找、递归… 基本算法思想：递归、分治、回溯搜索、贪心算法、动态规划… 二分查找O(logn) 最大公约数gcd：辗转相除法 最小公倍数lcm：两数相乘 / 最大公约数 O(logN) : n除xxx的操作等于1，1乘xxx的操作等于n。eg: 二分查找 递归算法的时间复杂度：递归的深度 depth 决定。 两次递归：O(2^n) 分治算法: O(nlogn) 二分查找：1234567891011121314151617public static int binarySearch(int[] nums, int length, int target) { int left = 0, right = length - 1; // 闭区间 while (left &lt;= right) { int mid = (left + right) / 2; if (target == nums[mid]) { return mid; } else if (target &lt; nums[mid]) { right = mid - 1; } else { left = mid + 1; } } return -1; }","link":"/2021/04/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%AE%97%E6%B3%95/"},{"title":"搭建轻量级 JavaWeb 框架","text":"这是一个基于mvc模式的轻量java web框架，实现了核心的IOC、AOP等功能。 0. 前置说明项目地址：https://github.com/cloris-cc/mini-mvc-framework 核心功能：IOC(Inversion of Control) &amp; AOP(Aspect Oriented Programming) IOC: 控制权由应用代码中转到了外部容器(即Bean容器)。即由框架(如Spring)来控制对象的生命周期和对象之间的关系，而非通过代码控制。IOC 功能通过依赖注入(Dependency Injection)实现。 AOP：封装通用逻辑为切面使用。实现技术为代理技术 核心技术：反射 &amp; 代理 反射：程序在运行状态(RUNTIME)中，能够获取、调用任意类的方法或属性的技术。 代理：隔离原对象，或为其增加功能。主要有 3 种代理的实现：静态代理、JDK动态代理、CGLib动态代理 AOP的应用场景： 性能监控、日志记录、权限控制、事务功能等 Bean的生命周期： 实例化（将Class实例化，即cls.newInstance()） 属性赋值（主要是给属性Bean赋值，通过反射实现） 初始化（在 DispatcherServlet 中初始化，继承自HttpServlet） 销毁 1. 基础框架搭建1.1 读取配置文件 注：properties是Map(继承了hashtable)，存储k-v结构数据。故只能用于properties文件，不适用于yml格式文件 下面演示了如何读取配置文件如application.properties的代码： 步骤：文件名 =&gt; InputStream (通过classLoader实现) =&gt; Properties 12345678// 转化文件为InputStreamInputStream is = Thread.currentThread() .getContextClassLoader() .getResourceAsStream(fileName); // fileName: application.yml// 加载InputStreamProperties props = new Properties();props.load(is); 1.2 开发 IOC 框架 将所有Bean放入一个容器中, 并实例化所有Bean 简述IOC实现步骤： 1. Bean context管理: 扫描获取指定包名下的所有 Bean（包括jar包里面class文件的Bean，这些Bean均由自定义注解如@Controller、@Service所修饰），并保存在Set集合中（保证Bean为单例） Bean 实例化: 实例化所有Bean（并初始化Controller的Service实例变量） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 1. 获取包名下的所有类public class URLTest { public static void main(String[] args) throws IOException, ClassNotFoundException { getClass(&quot;cn.teamwang.framework.test&quot;); } // 1. 获取包名下的所有类 public static Set&lt;Class&lt;?&gt;&gt; getClass(String packageName) throws IOException, ClassNotFoundException { Set&lt;Class&lt;?&gt;&gt; clsSet = new HashSet&lt;&gt;(); // 获取类加载器的另一种方式：Thread.currentThread().getContextClassLoader(); // getResources(String name) - name路径使用/分隔符 Enumeration&lt;URL&gt; urls = ClassLoader.getSystemClassLoader() .getResources(packageName.replace(&quot;.&quot;, &quot;/&quot;)); while (urls.hasMoreElements()) { URL url = urls.nextElement(); System.out.println(url.getProtocol()); // 1. protocol 为 file（即class文件） if (&quot;file&quot;.equals(url.getProtocol())) { // 过滤出名称以class结尾的文件 File[] files = new File(url.getPath()).listFiles(new FileFilter() { @Override public boolean accept(File file) { return file.getName().endsWith(&quot;class&quot;); } }); // 反射获取class（不初始化） if (null != files) { for (File file : files) { // eg: cn.teamwang.framework.test.Action，去掉后缀.class String name = packageName + &quot;.&quot; + file.getName().substring(0, file.getName().lastIndexOf(&quot;.&quot;)); System.out.println(name); // 不加载内部类 if (-1 == name.lastIndexOf(&quot;$&quot;)) { Class&lt;?&gt; cls = ClassLoader.getSystemClassLoader().loadClass(name); clsSet.add(cls); } } } } // 2. protocol 为 jar(压缩包，故里面也有文件路径) if (&quot;jar&quot;.equals(url.getProtocol())) { System.out.println(&quot;wait...&quot;); Enumeration&lt;JarEntry&gt; entries = ((JarURLConnection) url.openConnection()).getJarFile().entries(); while (entries.hasMoreElements()) { JarEntry jarEntry = entries.nextElement(); // jarEntry.getName(): cn/teamwang/framework/test/URLTest.class String name = jarEntry.getName().replace(&quot;/&quot;, &quot;.&quot;) .substring(0, jarEntry.getName().lastIndexOf(&quot;.&quot;)); Class&lt;?&gt; cls = ClassLoader.getSystemClassLoader().loadClass(name); clsSet.add(cls); } } } return clsSet; }} 123456789101112131415161718192021222324252627// 2. 再根据注解筛选出所有 Bean /** * 获取应用包名下所有 Service 类 */ public static Set&lt;Class&lt;?&gt;&gt; getServiceClassSet() { Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) { if (cls.isAnnotationPresent(Service.class)) { classSet.add(cls); } } return classSet; } /** * 获取应用包名下所有 Controller 类 */ public static Set&lt;Class&lt;?&gt;&gt; getControllerClassSet() { Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) { if (cls.isAnnotationPresent(Controller.class)) { classSet.add(cls); } } return classSet; } 12345678910111213141516171819202122// 3. 实例化后放进bean容器 &amp; 赋值 static { ClassHelper.getBeanClassSet().forEach(i -&gt; { BEAN_MAP.put(i, ReflectionUtil.newInstance(i)); }); } /* * 1. 遍历所有 Bean 实例 * 2. 遍历 Bean 的 Field，并给被 @Autowired 修饰的 Field 成员变量赋值 */ static { BeanHelper.getBeanMap().forEach((beanClass, beanInstance) -&gt; { for (Field field : beanClass.getDeclaredFields()) { if (field.isAnnotationPresent(Autowired.class)) { ReflectionUtil.setField(field.getType(), field, BeanHelper.getBean(field.getType())); } } }); } 1.3 额外内容迭代器 Iterator &amp; Enumeration 两者均可以遍历 Set 和 List 集合（Collections 容器）。虽然Enumeration效率更高，但是Iterator更安全。因为其他线程不能够修改正在被 iterator 遍历的集合里面的对象。 同时，Iterator 允许调用者删除底层集合里面的元素。(foreach和enumeration都无法删除) 另外，Map容器的迭代器为entrySet。 ClassLoader 常用方法 获取当前的ClassLoader也可以通过：ClassLoader.getSystemClassLoader() url.getProtocol(应用层协议)可以是 HTTP、HTTPS、FTP 和 File。 URL 解析： 协议为(protocol)： http **主机为(host:port)**：www.runoob.com 端口号为(port): 80 ，以上URL实例并未指定端口，因为 HTTP 协议默认的端口号为 80。 文件路径为(path)：/index.html **请求参数(query)**：language=cn 定位位置(fragment)： j2se，定位到网页中 id 属性为 j2se 的 HTML 元素位置 当为http时，URL为http://www.runoob.com/index.html?language=cn#j2se（其中http为 protocol） 当为file时，URL为file:/Users/jacky/IdeaProjects/jacky-framework/framework/target/classes/cn/teamwang/framework/test，下面同时给出获取该 path 下 class 文件的代码 File[] files = new File(url.getPath()).listFiles(); 1.4 Q &amp; AClassHelper获取Bean之后，再通过反射方式来获取实例对象。有了实例之后才能真正使用这个类对象。 @Controller修饰的类是单例吗？@Service修饰的类是单例吗？@Controller修饰的类的实例变量/成员变量也需要被初始化，说明这个类的@Service的实例变量会被初始化多次？ java中一个类实例化后，那么其中的成员变量要实例化吗？ 要，不实例化无法使用，但实例化始终只进行 1 次。类的成员属性在调用类的构造方法实例化对象的时候,如果你没有在构造方法中给这些属性赋值,这些属性都会被赋默认值,数值类型的赋值为 0, boolean 类型的赋值为 false, 引用类型赋值为 null。 Controller类中的被@Service修饰的实例变量，是已经被容器初始化过的，仅需给Controller类的实例变量赋值即可（赋值方式有2种：构造方法赋值、反射获取Controller类的field后再赋值，如使用@Mapper, @Service等注解） @RequestMapping 实现的关键：映射 Request 请求和 Handler 处理器的关系。 todo：代码示例，或者github连接 DispatcherServlet前置：Servlet是什么？一个处理网络请求和响应的接口而已。源码如下： 12345678910111213141516package javax.servlet; import java.io.IOException; public interface Servlet { void init(ServletConfig var1) throws ServletException; ServletConfig getServletConfig(); // 由service()方法决定调用doGet，doPost等方法。 void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException; String getServletInfo(); void destroy(); } Servlet 的生命周期 客户端请求该 Servlet 加载 Servlet类到内存 实例化并调用void init()方法初始化Servlet; 调用void service(req, res)方法 (根据请求方法不同调用 doget0或者 dopost0,此外还有 tohead()、 donut0、 dotrace0、 dodelete0、 dooptions(. destroy) 加载和实例化 Servlet。这项操作一般是动态执行的。然而, Server通常会提供一个管理的选项,用于在 Server启动时强制装载和初始化特定的 Servlet 其中一个Servlet的实现类——HttpServlet，其部分代码如下： 此外，常见的Servlet还有Spring实现的DispatcherServlet。 2. 使框架具备AOP特性 2.1 什么是代理 注意，当方法的参数类型为Object时，说明为实例；当为Class时，说明为xx.Class或instance.getClass() 通过实现代理类，来替代对原对象的使用。主要有2种用途：1.中介隔离作用，不能直接使用原对象；2.开闭原则，增加功能 代理技术主要有 3 种：静态代理、JDK动态代理、CGLib动态代理 静态代理 缺点：需要有接口类，并且需要重写每一个方法。通过实现接口方法的方式，故代理类所代理的方法均要@Override 123public interface Action { void eat(); } 123456public class ActionImpl implements Action{ @Override public void eat() { System.out.println(&quot;eat&quot;); } } 代理 ActionImpl 类: 12345678910111213141516171819202122public class ActionProxy implements Action{ private final Action action; public ActionProxy() { this.action = new ActionImpl(); } @Override public void eat() { this.sleep(); this.action.eat(); this.sleep(); } // @Override // 其它需要被代理的方法 public void sleep() { System.out.println(&quot;sleep&quot;); } } JDK 动态代理 缺点：被代理对象需要有接口类。 在方法调用(即动态，使用反射技术实现)时立刻生效，但只能代理有接口的实现类。通过实现JDK的InvocationHandler接口完成代理。 1234567891011public class TestMain { public static void main(String[] args) { // 被代理对象 Action target = new ActionImpl(); // 获取 proxy Action targetProxy = DynamicProxyHandler.getProxy(target); targetProxy.eat(); } } 1234567891011121314151617181920212223242526272829303132333435363738public class DynamicProxyHandler implements InvocationHandler { private final Object target; public DynamicProxyHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { before(); Object result = method.invoke(target, args); after(); return result; } /** * 获取代理类 * * @param target 代理对象实例 * @return 代理类 */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getProxy(T target) { return (T) Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new DynamicProxyHandler(target)); } private void before() { System.out.println(&quot;before&quot;); } private void after() { System.out.println(&quot;after&quot;); } } CGlib 动态代理 1. JDK代理是基于反射机制，CGLIB是基于继承机制。2. 原生JDK代理创建代理的速度更快，但创建后的代理运行速度更慢。CGLib相反，虽然初始化慢，但是运行速度更快，所以系统初始化的时候更适合用CGLib代理。 通过实现MethodInterceptor接口完成代理。 CGLib常用方法介绍： Enhancer.create(): 创建CGLib代理类 Method.intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable: 由用户自行实现的代理(或拦截)方法。返回结果为目标方法的返回值。 实现MethodInterceptor接口，重写其intercept()方法。其中MethodProxy参数是代理的关键。 123456789101112131415161718192021222324252627282930public class CGLibProxy implements MethodInterceptor { @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T getProxy(Class&lt;T&gt; target) { // this 的类型为 MethodInterceptor return (T) Enhancer.create(target, this); } @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T getProxy(Object target) { return (T) Enhancer.create(target.getClass(), this); } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { before(); Object result = methodProxy.invokeSuper(obj, args); after(); return result; } private void before() { System.out.println(&quot;before&quot;); } private void after() { System.out.println(&quot;after&quot;); } } 2.2 AOP 简介 AOP: Aspect-Oriented Programming，主要用于从业务逻辑中分离出来的横切逻辑，如性能监控、日志记录、权限控制等。实现AOP的技术主要有：代理*2、Spring AOP框架。 Spring AOP 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package cn.teamwang.aop.sample; import org.aopalliance.intercept.MethodInterceptor; import org.aopalliance.intercept.MethodInvocation; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.aop.AfterReturningAdvice; import org.springframework.aop.MethodBeforeAdvice; import org.springframework.aop.framework.ProxyFactory; import org.springframework.stereotype.Component; import java.lang.reflect.Method; /** * @author Jacky * Date: 2020/12/13 0:00 */ public class SpringAOP { static class BeforeAdvice implements MethodBeforeAdvice { @Override public void before(Method method, Object[] objects, Object o) throws Throwable { System.out.println(&quot;起床&quot;); } } static class AfterAdvice implements AfterReturningAdvice { @Override public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable { System.out.println(&quot;睡觉&quot;); } } /** * Around = Before + After */ static class AroundAdvice implements MethodInterceptor { @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable { // before(); System.out.println(&quot;起床&quot;); Object result = methodInvocation.proceed(); // after(); System.out.println(&quot;睡觉&quot;); return result; } } public static void main(String[] args) { ProxyFactory factory = new ProxyFactory(); factory.setTarget(new ActionImpl()); factory.addAdvice(new SpringAOP.BeforeAdvice()); factory.addAdvice(new SpringAOP.AfterAdvice()); Action action = (Action) factory.getProxy(); action.eat(); } /* * 结合 AspectJ（maven: Spring-boot-starter-aop） * 顺序：around &gt; before &gt; around &gt; after &gt; afterReturning */ // todo 内部类使用@Autowired有效吗？无效。这里仅作展示用。 @Component @Aspect class AspectSample { /** * execution()方法：执行目标 * 第一个*：所有类型返回值 * 第二个*：所有方法 * (..): 任意参数 */ @Around(&quot;execution(* cn.teamwang.aop.sample.ActionImpl.*(..))&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable { // before(); // proceed(): 让目标方法执行 Object methodResult = joinPoint.proceed(); // after(); return methodResult; } @Before(&quot;@annotation(cn.teamwang.aop.sample.Tag)&quot;) public void before() { } } } 2.3 开发 AOP 框架主要流程 流程/思路整理(主要使用CGLib动态代理技术)： 实现切面代理类AspectProxy 获取代理类实例 将代理类实例放入Bean容器覆盖目标类实例，即可生效 在开始之前，先模仿CGLib的MethodInterceptor接口，设计一个能循环执行多次代理（即执行多次intercept()方法）的接口。 123public interface MethodInterceptor extends Callback { Object intercept(Object var1, Method var2, Object[] var3, MethodProxy var4) throws Throwable;} 123456789101112/** * @author Jacky * Date: 2020/12/13 2:16 */public interface ProxyInterceptor { /** * 由用户来实现的切面方法。 * &lt;p&gt; * 按顺序执行链式代理 */ Object intercept(ProxyChain proxyChain) throws Throwable;} 为了能多次调用intercepte()方法，ProxyChain 除了封装了原有的obj，method，args，MethodProxy参数外，另外增加了List&lt;ProxyInterceptor&gt;参数。并在invoke方法内实现了多次调用intercept()方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @author Jacky * Date: 2020/12/13 2:23 */public class ProxyChain { // target: class, obj, method, args... // proxy: proxyList, methodProxy... private final Class&lt;?&gt; targetClass; private final Object targetObject; private final Method targetMethod; private final MethodProxy methodProxy; private final Object[] methodParams; private final List&lt;ProxyInterceptor&gt; proxyInterceptorList; private int proxyIndex = 0; public ProxyChain(Class&lt;?&gt; targetClass, Object targetObject, Method targetMethod, MethodProxy methodProxy, Object[] methodParams, List&lt;ProxyInterceptor&gt; proxyList) { this.targetClass = targetClass; this.targetObject = targetObject; this.targetMethod = targetMethod; this.methodProxy = methodProxy; this.methodParams = methodParams; this.proxyInterceptorList = proxyList; } public Class&lt;?&gt; getTargetClass() { return targetClass; } public Method getTargetMethod() { return targetMethod; } public Object[] getMethodParams() { return methodParams; } public Object invoke() throws Throwable { Object methodResult; if (proxyIndex &lt; proxyInterceptorList.size()) { methodResult = proxyInterceptorList.get(proxyIndex++).intercept(this); } else { // 执行完用户实现的所有 intercept() 后，最终调用目标对象的业务逻辑方法。 methodResult = methodProxy.invokeSuper(targetObject, methodParams); } return methodResult; }} Step 1. 实现切面代理类 AspectProxy1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @author Jacky * Date: 2020/12/14 2:10 */public abstract class AspectProxy implements ProxyInterceptor { public static final Logger LOGGER = LoggerFactory.getLogger(AspectProxy.class); @Override public Object intercept(ProxyChain proxyChain) throws Throwable { Object result; Class&lt;?&gt; cls = proxyChain.getTargetClass(); Method method = proxyChain.getTargetMethod(); Object[] args = proxyChain.getMethodParams(); begin(); try { if (validate()) { before(cls, method, args); result = proxyChain.invoke(); after(cls, method, args, result); } else { result = proxyChain.invoke(); } } catch (Exception e) { LOGGER.error(&quot;proxy failure: &quot;, e); error(cls, method, args, e); throw e; } finally { end(); } return result; } public boolean validate() { return true; } public void begin() { } public void before(Class&lt;?&gt; cls, Method method, Object[] args) { } public void after(Class&lt;?&gt; cls, Method method, Object[] args, Object result) throws Throwable { } public void error(Class&lt;?&gt; cls, Method method, Object[] args, Throwable e) { } public void end() { }} Step 2. 获取代理类实例123456789public static &lt;T&gt; T getProxy(final Class&lt;?&gt; targetClass, final List&lt;ProxyInterceptor&gt; proxyInterceptorList) { return (T) Enhancer.create(targetClass, new MethodInterceptor() { @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { return new ProxyChain(targetClass, obj, method, methodProxy, args, proxyInterceptorList) .invoke(); } });} Step 3. 将代理类实例放入Bean容器覆盖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 处理 目标类、切面类 &amp; 创建代理类实例 的关系。 * 最终以代理类实例覆盖IOC容器中的目标类实例。（另外，该类的初始化时间应在IOC容器初始化之后，才能实现覆盖） * * @author Jacky * Date: 2020/12/14 4:08 */public class AOPHelper { private static final Logger LOGGER = LoggerFactory.getLogger(AOPHelper.class); static { try { Map&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; proxyMap = createProxyMap(); // 目标类：代理 Map&lt;Class&lt;?&gt;, List&lt;ProxyInterceptor&gt;&gt; targetMap = createTargetMap(proxyMap); for (Map.Entry&lt;Class&lt;?&gt;, List&lt;ProxyInterceptor&gt;&gt; targetEntry : targetMap.entrySet()) { Class&lt;?&gt; targetClass = targetEntry.getKey(); List&lt;ProxyInterceptor&gt; proxyList = targetEntry.getValue(); // 创建代理类实例 Object proxyInstance = ProxyUtil.getProxy(targetClass, proxyList); // 替换IOC容器中targetClass的实例为代理类实例 BeanHelper.setBean(targetClass, proxyInstance); } } catch (Exception e) { LOGGER.error(&quot;aop failure&quot;, e); } } /** * (一个)切面代理类 : (多个)目标类 * 例如：ControllerAspect切面代理类 和 所有的(value=)Controller目标类 */ private static Map&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; createProxyMap() { // 代理类和(多个)目标类的映射集合 Map&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; proxyMap = new HashMap&lt;&gt;(); // proxySet: 获取所有继承了AspectProxy的切面类（即 AspectProxy 的子类） Set&lt;Class&lt;?&gt;&gt; proxySet = ClassHelper.getClassSetBySuper(AspectProxy.class); // 获取目标类 for (Class&lt;?&gt; proxyClass : proxySet) { if (proxyClass.isAnnotationPresent(Aspect.class)) { // 获取 @Aspect 注解中的 value，再获取被 value 修饰的所有类。 // 以 ControllerAspect 为例，目标类就是 @Aspect(Controller.class) 的 value proxyMap.put(proxyClass, ClassHelper.getClassSetByAnnotation(proxyClass.getAnnotation(Aspect.class).value())); } } addTransactionProxy(proxyMap); return proxyMap; } /** * 因为创建代理类实例需要targetClass，proxyInterceptorList参数，所以需要在proxyMap的基础上建立新的映射关系。 */ private static Map&lt;Class&lt;?&gt;, List&lt;ProxyInterceptor&gt;&gt; createTargetMap(Map&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; proxyMap) throws Exception { Map&lt;Class&lt;?&gt;, List&lt;ProxyInterceptor&gt;&gt; targetMap = new HashMap&lt;&gt;(); for (Map.Entry&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; proxyEntry : proxyMap.entrySet()) { // 代理类 Class&lt;?&gt; proxyClass = proxyEntry.getKey(); // n 个目标类 Set&lt;Class&lt;?&gt;&gt; targetClassSet = proxyEntry.getValue(); for (Class&lt;?&gt; targetCls : targetClassSet) { // 创建代理实例 ProxyInterceptor proxyInterceptor = (ProxyInterceptor) proxyClass.newInstance(); if (targetMap.containsKey(targetCls)) { targetMap.get(targetCls).add(proxyInterceptor); } else { List&lt;ProxyInterceptor&gt; temp = new ArrayList&lt;&gt;(); temp.add(proxyInterceptor); targetMap.put(targetCls, temp); } } } return targetMap; } private static void addTransactionProxy(Map&lt;Class&lt;?&gt;, Set&lt;Class&lt;?&gt;&gt;&gt; proxyMap) { Set&lt;Class&lt;?&gt;&gt; serviceClassSet = ClassHelper.getClassSetByAnnotation(Service.class); proxyMap.put(TransactionProxy.class, serviceClassSet); }} 2.4 ThreadLocal ThreadLocal (JDK1.2): 一个用来存放线程的 map 容器。用于解决多线程并发问题。 ThreadLocal的核心机制 每个Thread线程内部都有一个Map。 Map里面存储线程本地对象（key）和线程的变量副本（value） 但是，Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。 ThreadLocal的代码实现 在实现之前，先说明下HashMap是线程不安全的，需用ConcurrentHashMap/Collections.synchronizedMap/Hashtable(按性能排序)。 性能差异是由于HashTable直接用synchronized修饰方法；Collections.synchronizedMap用synchronized修饰代码块；ConcurrentHashMap使用分段锁 (jdk1.7及更早)/CAS。 HashMap的线程不安全主要体现在下面两个方面：1.在JDK1.7中，当并发执行扩容操作时会造成环形链和数据丢失的情况。2.在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。 下面是山寨版ThreadLocal的代码： 12345678910111213141516171819202122232425262728293031public class MyThreadLocal&lt;T&gt; { // 存放线程的map容器 private final Map&lt;Thread, T&gt; threadLocalMap = Collections.synchronizedMap(new HashMap&lt;&gt;()); public void set(T value) { // 修改当前的线程Map threadLocalMap.put(Thread.currentThread(), value); } public T get() { T value = threadLocalMap.get(Thread.currentThread()); if (value == null) { value = initialValue(); } return value; } /** * 由子类实现 */ protected T initialValue() { return null; } public void remove() { threadLocalMap.remove(Thread.currentThread()); }} 应用场景： 数据隔离 方便获取数据，避免方法不断传参（如userId，token等等） 2.5 实现事务功能该节主要包括：事务的特性(ACID)、隔离级别、传播行为(Spring) 这里仅介绍7种传播行为的一种，也是Spring框架默认的事务传播行为。 假设：方法A传播到有事务的方法B（其实就是A\b被B调用了），方法A有事务吗？ 如果没有，就新建一个事务；如果有，就加入当前(B的)事务。这就是Spring默认的事务传播行为——PROPAGATION_REQUIRED 6 种事务传播行为 支持当前事务(当前存在事务，则加入该事务；如果没有则如下：) TransactionDefinition.PROPAGATION_REQUIRED: 创建一个新事务。 supports：以非事务的方式继续运行。 mandatory：抛出异常。 不支持当前事务 requires_new: 创建一个新事务，挂起当前事务（若有）。 not_supported: 以非事务方式运行，挂起当前事务（若有） never: 以非事务方式运行，抛出异常（若有） 实现@Transaction功能 1234567891011121314151617181920212223242526272829303132333435363738public class TransactionProxy implements ProxyInterceptor { public static final Logger LOGGER = LoggerFactory.getLogger(TransactionProxy.class); public static final ThreadLocal&lt;Boolean&gt; FLAG_HOLDER = new ThreadLocal&lt;Boolean&gt;(){ @Override protected Boolean initialValue() { return false; } }; @Override public Object intercept(ProxyChain proxyChain) throws Throwable { Object result; boolean flag = FLAG_HOLDER.get(); Method method = proxyChain.getTargetMethod(); if (!flag &amp;&amp; method.isAnnotationPresent(Transaction.class)) { FLAG_HOLDER.set(true); try { DatabaseHelper.beginTransaction(); LOGGER.debug(&quot;begin transaction&quot;); result = proxyChain.invoke(); DatabaseHelper.commitTransaction(); LOGGER.debug(&quot;commit transaction&quot;); } catch (Exception e) { DatabaseHelper.rollbackTransaction(); LOGGER.debug(&quot;rollback transaction&quot;); throw e; } finally { FLAG_HOLDER.remove(); } } else { result = proxyChain.invoke(); } return result; }} 最后，在AOPHelper中处理代理类(TransactionProxy)和目标类(所有Service)的关系即可。 4. 优化和拓展4.1 获取ServletAPI获取Servlet API，即获取HttpServletRequest和Response对象。与BaseHandler一样，用拦截(Intercepter/DispacherServlet)的方法实现。 在DispatcherServlet的service方法把req和res参数放进ThreadLocal中。 5. 发布到maven仓库4.1 github package相关介绍： https://docs.github.com/cn/free-pro-team@latest/packages/guides/configuring-apache-maven-for-use-with-github-packages 若只想让个人或协作者访问，则使用私有仓库。另外，即便是只使用（即安装jar依赖），也需要配置github-token；maven deploy时需要配置POM的distributionManagement来指定Maven分发构件的位置 4.2 maven(略)4.3 jitpack网站：https://jitpack.io/ 直接releases版本号即可，然后修改pom.xml文件： 123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jitpack.io&lt;/id&gt; &lt;url&gt;https://jitpack.io&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 12345&lt;dependency&gt; &lt;groupId&gt;com.github.cloris-cc&lt;/groupId&gt; &lt;artifactId&gt;public-package&lt;/artifactId&gt; &lt;version&gt;Tag&lt;/version&gt;&lt;/dependency&gt;","link":"/2021/02/25/%E6%90%AD%E5%BB%BA%E8%BD%BB%E9%87%8F%E7%BA%A7java-web-MVC-%E6%A1%86%E6%9E%B6/"},{"title":"设计模式","text":"涵盖了开发中的各种设计模式… https://www.runoob.com/design-pattern/design-pattern-tutorial.html 1. 设计模式分类1.1 创建型模式工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 1.2 结构型模式适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 1.3 行为型模式策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 2. 设计模式的六大原则2.1 具体内容 总结：隔离 + 易扩展（通过 多接口组合；代理；） 高层组件可以调用控制底层组件，而低层组件不允许直接调用高层组件。比如 hock, web 分层… 六大原则 具体内容 开闭原则 对扩展开放，对修改关闭。(如代理) 里氏代换原则 任何基类可以出现的地方，子类一定可以出现。 依赖倒转原则 针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则 使用多个隔离的接口，比使用单个接口要好。 迪米特法则 / 最少知识原则 一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。(只和你的密友谈话。) 合成复用原则 尽量使用组合，而不是继承。 2.2 设计模式的解释 模式 描述 装饰者 包装一个对象，以提供新的行为。 状态 封装了基于状态的行为，并使用委托来决定要使用哪一个。 迭代器 在对象的集合中游走，而不暴露集合的实现。 外观 简化一群内的接口。 策略 封装可以互换的行为，并使用委托来决定要使用哪一个。 代理 包装对象，以控制对此对象的访问。 工厂方法 由子类决定要创建的具体类是哪一个。 抽象工厂 允许客户创建对象的家族，而无需指定他们的具体类。 观察者 让对象能够在状态改变时被通知。 模板方法 由子类决定如何实现一个算法中的步骤。 组合 客户用一致的方式处理对象集合和单个对象。 单件 确保有且只有一个对象被创建。 适配器 封装对象，并提供不同的接口。 命令 封装请求成为对象。 3. 观察者模式 一对多关系。当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 3.1 定义多个观察者(消费者) 订阅 某个主题对象(1*n关系)，当这个对象状态改变时，它的所有观察者都会收到通知并自动更新。主题是真正拥有数据的人，在数据变化时更新，这样比让多个对象控制同一份数据(repeat)来，可以得到更干净的OO设计。 3.2 设计原则松耦合。即对象之间的依赖性降低。 3.3 代码示例1234567891011// 主题接口public interface Subject { // 注册观察者(观察者的订阅行为)。 public void registerObserver(Observer o); // 移除观察者(观察者的退订行为)。 public void removeObserver(Observer o); // 当主题状态改变时，此方法会被调用，以通知所有的观察者对象。（发报纸） public void notifyObservers();} 12345// 观察者接口public interface Observer { // 当主题状态改变时，注意会把这些数据(参数)告知(传送)给观察者。 public void update(float temp, float humidity, float pressure);} 3.4 注意Observable 是一个类，而不是一个接口。且违反了组合复用原则。 因为java不支持类的多继承，限制了Observable的复用能力，无法让继承它的对象做更多的事情，反而可以通过实现多个接口来实现更多特性。 有多个观察者时，不可以依赖特定的通知次序。 3.5 部分源码1234567891011121314151617181920212223242526public class Observable { private boolean changed = false; private Vector&lt;Observer&gt; obs; /** Construct an Observable with zero Observers. */ public Observable() { obs = new Vector&lt;&gt;(); } /** * Adds an observer to the set of observers for this object, provided * that it is not the same as some observer already in the set. * The order in which notifications will be delivered to multiple * observers is not specified. See the class comment. * * @param o an observer to be added. * @throws NullPointerException if the parameter o is null. */ public synchronized void addObserver(Observer o) { if (o == null) throw new NullPointerException(); if (!obs.contains(o)) { obs.addElement(o); } } 3.6 使用场景MVC 模式、Swing 编程、JavaBeans、RMI. 4. 装饰者模式 在不修改子类的情况下修改类型、增加功能。 例如，饮料包括了红茶、绿茶、白咖啡、拿铁等等，然后这些饮料又有许多配料(如糖、冰块、牛奶等)。所以可将这些配料(装饰)提取为一个抽象(装饰)类再让子类去实现。本质上就是利用了Java的三大特性。 4.1 定义动态地将行为附加到对象上。通常采用抽象类，继承抽象类(成为装饰器)**，是为了有正确的类型，而不是行为。行为来自装饰者和基础组件，或与其他装饰者的组合关系。装饰者模式是继承的最佳使用方法。** 装饰者的责任：动态增加行为到被包装的对象上，就不用去修改对象的代码了。 4.2 设计原则组合复用原则、开闭原则(对扩展开放，对修改关闭)。 4.3 代码示例123456789public abstract class Beverage { String description = &quot;Unknow Beverage&quot;; public String getDescription() { return description; } // 在子类实现抽象方法 public abstract double cost();} 1234567891011// 浓缩咖啡public class BlackCoffee extends Beverage { public BlackCoffee() { description = &quot;BlackCoffee-黑咖啡&quot;; } @Override public double cost() { return 1.99; }} 12345678910public class WhiteCoffee extends Beverage { public WhiteCoffee() { description = &quot;WhiteCoffee-白咖啡&quot;; } @Override public double cost() { return .89; }} 1234public abstract class CondimentDecorator extends Beverage { // 所有的装饰者都必须实现此抽象方法。 public abstract String getDescription();} 1234567891011121314151617public class Mocha extends CondimentDecorator { Beverage beverage; public Mocha(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + &quot;, Mocha&quot;; } @Override public double cost() { return .2 + beverage.cost(); }} 123456789101112131415161718public class Sugar extends CondimentDecorator { Beverage beverage; public Sugar(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + &quot;, Sugar&quot;; } @Override public double cost() { return .1 + beverage.cost(); }} 123456789101112131415161718public class Soy extends CondimentDecorator { Beverage beverage; public Soy(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + &quot;, Soy&quot;; } @Override public double cost() { return 0.3 + beverage.cost(); }} 123456789101112131415161718public class StarbuzzCoffeeApplication { public static void main(String[] args) { // 加糖的白咖啡 Beverage whiteCoffee = new WhiteCoffee(); whiteCoffee = new Sugar(whiteCoffee); System.out.println(&quot;请享用：&quot; + whiteCoffee.getDescription()); System.out.println(&quot;价格为：&quot; + whiteCoffee.cost()); // 加糖、加黄豆的黑咖啡 Beverage blackCoffee = new BlackCoffee(); blackCoffee = new Sugar(blackCoffee); blackCoffee = new Soy(blackCoffee); System.out.println(&quot;请享用：&quot; + whiteCoffee.getDescription()); System.out.println(&quot;价格为：&quot; + whiteCoffee.cost()); }} 4.4 使用场景Java中的I/O: FilterInputStream是一个抽象的装饰类。BufferedInputStream和LineNumberInputStream是具体的装饰者。基类是InputStream. 下面以 BufferedInputStream 为例： 12345678// 使用装饰器(还是通过继承)public class BufferedInputStream extends FilterInputStream {..}// 继承抽象类，成为装饰器public class FilterInputStream extends InputStream {..}public abstract class InputStream implements Closeable {..} 5 工厂模式 作为一种创建类模式，在任何需要生成复杂对象(对象种类繁多、创建流程复杂)的地方，都可以使用工厂方法模式。如日志工厂(LoggerFactory)、数据库驱动工厂(JDBCFactory)等。 5.1 定义将创建对象的代码集中在一个对象或方法中，可以避免代码的重复，更加方便维护。意味着在实例化对象时，只会依赖接口，而不是具体类。 抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 抽象工厂使用对象组合。 工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类时哪一个。工厂方法让类把实例化推迟到子类。 工厂方法使用继承。 5.2 设计原则依赖倒置原则：要依赖抽象，不要依赖具体类。 6. 单例模式 单例和static方法的区别： 首先，单例是面向对象而言的；而static是面向具体方法的，在工具类上就能表现出来 static方法效率更好 单例因为只有一处可以获取实例，可以防止实例被修改；而static方法所在的类无法保证。 7 命令模式7.1 定义1）把方法调用的行为(或称请求)封装成一个对象。区别于对象的封装。 2）将请求封装成对象。这可以让你使用不同的请求、队列，或者日志请求来参数化其他对象。命令模式也可以支持撤销操作。 7.2 使用场景工作队列、线程池、日志请求。 8. 适配器模式8.1 定义及作用适配器作用：将一个接口转换成另一个接口，让原本接口不兼容的类可以合作无间。不做适配器只能去该接口的代码了。 8.2 外观模式12345678public float getTemp() { Thermometer thermometer = station.getThermometer(); return thermometer.getTemperature();}// 遵循最少知识原则public float getTemp() { return station.getTemperature();} 9 模版方法模式9.1 定义及示例抽象化算法为模板，由子类负责全部或部分实现。 模板方法模式——在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。 12345678910111213141516171819abstract class AbstractClass { // 这是一个模版方法。final表示不允许被子类重写。 final void templateMethod() { primitiveOperation1(); primitiveOperation2(); concreteOperation(); hook(); } // 这些方法可能有区别，所以由具体的子类实现。 abstract void primitiveOperation1(); abstract void primitiveOperation2(); void concreteOperation() { // 这里是实现... } // 注意，这是一个具体的 Hock 方法，但是它什么都不做！ // 因为一个方法，不是父类实现就是子类实现，总之一定要实现。 void hock() {}} 9.2 对模板方法挂钩12345678910111213141516171819202122public abstract class CaffeineBeverageWithHock { // template method. void prepareRecipe() { boilWater(); brew(); pourInCup(); if (customerWantsCondiments()) { addCondiments(); } } abstract void brew(); abstract void addCondiments(); void boilWater() { System.out.println(&quot;Boiling water...&quot;); } void pourInCup() { System.out.println(&quot;Pouring into cup...&quot;); } // Hook Method. SubClass can override this method. boolean customerWantsCondiments();} 10 代理模式11. 其它模式状态模式：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 桥接模式：使用桥接模式，不只改变你的实现，也改变你的抽象。 生成器模式：使用生成器模式封装一个产品的构造过程，并允许按步骤构造。 责任链模式：让多个对象处理某个请求。应用场景：请求 –&gt; A-Handler –&gt; B-Handler –&gt; C-Handler –&gt; New-Handler 蝇量模式：让某个类的一个实例提供多个“虚拟实例”。如List, Set… 解释器模式 中介者模式：使用中介者对象来集中管理多个对象间复杂的沟通和控制方式。 备忘录模式：备份。在java中，可以使用序列化机制存储系统的状态。 原型模式：clone 原型","link":"/2021/03/05/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"迈向高级Java的面试突围课","text":"… 3. 项目业务问题重复支付什么是重复支付？由于支付系统是异步处理任务的。所以可能存在该情况：当用户支付完成后，(可能由于网络波动等)本地服务器没有立即接收到支付系统的回调通知，而无法及时更新订单信息，而此时用户可能误操作重新发起支付？。/ 短时间2两次或多次支付成功的回调通知，即并发请求。 超时取消订单回滚失败如何处理？重试机制；分布式事务； 二阶段TPC提交：https://en.wikipedia.org/wiki/Two-phase_commit_protocol 通用jvm工具jps：虚拟机进程状态工具。eg: jps -v | grep pid jinfo：jvm参数信息工具。eg: info -flags pid jstate：查看虚拟机各种运算状态。eg: stat -gcutil pid jstack：线程快照工具。eg: stack -l pid jmap：HeapDump工具。eg:1.jmap -heap pid 查看堆信息2.jmap -dump：format=b，file=heapDump.hprof pid 导出堆文件并用 jhat 查看3.jhat -port 8899 heapDump.hprof java排查问题工具：visualvm, jprofiler(付费) todo 多线程的应用场景？和相关代码实例 池化策略：连接池中的空闲线程。IO密集型2n，计算密集型n+1，其中n为服务器cpu的核数。 4. 优化数据库性能4.1 单机数据库常见方法有：查询优化、批量写(batch insert)、索引优化、innodb相关优化。 6. 微服务和架构认知6.1 如何阅读源码必要前提：先会用框架+看官方文档 架构图 =&gt; 启动流程 =&gt; 最后再看执行方法 Test测试用例或框架源码，使用Assert.notNull()等方法来替代System.out.println() 6.2 SpringApplicationSpringApplication为springboot的入口类。 12345678910public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); this.bootstrapRegistryInitializers = getBootstrapRegistryInitializersFromSpringFactories(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();} 6.3 spring.factories 文件的作用在阅读 Spring-Boot 相关源码时，常常见到 spring.factories 文件，里面写了自动配置（AutoConfiguration）相关的类名，因此产生了一个疑问：“明明自动配置的类已经打上了 @Configuration 的注解，为什么还要写 spring.factories 文件？ 用过 Spring Boot 的都知道 @ComponentScan 注解的作用是扫描 @SpringBootApplication 所在的 Application 类所在的包（basepackage）下所有的 @component 注解（或拓展了 @component 的注解）标记的 bean，并注册到 spring 容器中。 那么问题来了 在 Spring Boot 项目中，如果你想要被 Spring 容器管理的 bean 不在 Spring Boot 包扫描路径下，怎么办？ 解决 Spring Boot 中不能被默认路径扫描的配置类的方式，有 2 种： （1）在 Spring Boot 主类上使用 @Import 注解（2）使用 spring.factories 文件 123456789101112131415161718192021222324252627282930313233343536private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(ClassLoader classLoader) { Map&lt;String, List&lt;String&gt;&gt; result = cache.get(classLoader); if (result != null) { return result; } result = new HashMap&lt;&gt;(); try { // FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); while (urls.hasMoreElements()) { URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) { String factoryTypeName = ((String) entry.getKey()).trim(); String[] factoryImplementationNames = StringUtils.commaDelimitedListToStringArray((String) entry.getValue()); for (String factoryImplementationName : factoryImplementationNames) { result.computeIfAbsent(factoryTypeName, key -&gt; new ArrayList&lt;&gt;()) .add(factoryImplementationName.trim()); } } } // Replace all lists with unmodifiable lists containing unique elements result.replaceAll((factoryType, implementations) -&gt; implementations.stream().distinct() .collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList))); cache.put(classLoader, result); } catch (IOException ex) { throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); } return result;} 而Spring这种机制类似于JavaSPI接口。 Java中例如服务发现、web服务器(tomcat, netty, luccent)、数据库连接池(jdbc,hirika..)、日志模块、消息队列等等都有许多不同的实现。而SPI就提供了这种机制：为某个接口寻找服务实现的机制。 Spring也有类似的JavaSPI机制。它有许多jar包在 resources/META-INF/spring.factories 文件配置了接口的实现类名称，然后在程序中读取这些配置文件(在classpath下能读取到)并实例化。 以 spring-boot-autoconfigure 包为例进行介绍，其spring.factories代码如下： 1234567891011121314151617181920212223242526272829# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Environment Post Processorsorg.springframework.boot.env.EnvironmentPostProcessor=\\org.springframework.boot.autoconfigure.integration.IntegrationPropertiesEnvironmentPostProcessor# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\... 6.4 DubboRPC原理 RPC(Remote Procedure Call，远程过程调用) 线程模型 IO线程池、业务工作线程池、Boss线程池 微服务配置知识常见的配置有哪些？ Timeout 超时时间、Retries失败重试(一般关闭，否则可能造成幂等性问题)、LoadBalance负载均衡(轮询，随机，最少活跃调用，一致性hash)。 服务发布有依赖怎么办？ 默认check=”true”，可以通过check=”false”关闭检查。 序列化方式 hessian(默认，二进制), fastjson/Jackson, jok, protobuf(推荐，二进制), protostuf 为什么 PB 的效率是最高的？ 可能有一些同学比较习惯于 JSON or XML 数据存储格式，对于 Protocol Buffer 还比较陌生。Protocol Buffer 其实是 Google 出品的一种轻量并且高效的结构化数据存储格式，性能比 JSON、XML 要高很多。REST传输JSON虽然方便但性能更低。 其实 PB 之所以性能如此好，主要得益于两个：第一，它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍；第二，它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。 所以，如果Dubbo满足业务场景的话，使用Dubbo相对Feign这种传输JSON数据的RPC框架(但非RPC协议，而是REST协议)而言，性能会更好。而目前Feign(SpringCloud)的微服务组件更加全面。 RPC服务的降级 远程服务出现问题则返回null 服务暴露的过程 todo Dubbo的服务注册、发现、调用是如何实现的？SPI？…Dubbo快速启动！ 服务发现及调用的过程略 6.5 如何解决微服务异常问题限流方式：接口限流、总限流。 熔断7 Other7.1 跨站点攻击XSS跨站点js脚本攻击XSS, Cross Site Scripting. 该攻击类型有两种：反射型 / 存储型。预防措施是 1.做输入校验，替换 2.设置cookie为http-only访问方式 CSRF跨站点请求攻击触发跨站请求预防：cookie hash 2.web token 7.2 容器化部署简介Docker的核心技术是什么： namespace 命名空间，是隔离进程，用户、网络、IPC以及UTS等的基础。 CGroups 控制组限制硬件资源 UnionFS 做了镜像管理 容器Docker与虚拟机的区别： 进程与系统的区别，docker仅仅是操作系统(虚拟机)的一个进程。 改造为docker部署 部分省略 application.properties文件中如server.port=${SERVER_PORT:8888}表示获取操作系统的环境变量SERVER_PORT,如果没有该环境变量则使用默认值8888. 7.3 对开发而言算法是什么99.9%的公司都是产品业务驱动；当产品的运营模式成功后，则考虑部分业务转为数据驱动，依赖数据(BI, 大数据, 算法)来驱动决策；。所以一般在大型互联网公司才会有大数据、数据挖掘、算法和人工智能这种实验室或部门。 7.4 fresh云原生云原生 = 微服务 + DevOps + 持续交付 + 容器化 service meshservice mesh = serverlessserverless = k8s工作流程 大数据","link":"/2021/10/29/%E8%BF%88%E5%90%91%E9%AB%98%E7%BA%A7Java%E7%9A%84%E9%9D%A2%E8%AF%95%E7%AA%81%E5%9B%B4%E8%AF%BE/"}],"tags":[{"name":"网易☁️","slug":"网易☁️","link":"/tags/%E7%BD%91%E6%98%93%E2%98%81%EF%B8%8F/"}],"categories":[{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"前端开发","slug":"前端开发","link":"/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"未分类","slug":"未分类","link":"/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/categories/Spring-Cloud/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"DevOps","slug":"DevOps","link":"/categories/DevOps/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]}